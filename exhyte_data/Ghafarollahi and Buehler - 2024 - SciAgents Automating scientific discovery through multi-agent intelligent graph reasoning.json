{
  "Inputs to the workflow": {
    "performed": "Yes",
    "User provide high-level research direction or goal": {
      "performed": "Yes",
      "Format": "Natural language prompt or task statement (e.g., keywords, research question, or task description)",
      "Example": "User specifies keywords such as 'silk' and 'energy-intensive', or requests generation of a research hypothesis from random keywords.",
      "Role in workflow": "Initiates the automated discovery process and guides the selection of concepts for hypothesis generation."
    },
    "User provide structured, domain-specific specifications": {
      "performed": "No"
    },
    "User provide research papers": {
      "performed": "Yes",
      "Format": "Corpus of scientific papers (PDFs or text), pre-processed into a knowledge graph",
      "Example": "A knowledge graph constructed from ~1,000 scientific papers in bio-inspired materials.",
      "Role in workflow": "Serves as the foundational data source for knowledge graph construction and downstream reasoning."
    },
    "User provide datasets other than research papers": {
      "performed": "No"
    },
    "User provide representations or formal inputs": {
      "performed": "Yes",
      "Format": "Keywords, node selections, or graph-based representations",
      "Example": "User provides or system randomly selects two nodes (concepts) from the knowledge graph to define the scope of hypothesis generation.",
      "Role in workflow": "Defines the start and end points for knowledge graph path sampling, shaping the context for hypothesis generation."
    }
  },
  "Query Structuring": {
    "performed": "Yes",
    "Query Decomposition": {
      "performed": "Yes",
      "Method details": "LLM-based agents or planners decompose the user’s high-level task into subtasks (e.g., path generation, ontology definition, hypothesis drafting, critique).",
      "Inputs": "User task or keywords",
      "Outputs": "Ordered sub-tasks for agent execution",
      "Example": "Planner agent breaks down 'generate research hypothesis from random keywords' into steps for path generation, ontology, hypothesis, critique.",
      "Role in workflow": "Enables modular, multi-agent execution and structured workflow progression."
    },
    "Structural or Entity Decomposition": {
      "performed": "Yes",
      "Method details": "Knowledge graph nodes and edges represent decomposed scientific entities and their relationships.",
      "Inputs": "Knowledge graph derived from literature",
      "Outputs": "Subgraphs/pathways connecting concepts",
      "Example": "Sampling a path between 'silk' and 'energy-intensive' reveals intermediate entities and relationships.",
      "Role in workflow": "Supports fine-grained reasoning and hypothesis generation by exposing entity-level structure."
    },
    "Workflow Decomposition": {
      "performed": "Yes",
      "Method details": "Planner agent generates a multi-step plan, assigning roles to specialized LLM agents (e.g., Ontologist, Scientist 1, Critic).",
      "Inputs": "User task or keywords",
      "Outputs": "Sequenced agent actions and responsibilities",
      "Example": "Planner outputs: generate path → define ontology → draft hypothesis → expand aspects → critique.",
      "Role in workflow": "Orchestrates agent collaboration and ensures systematic hypothesis development."
    },
    "Textual or Knowledge Embedding": {
      "performed": "Yes",
      "Method details": "Node embeddings generated using BAAI/bge-large-en-v1.5 model for heuristic pathfinding and semantic graph traversal.",
      "Inputs": "Text from scientific papers, graph nodes",
      "Outputs": "Vector embeddings for nodes",
      "Example": "Embeddings used to estimate distances and guide random path sampling in the knowledge graph.",
      "Role in workflow": "Enables semantic reasoning and diverse path sampling for hypothesis context."
    },
    "Molecular or Chemical Embedding": {
      "performed": "No"
    },
    "Biological or Phenotypic Embedding": {
      "performed": "No"
    },
    "Pattern and Feature Extraction": {
      "performed": "No"
    },
    "Biological Relationship Extraction": {
      "performed": "No"
    },
    "Property and Annotation Extraction": {
      "performed": "No"
    },
    "Sequence and Structure Feature Extraction": {
      "performed": "No"
    }
  },
  "Data Retrieval": {
    "performed": "Yes",
    "Data Retrieval via Multi-Query Generation and Exploration": {
      "performed": "No"
    },
    "Literature and Data Retrieval via APIs": {
      "performed": "Yes",
      "Method details": "Semantic Scholar API is used by an assistant agent to retrieve related publications for novelty and feasibility assessment.",
      "Inputs": "Keywords or research hypothesis generated by the system",
      "Outputs": "Top 10 relevant publications per query, including titles and abstracts",
      "Example": "Novelty assistant agent queries Semantic Scholar with hypothesis-related keywords.",
      "Role in workflow": "Provides external literature context for hypothesis novelty checking."
    },
    "Data Retrieval with Prioritization and Filtering Agents": {
      "performed": "Yes",
      "Method details": "Novelty assistant agent analyzes retrieved abstracts and rates novelty/feasibility on a 1–10 scale.",
      "Inputs": "Retrieved publications from Semantic Scholar API",
      "Outputs": "Novelty and feasibility scores, qualitative review",
      "Example": "Assistant agent returns 'Novelty: 8/10, Feasibility: 7/10' for a proposed hypothesis.",
      "Role in workflow": "Filters and prioritizes hypotheses based on literature overlap and feasibility."
    },
    "Domain-Specific Data Retrieval and Reasoning": {
      "performed": "No"
    },
    "Code-Driven or Tool-Augmented Data Retrieval": {
      "performed": "No"
    },
    "Literature data Retrieval Citation-Network–Based Expansion": {
      "performed": "No"
    },
    "Literature data Retrieval via Semantic and Similarity-Based analysis": {
      "performed": "Yes",
      "Method details": "Node embeddings and semantic similarity are used for pathfinding and subgraph extraction in the knowledge graph.",
      "Inputs": "Node embeddings, graph structure",
      "Outputs": "Semantically relevant subgraphs/paths",
      "Example": "Random path sampling between nodes based on embedding similarity.",
      "Role in workflow": "Expands the conceptual space for hypothesis generation."
    },
    "Literature data Retrieval via Multi-Step Reference and Evidence Selection": {
      "performed": "No"
    },
    "Domain-Specific Literature data Retrieval": {
      "performed": "No"
    },
    "Manual and Semi-Automatic Curation of Literature data": {
      "performed": "No"
    },
    "Structural or Similarity-Based Dataset Retrieval": {
      "performed": "No"
    },
    "Data Retrieval via Domain-Specific Repository Querying": {
      "performed": "No"
    },
    "Library Assembly and Data Augmentation": {
      "performed": "No"
    }
  },
  "Knowledge Assembly": {
    "performed": "Yes",
    "Standardized Section Extraction from Literature data": {
      "performed": "No"
    },
    "Concise Synopsis and Summarization of Literature data": {
      "performed": "No"
    },
    "Facet-Based or Field-Specific Extraction from Literature data": {
      "performed": "No"
    },
    "Domain-Tailored Extraction from Literature data": {
      "performed": "No"
    },
    "Task/Entity-Centric Knowledge Graphs": {
      "performed": "Yes",
      "Method details": "A large-scale knowledge graph is constructed from ~1,000 scientific papers, with nodes as concepts and edges as relationships.",
      "Inputs": "Corpus of scientific papers",
      "Outputs": "Knowledge graph with 33,159 nodes and 48,753 edges",
      "Example": "Graph connects concepts like 'silk' and 'energy-intensive' via intermediate nodes.",
      "Role in workflow": "Provides structured, queryable context for hypothesis generation and reasoning."
    },
    "Causal or Relation-Specific Knowledge Graphs": {
      "performed": "Yes",
      "Method details": "Edges in the knowledge graph encode specific relationships (e.g., 'possess', 'include', 'exhibited by').",
      "Inputs": "Extracted relationships from literature",
      "Outputs": "Relation-typed edges in the knowledge graph",
      "Example": "Edge: 'silk' -- 'possess' --> 'biopolymers'.",
      "Role in workflow": "Enables mechanistic and relational reasoning for hypothesis development."
    },
    "Biomedical or Domain-Specific Interaction Graphs": {
      "performed": "No"
    },
    "Literature Database Construction": {
      "performed": "No"
    },
    "Entity- or Co-Occurrence–Based Databases": {
      "performed": "No"
    },
    "Reasoning-Chain or Temporal Databases for Literature": {
      "performed": "No"
    }
  },
  "Hypothesis/Idea Generation": {
    "performed": "Yes",
    "Idea/hypothesis generation without additional literature or dataset as context": {
      "performed": "No"
    },
    "LLM Agent Generate ideas/hypotheses via Task Decomposition": {
      "performed": "Yes",
      "Method details": "Planner agent decomposes the workflow, assigning hypothesis generation to specialized LLM agents (e.g., Scientist 1, Scientist 2).",
      "Inputs": "Ontology definitions, knowledge graph subgraph",
      "Outputs": "Structured hypothesis with multiple facets (hypothesis, outcome, mechanisms, etc.)",
      "Example": "Scientist 1 agent drafts a hypothesis, Scientist 2 expands and refines it.",
      "Role in workflow": "Enables modular, multi-perspective hypothesis creation and refinement."
    },
    "Generate ideas/hypotheses using Domain-Specialized LLM Agent": {
      "performed": "Yes",
      "Method details": "Agents with specialized roles (Ontologist, Scientist, Critic) use LLMs (GPT-4) to generate, expand, and critique hypotheses.",
      "Inputs": "Knowledge graph context, ontology definitions",
      "Outputs": "Detailed, domain-specific research hypotheses",
      "Example": "Scientist 2 agent adds quantitative details, modeling suggestions, and experimental priorities.",
      "Role in workflow": "Ensures hypotheses are grounded in domain knowledge and scientific rigor."
    },
    "Literature data used during idea/hypothesis generation as context": {
      "performed": "Yes",
      "Method details": "Knowledge graph, constructed from literature, is sampled to provide context for LLM-based hypothesis generation.",
      "Inputs": "Subgraph/path from literature-derived knowledge graph",
      "Outputs": "Contextualized hypotheses incorporating literature-derived relationships",
      "Example": "Hypothesis integrates concepts and mechanisms from sampled knowledge graph path.",
      "Role in workflow": "Anchors hypothesis generation in existing scientific knowledge."
    },
    "Summarization Literature data used during idea/hypothesis generation": {
      "performed": "No"
    },
    "Idea/hypothesis generation via Facet Recombination": {
      "performed": "No"
    },
    "Idea/hypothesis generation via contructed Reasoning-Chain from literature": {
      "performed": "No"
    },
    "Idea/hypothesis generation via Knowledge Graph developed from literature": {
      "performed": "Yes",
      "Method details": "Hypotheses are generated by traversing sampled paths/subgraphs in the literature-derived knowledge graph.",
      "Inputs": "Sampled knowledge graph paths",
      "Outputs": "Novel hypotheses connecting previously unrelated concepts",
      "Example": "Random path between 'silk' and 'energy-intensive' yields a hypothesis on silk-pigment composites.",
      "Role in workflow": "Facilitates discovery of interdisciplinary or unexpected connections."
    },
    "Idea/hypothesis generation via Pattern Detection from dataset": {
      "performed": "No"
    },
    "Idea/hypothesis generation via Few-Shot Data Seeding": {
      "performed": "No"
    },
    "Idea/hypothesis generation using Observational data": {
      "performed": "No"
    },
    "Idea/hypothesis generation via Feature-Driven Property Prediction": {
      "performed": "No"
    },
    "Idea/hypothesis generation after Fine-Tuning the LLM model": {
      "performed": "No"
    }
  },
  "Hypothesis/Idea Prioritization": {
    "performed": "Yes",
    "LLM-based Hypothesis/Idea evaluation via Scientific Quality": {
      "performed": "Yes",
      "Method details": "Critic agent (LLM) reviews hypotheses for strengths, weaknesses, and suggests improvements.",
      "Inputs": "Drafted hypothesis and expanded aspects",
      "Outputs": "Critical review, summary, and improvement suggestions",
      "Example": "Critic agent highlights integration challenges and proposes pilot studies.",
      "Role in workflow": "Ensures scientific rigor and identifies areas for refinement."
    },
    "LLM-based Hypothesis/Idea evaluation via Domain-Specific Evaluation": {
      "performed": "Yes",
      "Method details": "Critic agent evaluates hypotheses for domain-specific feasibility, modeling, and experimental priorities.",
      "Inputs": "Expanded hypothesis document",
      "Outputs": "Domain-specific critique and prioritized research questions",
      "Example": "Critic agent identifies key modeling and synthetic biology questions.",
      "Role in workflow": "Aligns hypotheses with domain standards and actionable next steps."
    },
    "LLM-based Hypothesis/Idea evaluation via Contextual Evidence Scoring": {
      "performed": "No"
    },
    "LLM-based Hypothesis/Idea evaluation via Interpretability or Success Metrics": {
      "performed": "No"
    },
    "Hypothesis/Idea evaluation via Novelty Checking with Literature Comparison": {
      "performed": "Yes",
      "Method details": "Novelty assistant agent queries Semantic Scholar API and rates novelty/feasibility based on retrieved literature.",
      "Inputs": "Generated hypothesis, keywords",
      "Outputs": "Novelty and feasibility scores, literature-based review",
      "Example": "Returned score: 'Novelty: 8/10, Feasibility: 7/10' with supporting literature analysis.",
      "Role in workflow": "Filters out redundant or non-novel hypotheses, focusing resources on promising ideas."
    },
    "Hypothesis/Idea evaluation via Alignment with Literature Chains": {
      "performed": "No"
    },
    "Hypothesis/Idea evaluation via Knowledge-Graph Grounded Similarity Metrics": {
      "performed": "No"
    },
    "Hypothesis/Idea evaluation via Quantitative Assessment Using Domain Metrics": {
      "performed": "Yes",
      "Method details": "Critic and Scientist 2 agents add quantitative predictions (e.g., tensile strength, energy savings) and modeling priorities.",
      "Inputs": "Expanded hypothesis with quantitative details",
      "Outputs": "Numerical targets and modeling/experimental plans",
      "Example": "Predicted tensile strength, energy reduction, and simulation setup steps.",
      "Role in workflow": "Provides objective criteria for hypothesis assessment and downstream testing."
    },
    "Hypothesis/Idea evaluation via Human/Expert": {
      "performed": "No"
    }
  },
  "Test": {
    "performed": "Yes",
    "Experimental Design Generation via literature-Grounded Model/Protocol Selection": {
      "performed": "No"
    },
    "Experimental Design Generation via Literature Synthesis for New Protocol Generation": {
      "performed": "No"
    },
    "Experimental Design Generation via Few-Shot or Example-Based Prompting": {
      "performed": "No"
    },
    "Experimental Design Generation via Executable Code Generation from Literature": {
      "performed": "No"
    },
    "LLM-Based Experimental Design Generation via Agentic Exploration and Planning": {
      "performed": "Yes",
      "Method details": "Planner and Critic agents generate detailed modeling and experimental plans (e.g., MD simulation setup, synthetic biology protocols).",
      "Inputs": "Expanded hypothesis and critique",
      "Outputs": "Step-by-step modeling and experimental procedures",
      "Example": "Critic agent outlines MD simulation steps and synthetic biology engineering workflow.",
      "Role in workflow": "Translates hypotheses into actionable experimental and computational test plans."
    },
    "LLM-Based Experimental Design Generation via Code and Workflow Translation": {
      "performed": "No"
    },
    "LLM-Based Experimental Design Generation via Multi-Agent Planning with Specialized Roles": {
      "performed": "Yes",
      "Method details": "Agents with specialized roles (Planner, Scientist, Critic) collaborate to refine and detail experimental/modeling priorities.",
      "Inputs": "Hypothesis, expanded aspects, critique",
      "Outputs": "Integrated experimental and modeling plans",
      "Example": "Planner agent initiates, Critic agent finalizes modeling and experimental steps.",
      "Role in workflow": "Ensures comprehensive, multi-perspective experimental design."
    },
    "LLM-Based Experimental Design Generation via Domain-Specific Experimental Mapping": {
      "performed": "Yes",
      "Method details": "Critic agent maps hypotheses to specific modeling (e.g., MD, FEA) and experimental (e.g., synthetic biology) techniques.",
      "Inputs": "Expanded hypothesis and critique",
      "Outputs": "Domain-specific experimental and modeling protocols",
      "Example": "Critic agent specifies use of GROMACS/AMBER for MD, CRISPR for gene editing.",
      "Role in workflow": "Bridges hypothesis to concrete domain-specific test strategies."
    },
    "Test Execution via Human-in-the-Loop": {
      "performed": "No"
    },
    "Test Execution via Automated Wet-Lab Execution": {
      "performed": "No"
    },
    "Test Execution via Computational or In-Silico": {
      "performed": "No"
    },
    "Refinement via LLM Agent Feedback Loops": {
      "performed": "Yes",
      "Method details": "Critic agent provides iterative feedback and suggestions for hypothesis and experimental plan improvement.",
      "Inputs": "Drafted hypothesis, expanded aspects, critique",
      "Outputs": "Refined hypotheses and experimental plans",
      "Example": "Critic agent suggests pilot studies, green chemistry, and scalability improvements.",
      "Role in workflow": "Enables iterative refinement and increased robustness of proposed research."
    },
    "Refinement via Automated Quality Evaluation using Model-Based Critics": {
      "performed": "No"
    },
    "Refinement via Dynamic Agent Updating Based on Evolving Context or Data": {
      "performed": "No"
    },
    "Refinement via guided by computational-data": {
      "performed": "No"
    },
    "Refinement via experimental validation": {
      "performed": "No"
    },
    "Refinement via Performance-metric": {
      "performed": "No"
    },
    "Refinement via Human–data integration": {
      "performed": "No"
    }
  },
  "paper_title": "SciAgents: Automating scientific discovery through multi-agent intelligent graph reasoning",
  "authors": [
    "Alireza",
    "Markus J."
  ],
  "published": "2024-09-09",
  "link": "http://arxiv.org/abs/2409.05556"
}