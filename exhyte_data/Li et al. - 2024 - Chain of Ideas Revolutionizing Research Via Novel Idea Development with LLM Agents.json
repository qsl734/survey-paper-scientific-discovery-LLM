{
  "Inputs to the workflow": {
    "performed": "Yes",
    "User provide high-level research direction or goal": {
      "performed": "Yes",
      "Format": "Natural language research topic or question",
      "Example": "Using LLM agent to generate novel and original research ideas without human participation",
      "Role in workflow": "Defines the research topic for which the system generates ideas and experiment designs"
    },
    "User provide structured, domain-specific specifications": {
      "performed": "No"
    },
    "User provide research papers": {
      "performed": "No"
    },
    "User provide datasets other than research papers": {
      "performed": "No"
    },
    "User provide representations or formal inputs": {
      "performed": "No"
    }
  },
  "Query Structuring": {
    "performed": "Yes",
    "Query Decomposition": {
      "performed": "Yes",
      "Method details": "LLM generates multiple queries from the initial research topic to capture different perspectives.",
      "Inputs": "User-provided research topic",
      "Outputs": "A set of K queries reflecting different aspects of the topic",
      "Example": "For a topic, LLM outputs several search queries, each targeting a sub-aspect.",
      "Role in workflow": "Enables retrieval of anchor papers covering diverse angles of the research topic."
    },
    "Structural or Entity Decomposition": {
      "performed": "Yes",
      "Method details": "LLM extracts entities such as model names, datasets, and metrics from papers.",
      "Inputs": "Full text of retrieved papers",
      "Outputs": "List of entities with descriptions",
      "Example": "Extracting 'GPT4: A strong LLM used in recent papers' as an entity.",
      "Role in workflow": "Provides structured knowledge for downstream idea generation and experiment design."
    },
    "Workflow Decomposition": {
      "performed": "No"
    },
    "Textual or Knowledge Embedding": {
      "performed": "Yes",
      "Method details": "Uses OpenAI’s text-embedding-3-large to embed topic and paper abstracts for similarity ranking.",
      "Inputs": "Concatenated research topic and anchor paper abstract; candidate papers’ abstracts",
      "Outputs": "Cosine similarity scores for ranking papers",
      "Example": "Ranking forward citations by embedding similarity to topic+anchor abstract.",
      "Role in workflow": "Selects the most relevant papers for chain construction."
    },
    "Molecular or Chemical Embedding": {
      "performed": "No"
    },
    "Biological or Phenotypic Embedding": {
      "performed": "No"
    },
    "Pattern and Feature Extraction": {
      "performed": "No"
    },
    "Biological Relationship Extraction": {
      "performed": "No"
    },
    "Property and Annotation Extraction": {
      "performed": "No"
    },
    "Sequence and Structure Feature Extraction": {
      "performed": "No"
    }
  },
  "Data Retrieval": {
    "performed": "Yes",
    "Data Retrieval via Multi-Query Generation and Exploration": {
      "performed": "Yes",
      "Method details": "LLM generates multiple queries per topic to retrieve anchor papers for different perspectives.",
      "Inputs": "User topic",
      "Outputs": "Multiple anchor papers, each for a query",
      "Example": "Three queries yield three anchor papers for chain construction.",
      "Role in workflow": "Ensures coverage of multiple research directions."
    },
    "Literature and Data Retrieval via APIs": {
      "performed": "Yes",
      "Method details": "Semantic Scholar API is used to retrieve papers based on queries.",
      "Inputs": "Search queries generated by LLM",
      "Outputs": "Lists of relevant papers per query",
      "Example": "Querying Semantic Scholar for top-ranked papers.",
      "Role in workflow": "Automates literature collection for chain construction."
    },
    "Data Retrieval with Prioritization and Filtering Agents": {
      "performed": "Yes",
      "Method details": "LLM and embedding-based ranking select the most relevant papers among citations and references.",
      "Inputs": "Candidate papers from API retrieval",
      "Outputs": "Selected papers for chain extension",
      "Example": "Selecting the highest-ranked forward citation as next in chain.",
      "Role in workflow": "Filters literature to build coherent chains."
    },
    "Domain-Specific Data Retrieval and Reasoning": {
      "performed": "No"
    },
    "Code-Driven or Tool-Augmented Data Retrieval": {
      "performed": "No"
    },
    "Literature data Retrieval Citation-Network–Based Expansion": {
      "performed": "Yes",
      "Method details": "Chains are extended forward via papers citing the anchor and backward via references.",
      "Inputs": "Anchor paper; its citations and references",
      "Outputs": "Ordered chain of papers tracing research evolution",
      "Example": "Extending from ToT to GoT (forward), and from ToT to SC to CoT (backward).",
      "Role in workflow": "Mirrors the progression of research for context-rich idea generation."
    },
    "Literature data Retrieval via Semantic and Similarity-Based analysis": {
      "performed": "Yes",
      "Method details": "Embeddings are used to rank candidate papers by semantic similarity to topic and anchor.",
      "Inputs": "Embeddings of topic+anchor and candidate papers",
      "Outputs": "Ranked list of papers",
      "Example": "Using cosine similarity to select the most relevant citation.",
      "Role in workflow": "Ensures relevance in chain construction."
    },
    "Literature data Retrieval via Multi-Step Reference and Evidence Selection": {
      "performed": "Yes",
      "Method details": "LLM iteratively selects the most relevant reference or citation at each step to extend the chain.",
      "Inputs": "References/citations of current chain paper",
      "Outputs": "Next paper in chain",
      "Example": "LLM reviews references to pick the most relevant for backward extension.",
      "Role in workflow": "Builds a logically coherent chain of literature."
    },
    "Domain-Specific Literature data Retrieval": {
      "performed": "No"
    },
    "Manual and Semi-Automatic Curation of Literature data": {
      "performed": "No"
    },
    "Structural or Similarity-Based Dataset Retrieval": {
      "performed": "No"
    },
    "Data Retrieval via Domain-Specific Repository Querying": {
      "performed": "No"
    },
    "Library Assembly and Data Augmentation": {
      "performed": "No"
    }
  },
  "Knowledge Assembly": {
    "performed": "Yes",
    "Standardized Section Extraction from Literature data": {
      "performed": "Yes",
      "Method details": "LLM extracts structured fields (entities, idea summary, experiment, references) from each paper.",
      "Inputs": "Full text or summary of each paper",
      "Outputs": "Entities, idea, experiment, references per paper",
      "Example": "Extracting 'Entities', 'Idea', 'Experiment', 'References' from a paper.",
      "Role in workflow": "Normalizes literature for downstream reasoning."
    },
    "Concise Synopsis and Summarization of Literature data": {
      "performed": "Yes",
      "Method details": "LLM summarizes the core idea and experimental content of each paper.",
      "Inputs": "Paper content",
      "Outputs": "Concise summary of idea and experiment",
      "Example": "Summarizing the novelty and contribution of a cited work.",
      "Role in workflow": "Provides digestible context for idea generation."
    },
    "Facet-Based or Field-Specific Extraction from Literature data": {
      "performed": "Yes",
      "Method details": "LLM extracts background, novelty, contribution, limitations, and experimental details.",
      "Inputs": "Paper content",
      "Outputs": "Structured facets per paper",
      "Example": "Extracting 'Limitation' and 'Contribution' fields.",
      "Role in workflow": "Enables fine-grained analysis and recombination."
    },
    "Domain-Tailored Extraction from Literature data": {
      "performed": "Yes",
      "Method details": "LLM extracts entities relevant to the research topic, such as models and datasets.",
      "Inputs": "Paper content",
      "Outputs": "Domain-specific entities",
      "Example": "Extracting 'GraphGPT' as a model entity.",
      "Role in workflow": "Grounds idea generation in domain knowledge."
    },
    "Task/Entity-Centric Knowledge Graphs": {
      "performed": "No"
    },
    "Causal or Relation-Specific Knowledge Graphs": {
      "performed": "No"
    },
    "Biomedical or Domain-Specific Interaction Graphs": {
      "performed": "No"
    },
    "Literature Database Construction": {
      "performed": "No"
    },
    "Entity- or Co-Occurrence–Based Databases": {
      "performed": "No"
    },
    "Reasoning-Chain or Temporal Databases for Literature": {
      "performed": "Yes",
      "Method details": "Papers are organized into a chain reflecting the temporal/progressive development of ideas.",
      "Inputs": "Ordered list of papers (by citation and relevance)",
      "Outputs": "Chain of ideas showing research evolution",
      "Example": "CoT → SC → ToT → GoT chain for reasoning.",
      "Role in workflow": "Supports trend analysis and future idea prediction."
    }
  },
  "Hypothesis/Idea Generation": {
    "performed": "Yes",
    "Idea/hypothesis generation without additional literature or dataset as context": {
      "performed": "No"
    },
    "LLM Agent Generate ideas/hypotheses via Task Decomposition": {
      "performed": "No"
    },
    "Generate ideas/hypotheses using Domain-Specialized LLM Agent": {
      "performed": "No"
    },
    "Literature data used during idea/hypothesis generation as context": {
      "performed": "Yes",
      "Method details": "LLM is prompted with the constructed chain of ideas, extracted entities, and summarized trends.",
      "Inputs": "Chain of ideas, entities, summarized trends",
      "Outputs": "Draft research ideas and motivations",
      "Example": "LLM proposes a new idea after analyzing CoT→SC→ToT→GoT progression.",
      "Role in workflow": "Ensures ideas are grounded in current research evolution."
    },
    "Summarization Literature data used during idea/hypothesis generation": {
      "performed": "Yes",
      "Method details": "LLM uses summarized trends and extracted facets from literature as context for ideation.",
      "Inputs": "Summarized trends, extracted facets",
      "Outputs": "Motivation, novelty, and method for new idea",
      "Example": "LLM uses trend analysis to predict future research directions.",
      "Role in workflow": "Guides idea generation with concise, relevant context."
    },
    "Idea/hypothesis generation via Facet Recombination": {
      "performed": "Yes",
      "Method details": "LLM combines limitations, contributions, and methods from multiple papers to form new ideas.",
      "Inputs": "Extracted facets from chain papers",
      "Outputs": "Novel research idea combining multiple facets",
      "Example": "Combining 'mutation' from one method and 'crossover' from another for evolutionary idea generation.",
      "Role in workflow": "Synthesizes new concepts from existing literature."
    },
    "Idea/hypothesis generation via contructed Reasoning-Chain from literature": {
      "performed": "Yes",
      "Method details": "LLM analyzes the progression of ideas in the chain to predict future trends and generate ideas.",
      "Inputs": "Chain of ideas with trend analysis",
      "Outputs": "Future trend prediction and consolidated idea",
      "Example": "Identifying the shift from hypothesis generation to idea generation and proposing the next step.",
      "Role in workflow": "Enables evidence-based, forward-looking ideation."
    },
    "Idea/hypothesis generation via Knowledge Graph developed from literature": {
      "performed": "No"
    },
    "Idea/hypothesis generation via Pattern Detection from dataset": {
      "performed": "No"
    },
    "Idea/hypothesis generation via Few-Shot Data Seeding": {
      "performed": "Yes",
      "Method details": "LLM is prompted with few-shot examples of ideas and experiments from existing works.",
      "Inputs": "Extracted experiments and ideas from prior papers",
      "Outputs": "New idea and experiment design",
      "Example": "Providing CoT and SC experiment designs as examples for new design.",
      "Role in workflow": "Improves quality and feasibility of generated ideas."
    },
    "Idea/hypothesis generation using Observational data": {
      "performed": "No"
    },
    "Idea/hypothesis generation via Feature-Driven Property Prediction": {
      "performed": "No"
    },
    "Idea/hypothesis generation after Fine-Tuning the LLM model": {
      "performed": "No"
    }
  },
  "Hypothesis/Idea Prioritization": {
    "performed": "Yes",
    "LLM-based Hypothesis/Idea evaluation via Scientific Quality": {
      "performed": "Yes",
      "Method details": "LLM judges evaluate ideas for novelty, significance, clarity, feasibility, and effectiveness.",
      "Inputs": "Generated ideas and evaluation criteria",
      "Outputs": "Pairwise rankings and ELO scores",
      "Example": "Idea Arena uses LLMs to rank ideas on multiple criteria.",
      "Role in workflow": "Selects the best idea for experiment design."
    },
    "LLM-based Hypothesis/Idea evaluation via Domain-Specific Evaluation": {
      "performed": "Yes",
      "Method details": "LLM judges use ICML review guidelines and domain-specific criteria for evaluation.",
      "Inputs": "Ideas, domain-specific evaluation prompts",
      "Outputs": "Rankings per domain-relevant metrics",
      "Example": "Evaluating feasibility and technical quality for experiment designs.",
      "Role in workflow": "Ensures ideas are relevant and actionable in the domain."
    },
    "LLM-based Hypothesis/Idea evaluation via Contextual Evidence Scoring": {
      "performed": "No"
    },
    "LLM-based Hypothesis/Idea evaluation via Interpretability or Success Metrics": {
      "performed": "No"
    },
    "Hypothesis/Idea evaluation via Novelty Checking with Literature Comparison": {
      "performed": "Yes",
      "Method details": "A novelty-checker agent retrieves relevant papers and prompts LLM to assess similarity.",
      "Inputs": "Draft idea, retrieved literature",
      "Outputs": "Novelty assessment and possible refinement",
      "Example": "LLM checks if the generated idea is too similar to existing works.",
      "Role in workflow": "Prevents plagiarism and ensures originality."
    },
    "Hypothesis/Idea evaluation via Alignment with Literature Chains": {
      "performed": "Yes",
      "Method details": "LLM analyzes if the idea logically follows the progression in the constructed chain.",
      "Inputs": "Generated idea, chain of ideas",
      "Outputs": "Assessment of logical alignment",
      "Example": "Evaluating if the new idea is a natural next step after GoT.",
      "Role in workflow": "Ensures coherence with research trends."
    },
    "Hypothesis/Idea evaluation via Knowledge-Graph Grounded Similarity Metrics": {
      "performed": "No"
    },
    "Hypothesis/Idea evaluation via Quantitative Assessment Using Domain Metrics": {
      "performed": "No"
    },
    "Hypothesis/Idea evaluation via Human/Expert": {
      "performed": "Yes",
      "Method details": "Human researchers perform pairwise evaluation of generated ideas and experiment designs.",
      "Inputs": "Generated ideas, experiment designs",
      "Outputs": "Human rankings and agreement metrics",
      "Example": "10 researchers rank ideas for novelty and feasibility.",
      "Role in workflow": "Provides ground-truth validation for LLM-based evaluation."
    }
  },
  "Test": {
    "performed": "Yes",
    "Experimental Design Generation via literature-Grounded Model/Protocol Selection": {
      "performed": "Yes",
      "Method details": "LLM uses extracted experiment designs from prior works as baselines for new designs.",
      "Inputs": "Experiment designs from chain papers",
      "Outputs": "Baseline selection for new experiment",
      "Example": "Using CoT and SC experiment designs as baselines.",
      "Role in workflow": "Ensures new experiments are grounded in proven protocols."
    },
    "Experimental Design Generation via Literature Synthesis for New Protocol Generation": {
      "performed": "Yes",
      "Method details": "LLM synthesizes methods and steps from multiple prior experiments to generate new protocols.",
      "Inputs": "Extracted experiment designs, entities, and the new idea",
      "Outputs": "Detailed experimental plan",
      "Example": "Combining steps from GoT and ToT experiments for a new protocol.",
      "Role in workflow": "Creates tailored experimental designs for novel ideas."
    },
    "Experimental Design Generation via Few-Shot or Example-Based Prompting": {
      "performed": "Yes",
      "Method details": "LLM is prompted with few-shot examples of experiment designs from literature.",
      "Inputs": "Prior experiment designs, new idea",
      "Outputs": "Experiment design for new idea",
      "Example": "Prompting LLM with previous experiment steps to guide new design.",
      "Role in workflow": "Improves clarity and feasibility of generated protocols."
    },
    "Experimental Design Generation via Executable Code Generation from Literature": {
      "performed": "No"
    },
    "LLM-Based Experimental Design Generation via Agentic Exploration and Planning": {
      "performed": "Yes",
      "Method details": "LLM agent iteratively plans and refines experiment design, incorporating review agent feedback.",
      "Inputs": "Initial experiment design, review feedback, additional literature if needed",
      "Outputs": "Refined experimental plan",
      "Example": "Review agent critiques and LLM refines the experiment design.",
      "Role in workflow": "Ensures experiment designs are clear, feasible, and actionable."
    },
    "LLM-Based Experimental Design Generation via Code and Workflow Translation": {
      "performed": "No"
    },
    "LLM-Based Experimental Design Generation via Multi-Agent Planning with Specialized Roles": {
      "performed": "Yes",
      "Method details": "Review agent evaluates experiment design for clarity and feasibility, prompting LLM to refine.",
      "Inputs": "Draft experiment design, review agent feedback",
      "Outputs": "Improved experiment design",
      "Example": "Review agent suggests improvements, LLM updates design.",
      "Role in workflow": "Enhances quality and implementability of experimental protocols."
    },
    "LLM-Based Experimental Design Generation via Domain-Specific Experimental Mapping": {
      "performed": "No"
    },
    "Test Execution via Human-in-the-Loop": {
      "performed": "No"
    },
    "Test Execution via Automated Wet-Lab Execution": {
      "performed": "No"
    },
    "Test Execution via Computational or In-Silico": {
      "performed": "No"
    },
    "Refinement via LLM Agent Feedback Loops": {
      "performed": "Yes",
      "Method details": "LLM and review agent iteratively critique and refine experiment designs based on feedback.",
      "Inputs": "Experiment design, review feedback, additional literature if needed",
      "Outputs": "Refined experiment design",
      "Example": "LLM refines experiment after review agent points out missing details.",
      "Role in workflow": "Improves clarity, feasibility, and completeness of experimental plans."
    },
    "Refinement via Automated Quality Evaluation using Model-Based Critics": {
      "performed": "No"
    },
    "Refinement via Dynamic Agent Updating Based on Evolving Context or Data": {
      "performed": "No"
    },
    "Refinement via guided by computational-data": {
      "performed": "No"
    },
    "Refinement via experimental validation": {
      "performed": "No"
    },
    "Refinement via Performance-metric": {
      "performed": "No"
    },
    "Refinement via Human–data integration": {
      "performed": "No"
    }
  },
  "paper_title": "Chain of Ideas: Revolutionizing Research Via Novel Idea Development with LLM Agents",
  "authors": [
    "Long",
    "Weiwen",
    "Jiayan",
    "Ruochen",
    "Xingxuan",
    "Yuqian",
    "Boqiang",
    "Yuming",
    "Yifei",
    "Ronghao",
    "Deli",
    "Yu",
    "Tian",
    "Lidong"
  ],
  "published": "2024-10-30",
  "link": "http://arxiv.org/abs/2410.13185"
}