{
  "Inputs to the workflow": {
    "performed": "Yes",
    "User provide high-level research direction or goal": {
      "performed": "Yes",
      "Format": "Research problem statement: enabling LLMs to generate high-quality hypotheses from data.",
      "Example": "Main question: how can we enable LLMs to generate hypotheses of high-quality?",
      "Role in workflow": "Defines the scope and motivation for developing and evaluating the HypoGeniC algorithm."
    },
    "User provide structured, domain-specific specifications": {
      "performed": "No"
    },
    "User provide research papers": {
      "performed": "No"
    },
    "User provide datasets other than research papers": {
      "performed": "Yes",
      "Format": "Structured datasets for classification tasks (synthetic and real-world).",
      "Example": "SHOE SALES, DECEPTIVE REVIEWS, HEADLINE POPULARITY, TWEET POPULARITY datasets.",
      "Role in workflow": "Serve as the empirical basis for hypothesis generation and evaluation."
    },
    "User provide representations or formal inputs": {
      "performed": "No"
    }
  },
  "Query Structuring": {
    "performed": "Yes",
    "Query Decomposition": {
      "performed": "No"
    },
    "Structural or Entity Decomposition": {
      "performed": "No"
    },
    "Workflow Decomposition": {
      "performed": "No"
    },
    "Textual or Knowledge Embedding": {
      "performed": "No"
    },
    "Molecular or Chemical Embedding": {
      "performed": "No"
    },
    "Biological or Phenotypic Embedding": {
      "performed": "No"
    },
    "Pattern and Feature Extraction": {
      "performed": "Yes",
      "Method details": "LLMs are prompted to extract high-level patterns or features from labeled examples to generate hypotheses.",
      "Inputs": "Labeled data examples (input-output pairs) from datasets.",
      "Outputs": "Natural language hypotheses describing patterns between input features and labels.",
      "Example": "Hypothesis: 'Tweets with imperative commands like \"RT this\" are more likely to be retweeted.'",
      "Role in workflow": "Transforms raw data into interpretable hypotheses for downstream inference and evaluation."
    },
    "Biological Relationship Extraction": {
      "performed": "No"
    },
    "Property and Annotation Extraction": {
      "performed": "No"
    },
    "Sequence and Structure Feature Extraction": {
      "performed": "No"
    }
  },
  "Data Retrieval": {
    "performed": "Yes",
    "Data Retrieval via Multi-Query Generation and Exploration": {
      "performed": "No"
    },
    "Literature and Data Retrieval via APIs": {
      "performed": "No"
    },
    "Data Retrieval with Prioritization and Filtering Agents": {
      "performed": "No"
    },
    "Domain-Specific Data Retrieval and Reasoning": {
      "performed": "No"
    },
    "Code-Driven or Tool-Augmented Data Retrieval": {
      "performed": "No"
    },
    "Literature data Retrieval Citation-Network–Based Expansion": {
      "performed": "No"
    },
    "Literature data Retrieval via Semantic and Similarity-Based analysis": {
      "performed": "No"
    },
    "Literature data Retrieval via Multi-Step Reference and Evidence Selection": {
      "performed": "No"
    },
    "Domain-Specific Literature data Retrieval": {
      "performed": "No"
    },
    "Manual and Semi-Automatic Curation of Literature data": {
      "performed": "No"
    },
    "Structural or Similarity-Based Dataset Retrieval": {
      "performed": "No"
    },
    "Data Retrieval via Domain-Specific Repository Querying": {
      "performed": "No"
    },
    "Library Assembly and Data Augmentation": {
      "performed": "No"
    }
  },
  "Knowledge Assembly": {
    "performed": "No"
  },
  "Hypothesis/Idea Generation": {
    "performed": "Yes",
    "Idea/hypothesis generation without additional literature or dataset as context": {
      "performed": "No"
    },
    "LLM Agent Generate ideas/hypotheses via Task Decomposition": {
      "performed": "No"
    },
    "Generate ideas/hypotheses using Domain-Specialized LLM Agent": {
      "performed": "No"
    },
    "Literature data used during idea/hypothesis generation as context": {
      "performed": "No"
    },
    "Summarization Literature data used during idea/hypothesis generation": {
      "performed": "No"
    },
    "Idea/hypothesis generation via Facet Recombination": {
      "performed": "No"
    },
    "Idea/hypothesis generation via contructed Reasoning-Chain from literature": {
      "performed": "No"
    },
    "Idea/hypothesis generation via Knowledge Graph developed from literature": {
      "performed": "No"
    },
    "Idea/hypothesis generation via Pattern Detection from dataset": {
      "performed": "Yes",
      "Method details": "LLMs are prompted with labeled examples to induce hypotheses that capture patterns in the data.",
      "Inputs": "Small sets of labeled examples from datasets.",
      "Outputs": "Natural language hypotheses describing relationships between features and labels.",
      "Example": "Hypothesis: 'Customers tend to buy shoes that match the color of their shirt.'",
      "Role in workflow": "Enables interpretable, data-driven hypothesis generation for downstream testing and refinement."
    },
    "Idea/hypothesis generation via Few-Shot Data Seeding": {
      "performed": "Yes",
      "Method details": "LLMs are given a few labeled examples (few-shot) to prompt initial hypothesis generation.",
      "Inputs": "Few-shot labeled data pairs.",
      "Outputs": "Initial hypotheses in natural language.",
      "Example": "Prompting LLMs with 10 labeled examples to generate initial hypotheses.",
      "Role in workflow": "Bootstraps the hypothesis generation process with minimal data."
    },
    "Idea/hypothesis generation using Observational data": {
      "performed": "Yes",
      "Method details": "LLMs analyze observed input-output pairs to generate hypotheses about underlying relationships.",
      "Inputs": "Observed data pairs (e.g., tweet and retweet count).",
      "Outputs": "Hypotheses describing empirical relationships.",
      "Example": "Hypothesis: 'Tweets with named entities like people, places, or organizations tend to get more retweets.'",
      "Role in workflow": "Grounds hypothesis generation in empirical evidence from data."
    },
    "Idea/hypothesis generation via Feature-Driven Property Prediction": {
      "performed": "No"
    },
    "Idea/hypothesis generation after Fine-Tuning the LLM model": {
      "performed": "No"
    }
  },
  "Hypothesis/Idea Prioritization": {
    "performed": "Yes",
    "LLM-based Hypothesis/Idea evaluation via Scientific Quality": {
      "performed": "No"
    },
    "LLM-based Hypothesis/Idea evaluation via Domain-Specific Evaluation": {
      "performed": "No"
    },
    "LLM-based Hypothesis/Idea evaluation via Contextual Evidence Scoring": {
      "performed": "No"
    },
    "LLM-based Hypothesis/Idea evaluation via Interpretability or Success Metrics": {
      "performed": "Yes",
      "Method details": "Hypotheses are assigned rewards based on their predictive accuracy on training data; interpretability is ensured by natural language formulation.",
      "Inputs": "Hypotheses and labeled training data.",
      "Outputs": "Reward scores reflecting hypothesis accuracy.",
      "Example": "Reward=0.83 for a hypothesis that correctly predicts retweet outcomes.",
      "Role in workflow": "Ranks hypotheses for selection and further refinement based on empirical performance."
    },
    "Hypothesis/Idea evaluation via Novelty Checking with Literature Comparison": {
      "performed": "Yes",
      "Method details": "Qualitative analysis compares generated hypotheses to existing literature to identify novel insights.",
      "Inputs": "Generated hypotheses and findings from prior studies.",
      "Outputs": "Assessment of whether hypotheses are supported by or novel relative to literature.",
      "Example": "Novel hypothesis: 'Truthful reviews mention special occasions.'",
      "Role in workflow": "Validates novelty and relevance of hypotheses."
    },
    "Hypothesis/Idea evaluation via Alignment with Literature Chains": {
      "performed": "No"
    },
    "Hypothesis/Idea evaluation via Knowledge-Graph Grounded Similarity Metrics": {
      "performed": "No"
    },
    "Hypothesis/Idea evaluation via Quantitative Assessment Using Domain Metrics": {
      "performed": "Yes",
      "Method details": "Hypotheses are quantitatively evaluated by their classification accuracy on held-out test sets.",
      "Inputs": "Hypotheses, test datasets.",
      "Outputs": "Accuracy scores for each hypothesis.",
      "Example": "Hypothesis achieves 62% accuracy on TWEET POPULARITY test set.",
      "Role in workflow": "Objectively measures hypothesis predictive power."
    },
    "Hypothesis/Idea evaluation via Human/Expert": {
      "performed": "No"
    }
  },
  "Test": {
    "performed": "Yes",
    "Experimental Design Generation via literature-Grounded Model/Protocol Selection": {
      "performed": "No"
    },
    "Experimental Design Generation via Literature Synthesis for New Protocol Generation": {
      "performed": "No"
    },
    "Experimental Design Generation via Few-Shot or Example-Based Prompting": {
      "performed": "No"
    },
    "Experimental Design Generation via Executable Code Generation from Literature": {
      "performed": "No"
    },
    "LLM-Based Experimental Design Generation via Agentic Exploration and Planning": {
      "performed": "No"
    },
    "LLM-Based Experimental Design Generation via Code and Workflow Translation": {
      "performed": "No"
    },
    "LLM-Based Experimental Design Generation via Multi-Agent Planning with Specialized Roles": {
      "performed": "No"
    },
    "LLM-Based Experimental Design Generation via Domain-Specific Experimental Mapping": {
      "performed": "No"
    },
    "Test Execution via Human-in-the-Loop": {
      "performed": "No"
    },
    "Test Execution via Automated Wet-Lab Execution": {
      "performed": "No"
    },
    "Test Execution via Computational or In-Silico": {
      "performed": "Yes",
      "Method details": "Hypotheses are tested by applying them to held-out test data and measuring predictive accuracy.",
      "Inputs": "Generated hypotheses, test datasets.",
      "Outputs": "Prediction labels, accuracy metrics.",
      "Example": "Hypothesis-based classifier achieves 61.3% accuracy on HEADLINE POPULARITY test set.",
      "Role in workflow": "Validates hypotheses computationally, enabling iterative improvement."
    },
    "Refinement via LLM Agent Feedback Loops": {
      "performed": "No"
    },
    "Refinement via Automated Quality Evaluation using Model-Based Critics": {
      "performed": "No"
    },
    "Refinement via Dynamic Agent Updating Based on Evolving Context or Data": {
      "performed": "Yes",
      "Method details": "Hypotheses are iteratively updated based on errors identified in a 'wrong example bank' and their reward scores.",
      "Inputs": "Incorrectly predicted examples, current hypothesis pool.",
      "Outputs": "New or refined hypotheses with updated rewards.",
      "Example": "Wrong example bank triggers generation of new hypotheses to address gaps.",
      "Role in workflow": "Improves hypothesis quality by targeting unexplained data."
    },
    "Refinement via guided by computational-data": {
      "performed": "Yes",
      "Method details": "Refinement is guided by empirical performance (accuracy) on training and test data.",
      "Inputs": "Performance metrics from computational tests.",
      "Outputs": "Updated hypothesis pool with higher accuracy.",
      "Example": "Hypotheses with low reward are replaced after evaluation.",
      "Role in workflow": "Ensures only high-performing hypotheses are retained."
    },
    "Refinement via experimental validation": {
      "performed": "No"
    },
    "Refinement via Performance-metric": {
      "performed": "Yes",
      "Method details": "Performance metrics (accuracy) directly inform which hypotheses are kept or replaced.",
      "Inputs": "Accuracy scores from test execution.",
      "Outputs": "Selection of top-performing hypotheses.",
      "Example": "Top k hypotheses by reward are retained in the hypothesis bank.",
      "Role in workflow": "Drives iterative improvement of hypothesis pool."
    },
    "Refinement via Human–data integration": {
      "performed": "No"
    }
  },
  "paper_title": "Hypothesis Generation with Large Language Models",
  "authors": [
    "Yangqiaoyu",
    "Haokun",
    "Tejes",
    "Hongyuan",
    "Chenhao"
  ],
  "published": "2024",
  "link": "http://arxiv.org/abs/2404.04326"
}