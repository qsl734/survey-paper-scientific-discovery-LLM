{
  "Inputs to the workflow": {
    "performed": "Yes",
    "User provide high-level research direction or goal": {
      "performed": "Yes",
      "Format": "Definition of drug development tasks and stages (lead compound discovery, pre-clinic, clinic prediction)",
      "Example": "Y-Mol is designed to accomplish tasks across lead compound discovery, pre-clinic, and clinic prediction.",
      "Role in workflow": "Sets the overall scope and objectives for the LLM paradigm and downstream tasks."
    },
    "User provide structured, domain-specific specifications": {
      "performed": "Yes",
      "Format": "Task-specific prompts and constraints (e.g., molecular properties, drug-likeness, toxicity)",
      "Example": "Given target GSH-S design an active molecule with good safety...",
      "Role in workflow": "Guides LLM to generate or predict molecules with specified properties or constraints."
    },
    "User provide research papers": {
      "performed": "Yes",
      "Format": "Biomedical publications (abstracts, introductions) from PubMed and other sources",
      "Example": "We extract and preprocess over 33 million publications across multiple topics from online publishers (e.g., PubMed).",
      "Role in workflow": "Serves as the primary corpus for pretraining and knowledge extraction."
    },
    "User provide datasets other than research papers": {
      "performed": "Yes",
      "Format": "Drug databases (DrugBank, DrugCentral), knowledge graphs (Hetionet, DRKG), expert model outputs (ADMETlab, RDKit, TDC, DrugBAN)",
      "Example": "We extract molecule-text pairs from DrugBank... context of specific facts as queries from biomedical knowledge graphs Hetionet and DRKG.",
      "Role in workflow": "Provides structured data for instruction tuning and downstream evaluation."
    },
    "User provide representations or formal inputs": {
      "performed": "Yes",
      "Format": "SMILES strings for molecules, entity tables, property lists",
      "Example": "We adopt their SMILES sequence for drug entities to replace entity text...",
      "Role in workflow": "Enables LLM to reason over molecular structures and properties."
    }
  },
  "Query Structuring": {
    "performed": "Yes",
    "Query Decomposition": {
      "performed": "Yes",
      "Method details": "Instruction templates decompose tasks into question-answer pairs (e.g., property prediction, DTI, DDI).",
      "Inputs": "Task descriptions, molecule/target pairs, property constraints",
      "Outputs": "Structured prompts and queries for LLM",
      "Example": "Please describe the molecule: dsmiles.",
      "Role in workflow": "Transforms high-level tasks into actionable LLM queries."
    },
    "Structural or Entity Decomposition": {
      "performed": "Yes",
      "Method details": "Named entity recognition (NER) and entity matching extract and standardize drug, gene, disease entities.",
      "Inputs": "Biomedical texts, molecule descriptions",
      "Outputs": "Standardized entities (SMILES, gene names, disease terms)",
      "Example": "We introduce a named entity recognition (NER) tool... to match entities and use a standard biomedical PubTator.",
      "Role in workflow": "Aligns and normalizes entities for downstream reasoning and retrieval."
    },
    "Workflow Decomposition": {
      "performed": "No"
    },
    "Textual or Knowledge Embedding": {
      "performed": "Yes",
      "Method details": "Self-supervised pretraining on biomedical text corpus for next-token prediction; prompts converted to natural language.",
      "Inputs": "Biomedical publications, knowledge graph facts, synthetic data",
      "Outputs": "Contextual embeddings for LLM reasoning",
      "Example": "Self-supervised pretrain LLaMA2 based on biomedical publications...",
      "Role in workflow": "Enables semantic understanding and context-aware reasoning."
    },
    "Molecular or Chemical Embedding": {
      "performed": "Yes",
      "Method details": "SMILES sequences used as molecular representations; property extraction via tools (e.g., RDKit).",
      "Inputs": "SMILES strings, molecular structures",
      "Outputs": "Encoded molecular representations for LLM input",
      "Example": "We adopt their SMILES sequence for drug entities...",
      "Role in workflow": "Facilitates molecular property prediction and molecule generation."
    },
    "Biological or Phenotypic Embedding": {
      "performed": "No"
    },
    "Pattern and Feature Extraction": {
      "performed": "Yes",
      "Method details": "Extraction of molecular properties (QED, SAs, LogP, toxicity, etc.) using expert models and analytic tools.",
      "Inputs": "Molecular datasets, expert model outputs",
      "Outputs": "Feature vectors and property lists for molecules",
      "Example": "We collected a series of molecular tools... to extract molecules with diverse properties...",
      "Role in workflow": "Provides empirical features for property prediction and instruction construction."
    },
    "Biological Relationship Extraction": {
      "performed": "Yes",
      "Method details": "Extraction of drug-target, drug-disease, gene-disease relationships from knowledge graphs.",
      "Inputs": "Biomedical KGs (Hetionet, DRKG)",
      "Outputs": "Structured relationship triples and reasoning chains",
      "Example": "We prompt the facts included in the KGs as natural language... extract the enclosing subgraph surrounding the target link.",
      "Role in workflow": "Enables reasoning over biomedical interactions for DTI/DDI prediction."
    },
    "Property and Annotation Extraction": {
      "performed": "Yes",
      "Method details": "Extraction of molecular properties and annotations from expert models and databases.",
      "Inputs": "Expert model outputs, drug databases",
      "Outputs": "Property annotations (e.g., toxicity, LogP, QED)",
      "Example": "We collected a series of molecular tools... to extract molecules with diverse properties...",
      "Role in workflow": "Informs property prediction and multi-objective drug design."
    },
    "Sequence and Structure Feature Extraction": {
      "performed": "No"
    }
  },
  "Data Retrieval": {
    "performed": "Yes",
    "Data Retrieval via Multi-Query Generation and Exploration": {
      "performed": "No"
    },
    "Literature and Data Retrieval via APIs": {
      "performed": "Yes",
      "Method details": "Biomedical publications retrieved from PubMed; drug data from DrugBank, DrugCentral; KGs from Hetionet, DRKG.",
      "Inputs": "API queries to PubMed, DrugBank, DrugCentral, Hetionet, DRKG",
      "Outputs": "Large-scale biomedical corpus and structured datasets",
      "Example": "We extract and preprocess over 33 million publications... from online publishers (e.g., PubMed).",
      "Role in workflow": "Provides foundational data for pretraining and instruction tuning."
    },
    "Data Retrieval with Prioritization and Filtering Agents": {
      "performed": "No"
    },
    "Domain-Specific Data Retrieval and Reasoning": {
      "performed": "Yes",
      "Method details": "Retrieval of drug-related facts and relationships from biomedical KGs for instruction construction.",
      "Inputs": "Knowledge graphs (Hetionet, DRKG)",
      "Outputs": "Contextual facts and reasoning chains for LLM prompts",
      "Example": "We prompt the facts included in the KGs as natural language...",
      "Role in workflow": "Enables context-rich instruction generation for LLM fine-tuning."
    },
    "Code-Driven or Tool-Augmented Data Retrieval": {
      "performed": "Yes",
      "Method details": "Use of computational tools (ADMETlab, RDKit, TDC, DrugBAN) to generate property data for molecules.",
      "Inputs": "Molecular datasets, tool APIs",
      "Outputs": "Predicted molecular properties and features",
      "Example": "We collected a series of molecular tools and advanced models... to extract molecules with diverse properties...",
      "Role in workflow": "Augments dataset with expert model predictions for instruction construction."
    },
    "Literature data Retrieval Citation-Networkâ€“Based Expansion": {
      "performed": "No"
    },
    "Literature data Retrieval via Semantic and Similarity-Based analysis": {
      "performed": "No"
    },
    "Literature data Retrieval via Multi-Step Reference and Evidence Selection": {
      "performed": "No"
    },
    "Domain-Specific Literature data Retrieval": {
      "performed": "Yes",
      "Method details": "Selection of publications from chemistry, bioinformatics, and computer science domains.",
      "Inputs": "Domain-specific keywords and topics",
      "Outputs": "Curated biomedical text corpus",
      "Example": "We select publications within the areas of Chemistry, Computer Science, and Bioinformatics.",
      "Role in workflow": "Ensures relevance and coverage of pretraining data."
    },
    "Manual and Semi-Automatic Curation of Literature data": {
      "performed": "No"
    },
    "Structural or Similarity-Based Dataset Retrieval": {
      "performed": "No"
    },
    "Data Retrieval via Domain-Specific Repository Querying": {
      "performed": "Yes",
      "Method details": "Direct querying of repositories like PubMed, DrugBank, DrugCentral, Hetionet, DRKG.",
      "Inputs": "Repository queries",
      "Outputs": "Biomedical texts, drug data, knowledge graph triples",
      "Example": "We extract and preprocess over 33 million publications... from online publishers (e.g., PubMed).",
      "Role in workflow": "Provides large-scale, domain-relevant data for model training."
    },
    "Library Assembly and Data Augmentation": {
      "performed": "Yes",
      "Method details": "Combining publications, knowledge graphs, and expert model outputs to build a comprehensive instruction dataset.",
      "Inputs": "Biomedical texts, KGs, expert model predictions",
      "Outputs": "Unified instruction dataset (~2.3M instructions)",
      "Example": "We construct an informative instruction dataset... by collecting the corpus of publications, domain knowledge graph, and synthesized data from small models.",
      "Role in workflow": "Expands data diversity and supports robust model training."
    }
  },
  "Knowledge Assembly": {
    "performed": "Yes",
    "Standardized Section Extraction from Literature data": {
      "performed": "Yes",
      "Method details": "Extraction of abstracts and brief introductions from publications; NER for entity standardization.",
      "Inputs": "Full-text publications",
      "Outputs": "Standardized biomedical texts with entity normalization",
      "Example": "We extract their visible abstracts and brief introductions as biomedical texts...",
      "Role in workflow": "Normalizes input data for pretraining and entity alignment."
    },
    "Concise Synopsis and Summarization of Literature data": {
      "performed": "No"
    },
    "Facet-Based or Field-Specific Extraction from Literature data": {
      "performed": "No"
    },
    "Domain-Tailored Extraction from Literature data": {
      "performed": "Yes",
      "Method details": "Extraction of drug descriptions, mechanisms, and therapeutic effects from DrugBank and other databases.",
      "Inputs": "Drug databases, publications",
      "Outputs": "Domain-specific instruction pairs (e.g., molecule-text, property-text)",
      "Example": "The descriptions from DrugBank contain drug-related background knowledge such as symptom-specific therapeutic effects...",
      "Role in workflow": "Provides domain-relevant context for instruction tuning."
    },
    "Task/Entity-Centric Knowledge Graphs": {
      "performed": "Yes",
      "Method details": "Construction and use of biomedical KGs (Hetionet, DRKG) representing drugs, genes, diseases, and their relations.",
      "Inputs": "Knowledge graph data",
      "Outputs": "Structured graphs for instruction generation and reasoning",
      "Example": "We define a biomedical knowledge graph (KG)... where each triple (h, r, t) denotes a relation r between biomedical entities h and t.",
      "Role in workflow": "Enables structured reasoning and relationship extraction."
    },
    "Causal or Relation-Specific Knowledge Graphs": {
      "performed": "Yes",
      "Method details": "Extraction of reasoning chains and relational paths (e.g., drug inhibits gene, gene regulates disease) from KGs.",
      "Inputs": "Knowledge graph subgraphs",
      "Outputs": "Natural language prompts encoding causal/relation chains",
      "Example": "We extract each path from the enclosing subgraph of the target link and generate a natural language description...",
      "Role in workflow": "Supports context-rich, relation-aware instruction construction."
    },
    "Biomedical or Domain-Specific Interaction Graphs": {
      "performed": "Yes",
      "Method details": "Modeling of drug-target, drug-disease, and drug-drug interactions in KGs.",
      "Inputs": "Biomedical KGs",
      "Outputs": "Interaction graphs for DTI/DDI prediction tasks",
      "Example": "Biomedical KGs contain large-scale interactions between various entities...",
      "Role in workflow": "Enables interaction prediction and reasoning."
    },
    "Literature Database Construction": {
      "performed": "No"
    },
    "Entity- or Co-Occurrenceâ€“Based Databases": {
      "performed": "No"
    },
    "Reasoning-Chain or Temporal Databases for Literature": {
      "performed": "Yes",
      "Method details": "Construction of reasoning chains from KGs for use as context in instruction prompts.",
      "Inputs": "Knowledge graph subgraphs",
      "Outputs": "Contextual reasoning chains in natural language",
      "Example": "We extract the enclosing subgraph... as the context. After obtaining the enclosing subgraphs... we prompt them using the pre-designed templates.",
      "Role in workflow": "Provides multi-hop relational context for LLM fine-tuning."
    }
  },
  "Hypothesis/Idea Generation": {
    "performed": "Yes",
    "Idea/hypothesis generation without additional literature or dataset as context": {
      "performed": "No"
    },
    "LLM Agent Generate ideas/hypotheses via Task Decomposition": {
      "performed": "No"
    },
    "Generate ideas/hypotheses using Domain-Specialized LLM Agent": {
      "performed": "Yes",
      "Method details": "Y-Mol (LLaMA2-based) generates drug candidates, predicts properties, and infers interactions using domain-specific instructions.",
      "Inputs": "Structured prompts, molecular/target data, property constraints",
      "Outputs": "Generated molecules, predicted properties, DTI/DDI predictions",
      "Example": "Y-Mol generates a target molecule with SMILES sequence from the context of the query.",
      "Role in workflow": "Produces candidate drugs and predictions tailored to biomedical tasks."
    },
    "Literature data used during idea/hypothesis generation as context": {
      "performed": "Yes",
      "Method details": "Biomedical corpus and KG-derived facts are used as context in instruction prompts for LLM generation.",
      "Inputs": "Biomedical texts, KG reasoning chains",
      "Outputs": "Contextualized LLM outputs (molecule generation, property prediction)",
      "Example": "The constructed contexts combined with the corresponding question are input into Y-Mol...",
      "Role in workflow": "Grounds LLM outputs in domain knowledge and evidence."
    },
    "Summarization Literature data used during idea/hypothesis generation": {
      "performed": "No"
    },
    "Idea/hypothesis generation via Facet Recombination": {
      "performed": "No"
    },
    "Idea/hypothesis generation via contructed Reasoning-Chain from literature": {
      "performed": "Yes",
      "Method details": "Reasoning chains from KGs are converted to natural language and used as context for LLM predictions.",
      "Inputs": "KG subgraphs, reasoning paths",
      "Outputs": "Contextual prompts for DTI/DDI prediction",
      "Example": "We extract each path from the enclosing subgraph... and generate a natural language description as follows.",
      "Role in workflow": "Supports evidence-based prediction and hypothesis generation."
    },
    "Idea/hypothesis generation via Knowledge Graph developed from literature": {
      "performed": "Yes",
      "Method details": "KGs are used to generate instruction data and as context for LLM-based link prediction (e.g., DTI, DDI).",
      "Inputs": "Biomedical KGs",
      "Outputs": "Predicted interactions, property values",
      "Example": "We prompt the facts included in the KGs as natural language...",
      "Role in workflow": "Enables hypothesis generation via structured knowledge."
    },
    "Idea/hypothesis generation via Pattern Detection from dataset": {
      "performed": "Yes",
      "Method details": "Expert models extract molecular property patterns, which are distilled into LLM instructions.",
      "Inputs": "Expert model outputs, molecular datasets",
      "Outputs": "Property-based instruction pairs",
      "Example": "We collected a series of molecular tools... to extract molecules with diverse properties...",
      "Role in workflow": "Informs property-driven molecule generation and prediction."
    },
    "Idea/hypothesis generation via Few-Shot Data Seeding": {
      "performed": "No"
    },
    "Idea/hypothesis generation using Observational data": {
      "performed": "No"
    },
    "Idea/hypothesis generation via Feature-Driven Property Prediction": {
      "performed": "Yes",
      "Method details": "LLM predicts molecular properties based on extracted features and property constraints.",
      "Inputs": "Molecular features, property constraints",
      "Outputs": "Predicted property values",
      "Example": "Given a molecule and the property to be predicted, we construct a query... to ask Y-Mol the possible answers.",
      "Role in workflow": "Supports property prediction and multi-objective drug design."
    },
    "Idea/hypothesis generation after Fine-Tuning the LLM model": {
      "performed": "Yes",
      "Method details": "Y-Mol is fine-tuned on domain-specific instructions and then used to generate molecules and predictions.",
      "Inputs": "Finetuned LLM, instruction dataset",
      "Outputs": "Generated molecules, property predictions, DTI/DDI outputs",
      "Example": "After finetuning Y-Mol based on constructed instructions, we employ it in downstream tasks...",
      "Role in workflow": "Enables domain-adapted hypothesis generation and prediction."
    }
  },
  "Hypothesis/Idea Prioritization": {
    "performed": "Yes",
    "LLM-based Hypothesis/Idea evaluation via Scientific Quality": {
      "performed": "No"
    },
    "LLM-based Hypothesis/Idea evaluation via Domain-Specific Evaluation": {
      "performed": "Yes",
      "Method details": "LLM outputs are evaluated using domain-specific metrics (ROC-AUC for DTI/DDI, R2 for property prediction, Valid/Unique/Novelty/Diversity for drug design).",
      "Inputs": "LLM-generated outputs, ground-truth datasets",
      "Outputs": "Performance scores (AUC, R2, etc.)",
      "Example": "We adopt the receiver operating characteristic curve (ROC-AUC) to evaluate Y-Mol...",
      "Role in workflow": "Assesses the quality and relevance of generated hypotheses and predictions."
    },
    "LLM-based Hypothesis/Idea evaluation via Contextual Evidence Scoring": {
      "performed": "Yes",
      "Method details": "LLM uses context from KGs and literature to justify predictions; evidence is provided in case studies.",
      "Inputs": "Contextual facts, LLM predictions",
      "Outputs": "Evidence-backed answers",
      "Example": "Evidence: https://www.accessdata.fda.gov/drugsatfda_docs/label/2020/206966lbl.pdf",
      "Role in workflow": "Supports interpretability and evidence-based evaluation."
    },
    "LLM-based Hypothesis/Idea evaluation via Interpretability or Success Metrics": {
      "performed": "Yes",
      "Method details": "Drug design outputs are evaluated for validity, uniqueness, novelty, and diversity using RDKit and Tanimoto distance.",
      "Inputs": "Generated molecules",
      "Outputs": "Interpretability metrics (Valid, Unique, Novelty, Diversity)",
      "Example": "Valid assesses whether the generated drugs conform to the syntax rules of SMILES...",
      "Role in workflow": "Ensures generated molecules are meaningful and diverse."
    },
    "Hypothesis/Idea evaluation via Novelty Checking with Literature Comparison": {
      "performed": "Yes",
      "Method details": "Novelty metric checks if generated molecules are present in the training dataset.",
      "Inputs": "Generated molecules, training dataset",
      "Outputs": "Novelty scores",
      "Example": "Novelty signifies whether the generated drugs are previously unseen in the training dataset...",
      "Role in workflow": "Prevents duplication and promotes innovation."
    },
    "Hypothesis/Idea evaluation via Alignment with Literature Chains": {
      "performed": "No"
    },
    "Hypothesis/Idea evaluation via Knowledge-Graph Grounded Similarity Metrics": {
      "performed": "No"
    },
    "Hypothesis/Idea evaluation via Quantitative Assessment Using Domain Metrics": {
      "performed": "Yes",
      "Method details": "Performance on DTI/DDI prediction and property prediction is quantitatively assessed using ROC-AUC and R2.",
      "Inputs": "LLM predictions, ground-truth labels",
      "Outputs": "Quantitative performance metrics",
      "Example": "Our proposed Y-Mol outperforms LLaMA2 with an improvement of 5.02% and 4.13% on the AUC score...",
      "Role in workflow": "Objectively measures predictive accuracy."
    },
    "Hypothesis/Idea evaluation via Human/Expert": {
      "performed": "No"
    }
  },
  "Test": {
    "performed": "Yes",
    "Experimental Design Generation via literature-Grounded Model/Protocol Selection": {
      "performed": "No"
    },
    "Experimental Design Generation via Literature Synthesis for New Protocol Generation": {
      "performed": "No"
    },
    "Experimental Design Generation via Few-Shot or Example-Based Prompting": {
      "performed": "No"
    },
    "Experimental Design Generation via Executable Code Generation from Literature": {
      "performed": "No"
    },
    "LLM-Based Experimental Design Generation via Agentic Exploration and Planning": {
      "performed": "No"
    },
    "LLM-Based Experimental Design Generation via Code and Workflow Translation": {
      "performed": "No"
    },
    "LLM-Based Experimental Design Generation via Multi-Agent Planning with Specialized Roles": {
      "performed": "No"
    },
    "LLM-Based Experimental Design Generation via Domain-Specific Experimental Mapping": {
      "performed": "No"
    },
    "Test Execution via Human-in-the-Loop": {
      "performed": "No"
    },
    "Test Execution via Automated Wet-Lab Execution": {
      "performed": "No"
    },
    "Test Execution via Computational or In-Silico": {
      "performed": "Yes",
      "Method details": "LLM-generated molecules, property predictions, and DTI/DDI outputs are evaluated against benchmark datasets in silico.",
      "Inputs": "Generated outputs, benchmark datasets (DrugBank, DrugCentral, Ryuâ€™s, Dengâ€™s, etc.)",
      "Outputs": "Performance metrics (AUC, R2, Validity, etc.)",
      "Example": "We split DTIs and DDIs in each dataset into training and test sets with a ratio of 9:1...",
      "Role in workflow": "Validates LLM predictions and molecule designs computationally."
    },
    "Refinement via LLM Agent Feedback Loops": {
      "performed": "No"
    },
    "Refinement via Automated Quality Evaluation using Model-Based Critics": {
      "performed": "Yes",
      "Method details": "Generated molecules are evaluated for validity, uniqueness, novelty, and diversity using RDKit and Tanimoto distance.",
      "Inputs": "Generated molecules",
      "Outputs": "Quality metrics for refinement",
      "Example": "We adopt the RDKit to parse the designed drugs, determining if the parsing process was successful.",
      "Role in workflow": "Ensures only high-quality molecules are considered."
    },
    "Refinement via Dynamic Agent Updating Based on Evolving Context or Data": {
      "performed": "No"
    },
    "Refinement via guided by computational-data": {
      "performed": "Yes",
      "Method details": "Performance metrics from computational tests guide further model evaluation and reporting.",
      "Inputs": "Test results (AUC, R2, etc.)",
      "Outputs": "Refined evaluation and reporting",
      "Example": "The results highlight the value of constructed drug instructions and demonstrate the ability of Y-Mol...",
      "Role in workflow": "Improves model and output quality based on computational feedback."
    },
    "Refinement via experimental validation": {
      "performed": "No"
    },
    "Refinement via Performance-metric": {
      "performed": "Yes",
      "Method details": "Metrics such as Valid, Unique, Novelty, Diversity, AUC, and R2 are used to refine and assess outputs.",
      "Inputs": "Performance metrics from test phase",
      "Outputs": "Refined outputs and model selection",
      "Example": "We utilize R-square (R2) to assess the prediction capability of Y-Mol...",
      "Role in workflow": "Guides selection of best-performing models and outputs."
    },
    "Refinement via Humanâ€“data integration": {
      "performed": "No"
    }
  },
  "paper_title": "Y-Mol: A Multiscale Biomedical Knowledge-Guided Large Language Model for Drug Development",
  "authors": [
    "Tengfei",
    "Xuan",
    "Tianle",
    "Chaoyi",
    "Long",
    "Peng",
    "Xibao",
    "Xinyu",
    "Daojian",
    "Dongsheng",
    "Xiangxiang"
  ],
  "published": "2024-10-15",
  "link": "http://arxiv.org/abs/2410.11550"
}