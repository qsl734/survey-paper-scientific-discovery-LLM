{
  "Inputs to the workflow": {
    "performed": "Yes",
    "User provide high-level research direction or goal": {
      "performed": "Yes",
      "Format": "Natural language prompt describing requirements or prior knowledge for formula discovery.",
      "Example": "Please output an expression that does not include 'exp' to fit the observed data.",
      "Role in workflow": "Guides the symbolic regression model to generate expressions matching user-specified constraints."
    },
    "User provide structured, domain-specific specifications": {
      "performed": "Yes",
      "Format": "Natural language instructions specifying mathematical properties or required symbols.",
      "Example": "I want an expression with periodicity on the variable x to fit the above data.",
      "Role in workflow": "Constrains the search space for formula generation to match domain-specific requirements."
    },
    "User provide research papers": {
      "performed": "No"
    },
    "User provide datasets other than research papers": {
      "performed": "Yes",
      "Format": "Tabular observational data pairs [X, y]",
      "Example": "[X, y] where X is input variables and y is output values.",
      "Role in workflow": "Provides the empirical basis for symbolic regression and formula discovery."
    },
    "User provide representations or formal inputs": {
      "performed": "Yes",
      "Format": "Preorder traversal sequences of mathematical expressions; symbol lists.",
      "Example": "[*, C, sin, x]",
      "Role in workflow": "Used for training, evaluation, and as targets for model output."
    }
  },
  "Query Structuring": {
    "performed": "Yes",
    "Query Decomposition": {
      "performed": "No"
    },
    "Structural or Entity Decomposition": {
      "performed": "Yes",
      "Method details": "Mathematical expressions are represented as binary trees and decomposed via preorder traversal.",
      "Inputs": "Mathematical expressions (formulas).",
      "Outputs": "Sequences of symbols representing the expression structure.",
      "Example": "sin(2.6x) → [sin, *, C, x]",
      "Role in workflow": "Enables structured representation for model training and generation."
    },
    "Workflow Decomposition": {
      "performed": "No"
    },
    "Textual or Knowledge Embedding": {
      "performed": "Yes",
      "Method details": "SetTransformer encodes observational data into latent features; projection layer maps to LLM embedding space.",
      "Inputs": "[X, y] observational data.",
      "Outputs": "Latent data features compatible with LLM word embeddings.",
      "Example": "SetTransformer output mapped to Vicuna embedding space.",
      "Role in workflow": "Aligns data modality with language model for multimodal input processing."
    },
    "Molecular or Chemical Embedding": {
      "performed": "No"
    },
    "Biological or Phenotypic Embedding": {
      "performed": "No"
    },
    "Pattern and Feature Extraction": {
      "performed": "Yes",
      "Method details": "Contrastive learning pre-trains SetTransformer to extract features from [X, y] and expression sequences.",
      "Inputs": "[X, y] pairs and corresponding expression sequences.",
      "Outputs": "Feature vectors representing data-expression relationships.",
      "Example": "Contrastive learning aligns data and expression features.",
      "Role in workflow": "Improves model's ability to relate data patterns to symbolic expressions."
    },
    "Biological Relationship Extraction": {
      "performed": "No"
    },
    "Property and Annotation Extraction": {
      "performed": "Yes",
      "Method details": "Properties such as periodicity, symmetry, monotonicity are annotated for each expression.",
      "Inputs": "Generated or synthetic expressions.",
      "Outputs": "Property annotations (e.g., periodic, monotonic).",
      "Example": "Expression y = sin(x) + cos(x) annotated as periodic.",
      "Role in workflow": "Enables property-aware prompt generation and evaluation."
    },
    "Sequence and Structure Feature Extraction": {
      "performed": "Yes",
      "Method details": "Preorder traversal of expression binary trees extracts structural features.",
      "Inputs": "Expression binary trees.",
      "Outputs": "Symbol sequences.",
      "Example": "sin(x) → [sin, x]",
      "Role in workflow": "Facilitates sequence-based model training and output."
    }
  },
  "Data Retrieval": {
    "performed": "Yes",
    "Data Retrieval via Multi-Query Generation and Exploration": {
      "performed": "No"
    },
    "Literature and Data Retrieval via APIs": {
      "performed": "No"
    },
    "Data Retrieval with Prioritization and Filtering Agents": {
      "performed": "No"
    },
    "Domain-Specific Data Retrieval and Reasoning": {
      "performed": "No"
    },
    "Code-Driven or Tool-Augmented Data Retrieval": {
      "performed": "No"
    },
    "Literature data Retrieval Citation-Network–Based Expansion": {
      "performed": "No"
    },
    "Literature data Retrieval via Semantic and Similarity-Based analysis": {
      "performed": "No"
    },
    "Literature data Retrieval via Multi-Step Reference and Evidence Selection": {
      "performed": "No"
    },
    "Domain-Specific Literature data Retrieval": {
      "performed": "No"
    },
    "Manual and Semi-Automatic Curation of Literature data": {
      "performed": "No"
    },
    "Structural or Similarity-Based Dataset Retrieval": {
      "performed": "Yes",
      "Method details": "Synthetic datasets are generated by sampling input variables and computing outputs from known expressions.",
      "Inputs": "Expression forms and variable ranges.",
      "Outputs": "Tabular datasets [X, y] for training and evaluation.",
      "Example": "U(-1,1,20) samples for x in Nguyen datasets.",
      "Role in workflow": "Provides diverse data for robust model training and benchmarking."
    },
    "Data Retrieval via Domain-Specific Repository Querying": {
      "performed": "No"
    },
    "Library Assembly and Data Augmentation": {
      "performed": "Yes",
      "Method details": "Large-scale synthetic data generation: 5M expressions, 30M Q&A pairs.",
      "Inputs": "Randomly generated expressions and sampled data.",
      "Outputs": "Extensive training dataset for multimodal model.",
      "Example": "5M expressions × multiple Q&A per expression.",
      "Role in workflow": "Enables large-scale pretraining and instruction tuning."
    }
  },
  "Knowledge Assembly": {
    "performed": "Yes",
    "Standardized Section Extraction from Literature data": {
      "performed": "No"
    },
    "Concise Synopsis and Summarization of Literature data": {
      "performed": "No"
    },
    "Facet-Based or Field-Specific Extraction from Literature data": {
      "performed": "Yes",
      "Method details": "For each expression, properties (periodicity, symmetry, etc.), symbol content, and sequence length are extracted.",
      "Inputs": "Generated expressions.",
      "Outputs": "Structured metadata for Q&A generation.",
      "Example": "Expression y = sin(x): properties = periodic, symbols = [sin, x], length = 2.",
      "Role in workflow": "Supports property-aware prompt and dataset construction."
    },
    "Domain-Tailored Extraction from Literature data": {
      "performed": "Yes",
      "Method details": "Q&A pairs are generated with domain-specific prompts (e.g., 'generate a periodic expression').",
      "Inputs": "Expression metadata and properties.",
      "Outputs": "Instructional Q&A pairs for model training.",
      "Example": "Prompt: 'Generate an expression with periodicity.'",
      "Role in workflow": "Enables natural language guidance for symbolic regression."
    },
    "Task/Entity-Centric Knowledge Graphs": {
      "performed": "No"
    },
    "Causal or Relation-Specific Knowledge Graphs": {
      "performed": "No"
    },
    "Biomedical or Domain-Specific Interaction Graphs": {
      "performed": "No"
    },
    "Literature Database Construction": {
      "performed": "No"
    },
    "Entity- or Co-Occurrence–Based Databases": {
      "performed": "No"
    },
    "Reasoning-Chain or Temporal Databases for Literature": {
      "performed": "No"
    }
  },
  "Hypothesis/Idea Generation": {
    "performed": "Yes",
    "Idea/hypothesis generation without additional literature or dataset as context": {
      "performed": "No"
    },
    "LLM Agent Generate ideas/hypotheses via Task Decomposition": {
      "performed": "No"
    },
    "Generate ideas/hypotheses using Domain-Specialized LLM Agent": {
      "performed": "Yes",
      "Method details": "ChatSR (multimodal LLM) generates symbolic expressions conditioned on data and natural language prompts.",
      "Inputs": "[X, y] data and user instructions.",
      "Outputs": "Mathematical expressions fitting the data and constraints.",
      "Example": "Assistant: The expression I generated is [+, sin, x, cos, x].",
      "Role in workflow": "Automates formula discovery with domain-aware LLM."
    },
    "Literature data used during idea/hypothesis generation as context": {
      "performed": "No"
    },
    "Summarization Literature data used during idea/hypothesis generation": {
      "performed": "No"
    },
    "Idea/hypothesis generation via Facet Recombination": {
      "performed": "No"
    },
    "Idea/hypothesis generation via contructed Reasoning-Chain from literature": {
      "performed": "No"
    },
    "Idea/hypothesis generation via Knowledge Graph developed from literature": {
      "performed": "No"
    },
    "Idea/hypothesis generation via Pattern Detection from dataset": {
      "performed": "Yes",
      "Method details": "Model uses patterns in [X, y] to generate expressions matching data trends.",
      "Inputs": "Observed data [X, y].",
      "Outputs": "Symbolic expressions reflecting data patterns.",
      "Example": "Zero-shot tests for monotonicity, convexity, etc.",
      "Role in workflow": "Enables property-driven formula generation."
    },
    "Idea/hypothesis generation via Few-Shot Data Seeding": {
      "performed": "No"
    },
    "Idea/hypothesis generation using Observational data": {
      "performed": "Yes",
      "Method details": "Observed data [X, y] is the primary input for symbolic regression.",
      "Inputs": "[X, y] pairs.",
      "Outputs": "Fitted mathematical expressions.",
      "Example": "Given [X, y], generate y = sin(x) + 2.3x2.",
      "Role in workflow": "Grounds hypothesis generation in empirical data."
    },
    "Idea/hypothesis generation via Feature-Driven Property Prediction": {
      "performed": "No"
    },
    "Idea/hypothesis generation after Fine-Tuning the LLM model": {
      "performed": "Yes",
      "Method details": "LLM is instruction-tuned on large-scale synthetic Q&A pairs for symbolic regression.",
      "Inputs": "Synthetic Q&A pairs, [X, y], expression sequences.",
      "Outputs": "Fine-tuned multimodal LLM (ChatSR).",
      "Example": "Two-stage training: feature alignment, then end-to-end fine-tuning.",
      "Role in workflow": "Enables domain-specific formula generation."
    }
  },
  "Hypothesis/Idea Prioritization": {
    "performed": "Yes",
    "LLM-based Hypothesis/Idea evaluation via Scientific Quality": {
      "performed": "Yes",
      "Method details": "ChatSR leverages LLM knowledge to prefer concise, interpretable expressions.",
      "Inputs": "Candidate expressions.",
      "Outputs": "Selection of concise, high-quality formulas.",
      "Example": "ChatSR produces more concise expressions than baselines.",
      "Role in workflow": "Improves interpretability and scientific plausibility of outputs."
    },
    "LLM-based Hypothesis/Idea evaluation via Domain-Specific Evaluation": {
      "performed": "Yes",
      "Method details": "Expressions are evaluated for property compliance (e.g., periodicity, monotonicity) as specified in prompts.",
      "Inputs": "Generated expressions, property requirements.",
      "Outputs": "Success rate and recovery rate metrics.",
      "Example": "Success rate for monotonicity when prompted.",
      "Role in workflow": "Ensures generated formulas meet domain constraints."
    },
    "LLM-based Hypothesis/Idea evaluation via Contextual Evidence Scoring": {
      "performed": "No"
    },
    "LLM-based Hypothesis/Idea evaluation via Interpretability or Success Metrics": {
      "performed": "Yes",
      "Method details": "Evaluation metrics include R2 (fit quality), recovery rate (exactness), and expression complexity (nodes).",
      "Inputs": "Generated expressions and ground truth.",
      "Outputs": "Quantitative scores for each candidate.",
      "Example": "Table 1: R2, nodes, recovery rate.",
      "Role in workflow": "Quantifies model performance and interpretability."
    },
    "Hypothesis/Idea evaluation via Novelty Checking with Literature Comparison": {
      "performed": "No"
    },
    "Hypothesis/Idea evaluation via Alignment with Literature Chains": {
      "performed": "No"
    },
    "Hypothesis/Idea evaluation via Knowledge-Graph Grounded Similarity Metrics": {
      "performed": "No"
    },
    "Hypothesis/Idea evaluation via Quantitative Assessment Using Domain Metrics": {
      "performed": "Yes",
      "Method details": "R2, recovery rate, and node count are used to assess fit and complexity.",
      "Inputs": "Generated and true expressions, test datasets.",
      "Outputs": "Performance metrics.",
      "Example": "Average R2 across datasets.",
      "Role in workflow": "Objective evaluation of hypothesis quality."
    },
    "Hypothesis/Idea evaluation via Human/Expert": {
      "performed": "No"
    }
  },
  "Test": {
    "performed": "Yes",
    "Experimental Design Generation via literature-Grounded Model/Protocol Selection": {
      "performed": "No"
    },
    "Experimental Design Generation via Literature Synthesis for New Protocol Generation": {
      "performed": "No"
    },
    "Experimental Design Generation via Few-Shot or Example-Based Prompting": {
      "performed": "No"
    },
    "Experimental Design Generation via Executable Code Generation from Literature": {
      "performed": "No"
    },
    "LLM-Based Experimental Design Generation via Agentic Exploration and Planning": {
      "performed": "No"
    },
    "LLM-Based Experimental Design Generation via Code and Workflow Translation": {
      "performed": "No"
    },
    "LLM-Based Experimental Design Generation via Multi-Agent Planning with Specialized Roles": {
      "performed": "No"
    },
    "LLM-Based Experimental Design Generation via Domain-Specific Experimental Mapping": {
      "performed": "No"
    },
    "Test Execution via Human-in-the-Loop": {
      "performed": "No"
    },
    "Test Execution via Automated Wet-Lab Execution": {
      "performed": "No"
    },
    "Test Execution via Computational or In-Silico": {
      "performed": "Yes",
      "Method details": "Generated expressions are tested for fit against synthetic and benchmark datasets using R2 and recovery rate.",
      "Inputs": "Generated expressions, test datasets.",
      "Outputs": "Performance metrics (R2, recovery rate, node count).",
      "Example": "ChatSR tested on 13 datasets, AI Feynman dataset.",
      "Role in workflow": "Validates the quality and correctness of generated formulas."
    },
    "Refinement via LLM Agent Feedback Loops": {
      "performed": "No"
    },
    "Refinement via Automated Quality Evaluation using Model-Based Critics": {
      "performed": "No"
    },
    "Refinement via Dynamic Agent Updating Based on Evolving Context or Data": {
      "performed": "No"
    },
    "Refinement via guided by computational-data": {
      "performed": "Yes",
      "Method details": "Constants in expressions are optimized using BFGS or similar numerical algorithms after symbolic structure is generated.",
      "Inputs": "Expressions with constant placeholders, [X, y] data.",
      "Outputs": "Expressions with optimized constant values.",
      "Example": "BFGS optimizes C in y = C*sin(x).",
      "Role in workflow": "Improves numerical accuracy of generated formulas."
    },
    "Refinement via experimental validation": {
      "performed": "No"
    },
    "Refinement via Performance-metric": {
      "performed": "Yes",
      "Method details": "Model refinement is guided by R2 and recovery rate during evaluation.",
      "Inputs": "Performance metrics from test phase.",
      "Outputs": "Selection or adjustment of best-performing expressions.",
      "Example": "Expressions with higher R2 and lower node count are preferred.",
      "Role in workflow": "Ensures output quality and interpretability."
    },
    "Refinement via Human–data integration": {
      "performed": "No"
    }
  },
  "paper_title": "ChatSR: Multimodal Large Language Models for Scientific Formula Discovery",
  "authors": [
    "Yanjie",
    "Lina",
    "Weijun",
    "Min",
    "Jingyi",
    "Wenqiang",
    "Shu",
    "Yusong"
  ],
  "published": "2025-06-24",
  "link": "http://arxiv.org/abs/2406.05410"
}