{
  "Inputs to the workflow": {
    "performed": "Yes",
    "User provide high-level research direction or goal": {
      "performed": "Yes",
      "Format": "Task definition and motivation in abductive reasoning over knowledge graphs, with focus on controllability.",
      "Example": "Introduce the task of controllable abductive reasoning to generate logical hypotheses from observed entities.",
      "Role in workflow": "Defines the overall research objective and scope for the system."
    },
    "User provide structured, domain-specific specifications": {
      "performed": "Yes",
      "Format": "Control conditions specifying semantic focus (entity/relation) or structural constraints (pattern, entity/relation number).",
      "Example": "Control condition C: e.g., specific entity, relation, logical pattern, number of entities/relations.",
      "Role in workflow": "Guides the hypothesis generation process to adhere to user-specified constraints."
    },
    "User provide research papers": {
      "performed": "No"
    },
    "User provide datasets other than research papers": {
      "performed": "Yes",
      "Format": "Knowledge graph datasets: DBpedia50, WN18RR, FB15k-237.",
      "Example": "FB15k-237 dataset split into train/validation/test for experiments.",
      "Role in workflow": "Provides the factual basis and structure for hypothesis generation and evaluation."
    },
    "User provide representations or formal inputs": {
      "performed": "Yes",
      "Format": "Entities and relations represented by IDs; logical patterns in Lisp-like language.",
      "Example": "Hypotheses and observations encoded as sequences of entity/relation IDs and logical operators.",
      "Role in workflow": "Ensures machine-readable, leakage-free input for model training and inference."
    }
  },
  "Query Structuring": {
    "performed": "Yes",
    "Query Decomposition": {
      "performed": "No"
    },
    "Structural or Entity Decomposition": {
      "performed": "Yes",
      "Method details": "Sub-logical decomposition: complex logical hypotheses are recursively broken into sub-hypotheses based on identifiable sub-patterns.",
      "Inputs": "Complex hypothesis–observation pairs from knowledge graphs.",
      "Outputs": "Augmented dataset of sub-hypothesis–sub-observation pairs.",
      "Example": "A pattern 'inp' decomposed into two '2p' sub-patterns.",
      "Role in workflow": "Expands training data and enables the model to learn complex logical structures from simpler components."
    },
    "Workflow Decomposition": {
      "performed": "No"
    },
    "Textual or Knowledge Embedding": {
      "performed": "No"
    },
    "Molecular or Chemical Embedding": {
      "performed": "No"
    },
    "Biological or Phenotypic Embedding": {
      "performed": "No"
    },
    "Pattern and Feature Extraction": {
      "performed": "No"
    },
    "Biological Relationship Extraction": {
      "performed": "No"
    },
    "Property and Annotation Extraction": {
      "performed": "No"
    },
    "Sequence and Structure Feature Extraction": {
      "performed": "No"
    }
  },
  "Data Retrieval": {
    "performed": "Yes",
    "Data Retrieval via Multi-Query Generation and Exploration": {
      "performed": "No"
    },
    "Literature and Data Retrieval via APIs": {
      "performed": "No"
    },
    "Data Retrieval with Prioritization and Filtering Agents": {
      "performed": "No"
    },
    "Domain-Specific Data Retrieval and Reasoning": {
      "performed": "Yes",
      "Method details": "Sampling of observation–hypothesis pairs from knowledge graphs using predefined logical patterns.",
      "Inputs": "Knowledge graph datasets (DBpedia50, WN18RR, FB15k-237).",
      "Outputs": "Observation–hypothesis pairs for model training.",
      "Example": "Randomly sample pairs by constructing hypotheses with logical patterns and extracting their conclusions as observations.",
      "Role in workflow": "Provides structured training and evaluation data tailored to the abductive reasoning task."
    },
    "Code-Driven or Tool-Augmented Data Retrieval": {
      "performed": "No"
    },
    "Literature data Retrieval Citation-Network–Based Expansion": {
      "performed": "No"
    },
    "Literature data Retrieval via Semantic and Similarity-Based analysis": {
      "performed": "No"
    },
    "Literature data Retrieval via Multi-Step Reference and Evidence Selection": {
      "performed": "No"
    },
    "Domain-Specific Literature data Retrieval": {
      "performed": "No"
    },
    "Manual and Semi-Automatic Curation of Literature data": {
      "performed": "No"
    },
    "Structural or Similarity-Based Dataset Retrieval": {
      "performed": "No"
    },
    "Data Retrieval via Domain-Specific Repository Querying": {
      "performed": "No"
    },
    "Library Assembly and Data Augmentation": {
      "performed": "Yes",
      "Method details": "Dataset augmentation via sub-logical decomposition to expand the hypothesis space.",
      "Inputs": "Original observation–hypothesis pairs.",
      "Outputs": "Augmented set of pairs including sub-hypotheses.",
      "Example": "Decomposing complex patterns to generate additional training examples.",
      "Role in workflow": "Mitigates hypothesis space collapse and improves model learning for complex logic."
    }
  },
  "Knowledge Assembly": {
    "performed": "Yes",
    "Standardized Section Extraction from Literature data": {
      "performed": "No"
    },
    "Concise Synopsis and Summarization of Literature data": {
      "performed": "No"
    },
    "Facet-Based or Field-Specific Extraction from Literature data": {
      "performed": "No"
    },
    "Domain-Tailored Extraction from Literature data": {
      "performed": "No"
    },
    "Task/Entity-Centric Knowledge Graphs": {
      "performed": "Yes",
      "Method details": "Use of knowledge graphs (DBpedia50, WN18RR, FB15k-237) where entities and relations are nodes and edges.",
      "Inputs": "Domain-specific knowledge graph datasets.",
      "Outputs": "Structured representation of entities and relations for reasoning.",
      "Example": "Entities and relations from FB15k-237 encoded as graph structure.",
      "Role in workflow": "Provides the structured environment for abductive reasoning and hypothesis generation."
    },
    "Causal or Relation-Specific Knowledge Graphs": {
      "performed": "No"
    },
    "Biomedical or Domain-Specific Interaction Graphs": {
      "performed": "No"
    },
    "Literature Database Construction": {
      "performed": "No"
    },
    "Entity- or Co-Occurrence–Based Databases": {
      "performed": "No"
    },
    "Reasoning-Chain or Temporal Databases for Literature": {
      "performed": "No"
    }
  },
  "Hypothesis/Idea Generation": {
    "performed": "Yes",
    "Idea/hypothesis generation without additional literature or dataset as context": {
      "performed": "No"
    },
    "LLM Agent Generate ideas/hypotheses via Task Decomposition": {
      "performed": "No"
    },
    "Generate ideas/hypotheses using Domain-Specialized LLM Agent": {
      "performed": "No"
    },
    "Literature data used during idea/hypothesis generation as context": {
      "performed": "No"
    },
    "Summarization Literature data used during idea/hypothesis generation": {
      "performed": "No"
    },
    "Idea/hypothesis generation via Facet Recombination": {
      "performed": "No"
    },
    "Idea/hypothesis generation via contructed Reasoning-Chain from literature": {
      "performed": "No"
    },
    "Idea/hypothesis generation via Knowledge Graph developed from literature": {
      "performed": "Yes",
      "Method details": "A GPT-2–based generative model produces logical hypotheses over knowledge graphs, conditioned on observations and control constraints.",
      "Inputs": "Observation–hypothesis pairs, control conditions, knowledge graph structure.",
      "Outputs": "Generated logical hypotheses explaining observations and adhering to constraints.",
      "Example": "Given observed entities and a control (e.g., specific relation), generate a logical hypothesis matching the observation.",
      "Role in workflow": "Synthesizes plausible, controllable hypotheses grounded in the knowledge graph."
    },
    "Idea/hypothesis generation via Pattern Detection from dataset": {
      "performed": "No"
    },
    "Idea/hypothesis generation via Few-Shot Data Seeding": {
      "performed": "No"
    },
    "Idea/hypothesis generation using Observational data": {
      "performed": "Yes",
      "Method details": "Model is trained on observation–hypothesis pairs, using observed entities as input to generate hypotheses.",
      "Inputs": "Observation sets (entities) from knowledge graphs.",
      "Outputs": "Hypotheses that explain the observations.",
      "Example": "Observation: {Blues, Jazz, Rhythm_and_blues, Bebop} → Hypothesis: Parent_genre(Hard_bop, V?).",
      "Role in workflow": "Grounds hypothesis generation in actual observed data from the knowledge graph."
    },
    "Idea/hypothesis generation via Feature-Driven Property Prediction": {
      "performed": "No"
    },
    "Idea/hypothesis generation after Fine-Tuning the LLM model": {
      "performed": "Yes",
      "Method details": "Two-stage training: supervised learning on augmented data, then reinforcement learning with semantic and adherence rewards.",
      "Inputs": "Augmented observation–hypothesis pairs, control conditions.",
      "Outputs": "Fine-tuned GPT-2 model for controllable hypothesis generation.",
      "Example": "Model fine-tuned to generate hypotheses matching both observation and control constraints.",
      "Role in workflow": "Improves hypothesis quality and controllability through domain-specific fine-tuning."
    }
  },
  "Hypothesis/Idea Prioritization": {
    "performed": "Yes",
    "LLM-based Hypothesis/Idea evaluation via Scientific Quality": {
      "performed": "No"
    },
    "LLM-based Hypothesis/Idea evaluation via Domain-Specific Evaluation": {
      "performed": "No"
    },
    "LLM-based Hypothesis/Idea evaluation via Contextual Evidence Scoring": {
      "performed": "No"
    },
    "LLM-based Hypothesis/Idea evaluation via Interpretability or Success Metrics": {
      "performed": "No"
    },
    "Hypothesis/Idea evaluation via Novelty Checking with Literature Comparison": {
      "performed": "No"
    },
    "Hypothesis/Idea evaluation via Alignment with Literature Chains": {
      "performed": "No"
    },
    "Hypothesis/Idea evaluation via Knowledge-Graph Grounded Similarity Metrics": {
      "performed": "Yes",
      "Method details": "Semantic similarity between generated hypothesis conclusions and observations is measured using Jaccard, Dice, and Overlap indices.",
      "Inputs": "Generated hypotheses and ground-truth observations on the knowledge graph.",
      "Outputs": "Similarity scores (Jaccard, Dice, Overlap) for evaluation and reward.",
      "Example": "Jaccard([H]G, O) used as part of the reward in reinforcement learning.",
      "Role in workflow": "Quantifies how well generated hypotheses explain the observed data."
    },
    "Hypothesis/Idea evaluation via Quantitative Assessment Using Domain Metrics": {
      "performed": "Yes",
      "Method details": "Condition adherence accuracy and Smatch score used to evaluate structural and constraint compliance.",
      "Inputs": "Generated hypotheses, control conditions, reference hypotheses.",
      "Outputs": "Accuracy (adherence to control), Smatch (structural similarity).",
      "Example": "Condition adherence accuracy >80% for most settings.",
      "Role in workflow": "Ensures generated hypotheses meet user-specified constraints and structural requirements."
    },
    "Hypothesis/Idea evaluation via Human/Expert": {
      "performed": "No"
    }
  },
  "Test": {
    "performed": "Yes",
    "Experimental Design Generation via literature-Grounded Model/Protocol Selection": {
      "performed": "No"
    },
    "Experimental Design Generation via Literature Synthesis for New Protocol Generation": {
      "performed": "No"
    },
    "Experimental Design Generation via Few-Shot or Example-Based Prompting": {
      "performed": "No"
    },
    "Experimental Design Generation via Executable Code Generation from Literature": {
      "performed": "No"
    },
    "LLM-Based Experimental Design Generation via Agentic Exploration and Planning": {
      "performed": "No"
    },
    "LLM-Based Experimental Design Generation via Code and Workflow Translation": {
      "performed": "No"
    },
    "LLM-Based Experimental Design Generation via Multi-Agent Planning with Specialized Roles": {
      "performed": "No"
    },
    "LLM-Based Experimental Design Generation via Domain-Specific Experimental Mapping": {
      "performed": "No"
    },
    "Test Execution via Human-in-the-Loop": {
      "performed": "No"
    },
    "Test Execution via Automated Wet-Lab Execution": {
      "performed": "No"
    },
    "Test Execution via Computational or In-Silico": {
      "performed": "Yes",
      "Method details": "Generated hypotheses are evaluated computationally on held-out test sets from knowledge graphs.",
      "Inputs": "Test split of knowledge graph datasets, generated hypotheses.",
      "Outputs": "Evaluation metrics (semantic similarity, adherence, Smatch) on test data.",
      "Example": "Testing on Gtest to compute [H]Gtest for semantic similarity.",
      "Role in workflow": "Validates the generalization and controllability of the hypothesis generation model."
    },
    "Refinement via LLM Agent Feedback Loops": {
      "performed": "No"
    },
    "Refinement via Automated Quality Evaluation using Model-Based Critics": {
      "performed": "No"
    },
    "Refinement via Dynamic Agent Updating Based on Evolving Context or Data": {
      "performed": "No"
    },
    "Refinement via guided by computational-data": {
      "performed": "Yes",
      "Method details": "Reinforcement learning phase uses computed rewards (semantic similarity, adherence) to iteratively improve the model.",
      "Inputs": "Model outputs, computed reward metrics.",
      "Outputs": "Updated model parameters for improved hypothesis generation.",
      "Example": "GRPO algorithm updates model based on group reward normalization.",
      "Role in workflow": "Refines the model to better balance semantic accuracy and control adherence."
    },
    "Refinement via experimental validation": {
      "performed": "No"
    },
    "Refinement via Performance-metric": {
      "performed": "No"
    },
    "Refinement via Human–data integration": {
      "performed": "No"
    }
  },
  "paper_title": "Controllable Logical Hypothesis Generation for Abductive Reasoning in Knowledge Graphs",
  "authors": [
    "Yisen",
    "Jiaxin",
    "Tianshi",
    "Qingyun",
    "Ziwei",
    "Jianxin",
    "Yangqiu",
    "Xingcheng"
  ],
  "published": "2025-05-27",
  "link": "http://arxiv.org/abs/2505.20948"
}