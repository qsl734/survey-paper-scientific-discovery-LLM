{
  "Inputs to the workflow": {
    "performed": "Yes",
    "User provide high-level research direction or goal": {
      "performed": "Yes",
      "Format": "Task definition (e.g., determine suitability of shoes for business, or logical pattern in Zendo worlds)",
      "Example": "The system is tasked with generating hypotheses to explain binary classification tasks such as 'suitable_for_business' or 'Zendo'.",
      "Role in workflow": "Defines the main objective for hypothesis generation and evaluation."
    },
    "User provide structured, domain-specific specifications": {
      "performed": "No"
    },
    "User provide research papers": {
      "performed": "No"
    },
    "User provide datasets other than research papers": {
      "performed": "Yes",
      "Format": "Synthetic datasets (BUSINESS SHOES, ZENDO) with natural language descriptions and logical labels",
      "Example": "BUSINESS SHOES dataset with shoe attributes and labels; ZENDO dataset with multi-object worlds and logical rules.",
      "Role in workflow": "Provides the empirical basis for hypothesis generation and testing."
    },
    "User provide representations or formal inputs": {
      "performed": "No"
    }
  },
  "Query Structuring": {
    "performed": "Yes",
    "Query Decomposition": {
      "performed": "No"
    },
    "Structural or Entity Decomposition": {
      "performed": "Yes",
      "Method details": "LLM-based multi-agent system analyzes raw text samples to identify and define relevant entities (e.g., shoe attributes, object properties in Zendo).",
      "Inputs": "Natural language descriptions of samples.",
      "Outputs": "Structured predicates representing entities and their properties.",
      "Example": "Extracting 'color', 'material', 'style' from shoe descriptions; 'size', 'color', 'position' from Zendo pieces.",
      "Role in workflow": "Enables mapping of unstructured text to formal logic representations for downstream reasoning."
    },
    "Workflow Decomposition": {
      "performed": "Yes",
      "Method details": "Multi-agent LLM system with Actor and Critic agents iteratively refines the predicate system and symbolic encoding pipeline.",
      "Inputs": "Raw text samples and design principles.",
      "Outputs": "Predicate system, symbolic encoding, and ILP-ready facts.",
      "Example": "Actor proposes predicates, Critic evaluates and provides feedback, process repeats until satisfactory.",
      "Role in workflow": "Breaks down the overall hypothesis generation into sub-tasks: predicate design, encoding, and rule learning."
    },
    "Textual or Knowledge Embedding": {
      "performed": "No"
    },
    "Molecular or Chemical Embedding": {
      "performed": "No"
    },
    "Biological or Phenotypic Embedding": {
      "performed": "No"
    },
    "Pattern and Feature Extraction": {
      "performed": "Yes",
      "Method details": "LLM agents extract key features from text (e.g., attributes, relationships) to define predicates and encode facts.",
      "Inputs": "Natural language dataset samples.",
      "Outputs": "Predicate definitions and symbolic facts.",
      "Example": "Identifying 'expensive', 'leather', 'formal_shoes' as features for business shoes.",
      "Role in workflow": "Forms the basis for symbolic knowledge encoding and logical rule induction."
    },
    "Biological Relationship Extraction": {
      "performed": "No"
    },
    "Property and Annotation Extraction": {
      "performed": "No"
    },
    "Sequence and Structure Feature Extraction": {
      "performed": "No"
    }
  },
  "Data Retrieval": {
    "performed": "No",
    "Data Retrieval via Multi-Query Generation and Exploration": {
      "performed": "No"
    },
    "Literature and Data Retrieval via APIs": {
      "performed": "No"
    },
    "Data Retrieval with Prioritization and Filtering Agents": {
      "performed": "No"
    },
    "Domain-Specific Data Retrieval and Reasoning": {
      "performed": "No"
    },
    "Code-Driven or Tool-Augmented Data Retrieval": {
      "performed": "No"
    },
    "Literature data Retrieval Citation-Network–Based Expansion": {
      "performed": "No"
    },
    "Literature data Retrieval via Semantic and Similarity-Based analysis": {
      "performed": "No"
    },
    "Literature data Retrieval via Multi-Step Reference and Evidence Selection": {
      "performed": "No"
    },
    "Domain-Specific Literature data Retrieval": {
      "performed": "No"
    },
    "Manual and Semi-Automatic Curation of Literature data": {
      "performed": "No"
    },
    "Structural or Similarity-Based Dataset Retrieval": {
      "performed": "No"
    },
    "Data Retrieval via Domain-Specific Repository Querying": {
      "performed": "No"
    },
    "Library Assembly and Data Augmentation": {
      "performed": "No"
    }
  },
  "Knowledge Assembly": {
    "performed": "Yes",
    "Standardized Section Extraction from Literature data": {
      "performed": "No"
    },
    "Concise Synopsis and Summarization of Literature data": {
      "performed": "No"
    },
    "Facet-Based or Field-Specific Extraction from Literature data": {
      "performed": "No"
    },
    "Domain-Tailored Extraction from Literature data": {
      "performed": "No"
    },
    "Task/Entity-Centric Knowledge Graphs": {
      "performed": "No"
    },
    "Causal or Relation-Specific Knowledge Graphs": {
      "performed": "No"
    },
    "Biomedical or Domain-Specific Interaction Graphs": {
      "performed": "No"
    },
    "Literature Database Construction": {
      "performed": "No"
    },
    "Entity- or Co-Occurrence–Based Databases": {
      "performed": "No"
    },
    "Reasoning-Chain or Temporal Databases for Literature": {
      "performed": "No"
    }
  },
  "Hypothesis/Idea Generation": {
    "performed": "Yes",
    "Idea/hypothesis generation without additional literature or dataset as context": {
      "performed": "No"
    },
    "LLM Agent Generate ideas/hypotheses via Task Decomposition": {
      "performed": "Yes",
      "Method details": "Actor-Critic LLM agents decompose the task into predicate system design, symbolic encoding, and rule induction.",
      "Inputs": "Raw text samples, design principles.",
      "Outputs": "Predicate system, encoded facts, candidate hypotheses.",
      "Example": "Actor proposes predicates, Critic refines, leading to structured hypothesis space.",
      "Role in workflow": "Enables systematic, modular hypothesis generation from unstructured data."
    },
    "Generate ideas/hypotheses using Domain-Specialized LLM Agent": {
      "performed": "Yes",
      "Method details": "LLM agents specialize in predicate abstraction (Actor) and evaluation (Critic), focusing on domain-relevant features.",
      "Inputs": "Task-specific text samples.",
      "Outputs": "Domain-relevant predicate systems and hypotheses.",
      "Example": "Actor abstracts shoe features; Critic ensures relevance and completeness.",
      "Role in workflow": "Ensures generated hypotheses are tailored to the domain and task."
    },
    "Literature data used during idea/hypothesis generation as context": {
      "performed": "No"
    },
    "Summarization Literature data used during idea/hypothesis generation": {
      "performed": "No"
    },
    "Idea/hypothesis generation via Facet Recombination": {
      "performed": "No"
    },
    "Idea/hypothesis generation via contructed Reasoning-Chain from literature": {
      "performed": "No"
    },
    "Idea/hypothesis generation via Knowledge Graph developed from literature": {
      "performed": "No"
    },
    "Idea/hypothesis generation via Pattern Detection from dataset": {
      "performed": "Yes",
      "Method details": "ILP solver (MAXSYNTH) detects logical patterns in encoded facts to generate hypotheses.",
      "Inputs": "Symbolic facts derived from dataset.",
      "Outputs": "Logical rules (Horn clauses) explaining target predicates.",
      "Example": "Rule: suitable_for_business(A) ← expensive(A) ∧ formal_shoes(A).",
      "Role in workflow": "Discovers interpretable, data-driven hypotheses from structured representations."
    },
    "Idea/hypothesis generation via Few-Shot Data Seeding": {
      "performed": "Yes",
      "Method details": "Actor agent is guided by few-shot examples of predicate abstraction from other tasks.",
      "Inputs": "Few-shot predicate abstraction examples, small subset of training samples.",
      "Outputs": "Initial predicate system proposals.",
      "Example": "Actor uses few-shot prompts to design predicates for new tasks.",
      "Role in workflow": "Bootstraps predicate system design for new domains."
    },
    "Idea/hypothesis generation using Observational data": {
      "performed": "Yes",
      "Method details": "Symbolic encoding of observed input-output pairs (text and labels) forms the basis for rule induction.",
      "Inputs": "Natural language samples with labels.",
      "Outputs": "Symbolic facts for ILP.",
      "Example": "Text: 'Shoe_001 is a black formal shoe... suitable for business.' → pos(suitable_for_business(shoe_001)).",
      "Role in workflow": "Provides empirical grounding for hypothesis generation."
    },
    "Idea/hypothesis generation via Feature-Driven Property Prediction": {
      "performed": "No"
    },
    "Idea/hypothesis generation after Fine-Tuning the LLM model": {
      "performed": "No"
    }
  },
  "Hypothesis/Idea Prioritization": {
    "performed": "Yes",
    "LLM-based Hypothesis/Idea evaluation via Scientific Quality": {
      "performed": "Yes",
      "Method details": "Critic agent evaluates predicate systems for completeness, redundancy, and relevance using LLM capabilities.",
      "Inputs": "Predicate system proposals.",
      "Outputs": "Evaluation summaries and feedback.",
      "Example": "Critic checks if all crucial concepts are covered and if predicates are relevant.",
      "Role in workflow": "Ensures only high-quality, scientifically plausible predicate systems are used."
    },
    "LLM-based Hypothesis/Idea evaluation via Domain-Specific Evaluation": {
      "performed": "Yes",
      "Method details": "Critic agent checks semantic appropriateness and syntactic compliance with ILP requirements.",
      "Inputs": "Predicate system proposals.",
      "Outputs": "Feedback on domain relevance and structural validity.",
      "Example": "Critic validates that argument types in head predicates are covered by body predicates.",
      "Role in workflow": "Filters out domain-inappropriate or structurally invalid hypotheses."
    },
    "LLM-based Hypothesis/Idea evaluation via Contextual Evidence Scoring": {
      "performed": "No"
    },
    "LLM-based Hypothesis/Idea evaluation via Interpretability or Success Metrics": {
      "performed": "No"
    },
    "Hypothesis/Idea evaluation via Novelty Checking with Literature Comparison": {
      "performed": "No"
    },
    "Hypothesis/Idea evaluation via Alignment with Literature Chains": {
      "performed": "No"
    },
    "Hypothesis/Idea evaluation via Knowledge-Graph Grounded Similarity Metrics": {
      "performed": "No"
    },
    "Hypothesis/Idea evaluation via Quantitative Assessment Using Domain Metrics": {
      "performed": "Yes",
      "Method details": "ILP solver (MAXSYNTH) uses Minimum Description Length (MDL) to balance rule complexity and data fit.",
      "Inputs": "Candidate logic programs and dataset.",
      "Outputs": "Optimal rule set minimizing program size and misclassification.",
      "Example": "Selecting rules with lowest 'program size + false positives + false negatives'.",
      "Role in workflow": "Objectively prioritizes hypotheses for simplicity and accuracy."
    },
    "Hypothesis/Idea evaluation via Human/Expert": {
      "performed": "No"
    }
  },
  "Test": {
    "performed": "Yes",
    "Experimental Design Generation via literature-Grounded Model/Protocol Selection": {
      "performed": "No"
    },
    "Experimental Design Generation via Literature Synthesis for New Protocol Generation": {
      "performed": "No"
    },
    "Experimental Design Generation via Few-Shot or Example-Based Prompting": {
      "performed": "No"
    },
    "Experimental Design Generation via Executable Code Generation from Literature": {
      "performed": "No"
    },
    "LLM-Based Experimental Design Generation via Agentic Exploration and Planning": {
      "performed": "No"
    },
    "LLM-Based Experimental Design Generation via Code and Workflow Translation": {
      "performed": "No"
    },
    "LLM-Based Experimental Design Generation via Multi-Agent Planning with Specialized Roles": {
      "performed": "No"
    },
    "LLM-Based Experimental Design Generation via Domain-Specific Experimental Mapping": {
      "performed": "No"
    },
    "Test Execution via Human-in-the-Loop": {
      "performed": "No"
    },
    "Test Execution via Automated Wet-Lab Execution": {
      "performed": "No"
    },
    "Test Execution via Computational or In-Silico": {
      "performed": "Yes",
      "Method details": "ILP solver (MAXSYNTH) computationally tests candidate hypotheses against held-out test data.",
      "Inputs": "Learned rule sets and test datasets.",
      "Outputs": "Accuracy, F1 scores, and performance metrics.",
      "Example": "Evaluating learned rules on test split of SHOES/ZENDO datasets.",
      "Role in workflow": "Validates the predictive power and generalizability of generated hypotheses."
    },
    "Refinement via LLM Agent Feedback Loops": {
      "performed": "Yes",
      "Method details": "Actor and Critic agents iteratively refine the predicate system based on Critic feedback until criteria are met or max iterations reached.",
      "Inputs": "Predicate system proposals and Critic feedback.",
      "Outputs": "Improved predicate systems.",
      "Example": "Actor revises predicates after Critic identifies missing or redundant concepts.",
      "Role in workflow": "Improves the quality and suitability of the symbolic language bias for ILP."
    },
    "Refinement via Automated Quality Evaluation using Model-Based Critics": {
      "performed": "No"
    },
    "Refinement via Dynamic Agent Updating Based on Evolving Context or Data": {
      "performed": "No"
    },
    "Refinement via guided by computational-data": {
      "performed": "Yes",
      "Method details": "If ILP solving fails, the system restarts predicate system design and symbolic encoding, up to two attempts.",
      "Inputs": "ILP solver outcomes.",
      "Outputs": "Revised predicate systems and encodings.",
      "Example": "Restarting from predicate design if no valid rule set is found.",
      "Role in workflow": "Ensures robustness and recovery from failed hypothesis induction."
    },
    "Refinement via experimental validation": {
      "performed": "No"
    },
    "Refinement via Performance-metric": {
      "performed": "Yes",
      "Method details": "Performance metrics (accuracy, F1) guide further refinement and comparison across methods and data conditions.",
      "Inputs": "Test results.",
      "Outputs": "Performance-driven adjustments and reporting.",
      "Example": "Comparing F1 scores across noise levels to assess robustness.",
      "Role in workflow": "Quantitatively informs iterative improvement and benchmarking."
    },
    "Refinement via Human–data integration": {
      "performed": "No"
    }
  },
  "paper_title": "Robust Hypothesis Generation: LLM-Automated Language Bias for Inductive Logic Programming",
  "authors": [
    "Yang",
    "Jiemin",
    "Yutao"
  ],
  "published": "2025-05-27",
  "link": "http://arxiv.org/abs/2505.21486"
}