{
  "Inputs to the workflow": {
    "performed": "Yes",
    "User provide high-level research direction or goal": {
      "performed": "Yes",
      "Format": "Natural language problem statements and brainstorming objectives",
      "Example": "Design a car that can fly; goal is to save commuting time and improve traffic.",
      "Role in workflow": "Defines the creative brainstorming task and sets the context for LLM prompt engineering."
    },
    "User provide structured, domain-specific specifications": {
      "performed": "Yes",
      "Format": "Prompt templates specifying roles, audience, context, objectives, constraints, and output requirements",
      "Example": "Imagine you are an engineer... this car is designed for school teachers... generate as many ideas as possible.",
      "Role in workflow": "Constrains and guides LLM outputs to align with specific design and user needs."
    },
    "User provide research papers": {
      "performed": "No"
    },
    "User provide datasets other than research papers": {
      "performed": "No"
    },
    "User provide representations or formal inputs": {
      "performed": "Yes",
      "Format": "Structured prompt templates with fields (Who, What, Where, Additional Info, Output Requirement)",
      "Example": "Prompt template as shown in Figure 2, including role, context, and requirements.",
      "Role in workflow": "Ensures systematic and comprehensive prompt construction for LLM-based brainstorming."
    }
  },
  "Query Structuring": {
    "performed": "Yes",
    "Query Decomposition": {
      "performed": "Yes",
      "Method details": "Prompts are systematically structured into components (role, context, objective, constraints, output requirements) to clarify and decompose the brainstorming task.",
      "Inputs": "User-defined design challenge and context",
      "Outputs": "Structured prompts with explicit subcomponents",
      "Example": "Breaking down 'design a car that can fly' into role, audience, scenario, and requirements in the prompt template.",
      "Role in workflow": "Transforms vague tasks into actionable, detailed prompts for LLMs."
    },
    "Structural or Entity Decomposition": {
      "performed": "No"
    },
    "Workflow Decomposition": {
      "performed": "Yes",
      "Method details": "Prompting strategies (e.g., chain-of-thought, alternative approaches) guide LLMs to break down the design process into sequential or parallel ideation steps.",
      "Inputs": "Structured prompts with strategy instructions",
      "Outputs": "Stepwise or multi-perspective idea generation",
      "Example": "Chain-of-thought: 'How to build a car? Think step-by-step.'",
      "Role in workflow": "Enables LLM to generate ideas through decomposed reasoning or multi-step exploration."
    },
    "Textual or Knowledge Embedding": {
      "performed": "No"
    },
    "Molecular or Chemical Embedding": {
      "performed": "No"
    },
    "Biological or Phenotypic Embedding": {
      "performed": "No"
    },
    "Pattern and Feature Extraction": {
      "performed": "No"
    },
    "Biological Relationship Extraction": {
      "performed": "No"
    },
    "Property and Annotation Extraction": {
      "performed": "No"
    },
    "Sequence and Structure Feature Extraction": {
      "performed": "No"
    }
  },
  "Data Retrieval": {
    "performed": "No",
    "Data Retrieval via Multi-Query Generation and Exploration": {
      "performed": "No"
    },
    "Literature and Data Retrieval via APIs": {
      "performed": "No"
    },
    "Data Retrieval with Prioritization and Filtering Agents": {
      "performed": "No"
    },
    "Domain-Specific Data Retrieval and Reasoning": {
      "performed": "No"
    },
    "Code-Driven or Tool-Augmented Data Retrieval": {
      "performed": "No"
    },
    "Literature data Retrieval Citation-Network–Based Expansion": {
      "performed": "No"
    },
    "Literature data Retrieval via Semantic and Similarity-Based analysis": {
      "performed": "No"
    },
    "Literature data Retrieval via Multi-Step Reference and Evidence Selection": {
      "performed": "No"
    },
    "Domain-Specific Literature data Retrieval": {
      "performed": "No"
    },
    "Manual and Semi-Automatic Curation of Literature data": {
      "performed": "No"
    },
    "Structural or Similarity-Based Dataset Retrieval": {
      "performed": "No"
    },
    "Data Retrieval via Domain-Specific Repository Querying": {
      "performed": "No"
    },
    "Library Assembly and Data Augmentation": {
      "performed": "No"
    }
  },
  "Knowledge Assembly": {
    "performed": "No",
    "Standardized Section Extraction from Literature data": {
      "performed": "No"
    },
    "Concise Synopsis and Summarization of Literature data": {
      "performed": "No"
    },
    "Facet-Based or Field-Specific Extraction from Literature data": {
      "performed": "No"
    },
    "Domain-Tailored Extraction from Literature data": {
      "performed": "No"
    },
    "Task/Entity-Centric Knowledge Graphs": {
      "performed": "No"
    },
    "Causal or Relation-Specific Knowledge Graphs": {
      "performed": "No"
    },
    "Biomedical or Domain-Specific Interaction Graphs": {
      "performed": "No"
    },
    "Literature Database Construction": {
      "performed": "No"
    },
    "Entity- or Co-Occurrence–Based Databases": {
      "performed": "No"
    },
    "Reasoning-Chain or Temporal Databases for Literature": {
      "performed": "No"
    }
  },
  "Hypothesis/Idea Generation": {
    "performed": "Yes",
    "Idea/hypothesis generation without additional literature or dataset as context": {
      "performed": "Yes",
      "Method details": "ChatGPT 3.5 generates creative ideas based solely on prompt instructions and its internal knowledge, without external data.",
      "Inputs": "Structured prompts (with or without strategies) provided by users",
      "Outputs": "Lists of creative design ideas for the specified problem",
      "Example": "Generating solutions for 'design a car that can fly' using only prompt context.",
      "Role in workflow": "Central mechanism for brainstorming and creative ideation."
    },
    "LLM Agent Generate ideas/hypotheses via Task Decomposition": {
      "performed": "Yes",
      "Method details": "Strategies like chain-of-thought and alternative approaches instruct the LLM to break down the problem or generate multiple perspectives.",
      "Inputs": "Prompts specifying stepwise or alternative solution generation",
      "Outputs": "Stepwise or multi-perspective idea lists",
      "Example": "Prompt: 'How to build a car? Think step-by-step.'",
      "Role in workflow": "Enhances depth and diversity of generated ideas."
    },
    "Generate ideas/hypotheses using Domain-Specialized LLM Agent": {
      "performed": "Yes",
      "Method details": "Prompts assign specific roles (e.g., engineer, eight-year-old child) to the LLM, simulating domain or perspective specialization.",
      "Inputs": "Prompts specifying role or perspective",
      "Outputs": "Ideas generated from specified domain or viewpoint",
      "Example": "Prompt: 'Imagine you are an eight-year-old child...'",
      "Role in workflow": "Introduces diverse perspectives to stimulate creativity."
    },
    "Literature data used during idea/hypothesis generation as context": {
      "performed": "No"
    },
    "Summarization Literature data used during idea/hypothesis generation": {
      "performed": "No"
    },
    "Idea/hypothesis generation via Facet Recombination": {
      "performed": "No"
    },
    "Idea/hypothesis generation via contructed Reasoning-Chain from literature": {
      "performed": "No"
    },
    "Idea/hypothesis generation via Knowledge Graph developed from literature": {
      "performed": "No"
    },
    "Idea/hypothesis generation via Pattern Detection from dataset": {
      "performed": "No"
    },
    "Idea/hypothesis generation via Few-Shot Data Seeding": {
      "performed": "Yes",
      "Method details": "Prompts include example ideas (one-shot/few-shot) to guide LLM in generating similar or inspired solutions.",
      "Inputs": "Prompts with example solutions (e.g., 'using magnetic power to make the car hover')",
      "Outputs": "Idea lists influenced by provided examples",
      "Example": "Prompt: 'You can generate ideas such as using magnetic power... What are other possible solutions?'",
      "Role in workflow": "Steers LLM outputs toward desired novelty or direction."
    },
    "Idea/hypothesis generation using Observational data": {
      "performed": "No"
    },
    "Idea/hypothesis generation via Feature-Driven Property Prediction": {
      "performed": "No"
    },
    "Idea/hypothesis generation after Fine-Tuning the LLM model": {
      "performed": "No"
    }
  },
  "Hypothesis/Idea Prioritization": {
    "performed": "Yes",
    "LLM-based Hypothesis/Idea evaluation via Scientific Quality": {
      "performed": "No"
    },
    "LLM-based Hypothesis/Idea evaluation via Domain-Specific Evaluation": {
      "performed": "No"
    },
    "LLM-based Hypothesis/Idea evaluation via Contextual Evidence Scoring": {
      "performed": "No"
    },
    "LLM-based Hypothesis/Idea evaluation via Interpretability or Success Metrics": {
      "performed": "No"
    },
    "Hypothesis/Idea evaluation via Novelty Checking with Literature Comparison": {
      "performed": "No"
    },
    "Hypothesis/Idea evaluation via Alignment with Literature Chains": {
      "performed": "No"
    },
    "Hypothesis/Idea evaluation via Knowledge-Graph Grounded Similarity Metrics": {
      "performed": "No"
    },
    "Hypothesis/Idea evaluation via Quantitative Assessment Using Domain Metrics": {
      "performed": "No"
    },
    "Hypothesis/Idea evaluation via Human/Expert": {
      "performed": "Yes",
      "Method details": "Two professionals independently rate generated ideas for fluency, flexibility, originality, and elaboration using adapted TTCT criteria.",
      "Inputs": "LLM-generated idea lists",
      "Outputs": "Quantitative and qualitative ratings for each creativity dimension",
      "Example": "Experts rate originality from 0-10 for each idea.",
      "Role in workflow": "Provides human-grounded evaluation of LLM-generated ideas' creativity."
    }
  },
  "Test": {
    "performed": "No",
    "Experimental Design Generation via literature-Grounded Model/Protocol Selection": {
      "performed": "No"
    },
    "Experimental Design Generation via Literature Synthesis for New Protocol Generation": {
      "performed": "No"
    },
    "Experimental Design Generation via Few-Shot or Example-Based Prompting": {
      "performed": "No"
    },
    "Experimental Design Generation via Executable Code Generation from Literature": {
      "performed": "No"
    },
    "LLM-Based Experimental Design Generation via Agentic Exploration and Planning": {
      "performed": "No"
    },
    "LLM-Based Experimental Design Generation via Code and Workflow Translation": {
      "performed": "No"
    },
    "LLM-Based Experimental Design Generation via Multi-Agent Planning with Specialized Roles": {
      "performed": "No"
    },
    "LLM-Based Experimental Design Generation via Domain-Specific Experimental Mapping": {
      "performed": "No"
    },
    "Test Execution via Human-in-the-Loop": {
      "performed": "No"
    },
    "Test Execution via Automated Wet-Lab Execution": {
      "performed": "No"
    },
    "Test Execution via Computational or In-Silico": {
      "performed": "No"
    },
    "Refinement via LLM Agent Feedback Loops": {
      "performed": "No"
    },
    "Refinement via Automated Quality Evaluation using Model-Based Critics": {
      "performed": "No"
    },
    "Refinement via Dynamic Agent Updating Based on Evolving Context or Data": {
      "performed": "No"
    },
    "Refinement via guided by computational-data": {
      "performed": "No"
    },
    "Refinement via experimental validation": {
      "performed": "No"
    },
    "Refinement via Performance-metric": {
      "performed": "No"
    },
    "Refinement via Human–data integration": {
      "performed": "No"
    }
  },
  "paper_title": "A Framework for Collaborating a Large Language Model Tool in Brainstorming for Triggering Creative Thoughts",
  "authors": [
    "Hung-Fu",
    "Tong"
  ],
  "published": "2024-10-10",
  "link": "http://arxiv.org/abs/2410.11877"
}