{
  "objective": {
    "answer": "The primary objective of the paper is to present RUGGED, a comprehensive workflow that integrates Large Language Model (LLM) inference with Retrieval Augmented Generation (RAG) to support biomedical hypothesis generation and knowledge integration, minimizing LLM hallucinations and providing actionable insights.",
    "evidence": "In this protocol, we present RUGGED (Retrieval Under Graph-Guided Explainable disease Distinction), a comprehensive workflow designed to support investigators with knowledge integration and hypothesis generation, identifying validated paths forward."
  },
  "knowledge_gap": {
    "answer": "Current approaches to biomedical hypothesis generation often lack deep contextual understanding and have limited ability to draw inferences and interactively explore new hypotheses.",
    "evidence": "Despite efforts, our current approaches often lack deep contextual understanding of these fragmented data with limited ability to draw inferences and interactively explore new hypotheses."
  },
  "novelty": {
    "answer": [
      "Integration of LLMs with RAG to minimize hallucinations and enhance accuracy.",
      "Use of explainable AI predictions to uncover interpretable and actionable insights.",
      "Development of a workflow that facilitates user-directed mechanism elucidation and hypothesis exploration."
    ],
    "evidence": [
      "RUGGED is a computational workflow that integrates Large Language Model (LLM) inference with Retrieval Augmented Generation (RAG) drawing evidence from trustworthy and curated biomedical knowledge bases.",
      "We employ explainable artificial intelligence predictions to uncover interpretable and actionable insights from the existing biomedical knowledge.",
      "The completed workflow streamlines the exploration of knowledge graphs and model predictions via RAG-enabled LLMs, facilitating intuitive and informed interactions for researchers, clinicians, and clinical professionals."
    ]
  },
  "inspirational_papers": {
    "answer": [
      "Pelletier et al. (2023) A Knowledge Graph Approach to Elucidate the Role of Organellar Pathways in Disease via Biomedical Reports. (Methodological precursors)",
      "Xiao et al. (2023) Know2BIO: A Comprehensive Dual-View Benchmark for Evolving Biomedical Knowledge Graphs. (Experimental baselines)"
    ],
    "evidence": [
      "Pelletier, A.R., Steinecke, D., Sigdel, D., Adam, I., Caufield, J.H., Guevara-Gonzalez, V., et al. A Knowledge Graph Approach to Elucidate the Role of Organellar Pathways in Disease via Biomedical Reports.",
      "Xiao, Y., Steinecke, D., Pelletier, A.R., Bai, Y., Ping, P., Wang, W. Know2BIO: A Comprehensive Dual-View Benchmark for Evolving Biomedical Knowledge Graphs."
    ]
  },
  "method": {
    "steps": [
      {
        "step": "Install and configure necessary software and services for RUGGED.",
        "input": "Docker, Git, OpenAI API, Ollama, Neo4j",
        "output": "Configured environment for running RUGGED",
        "evidence": "Install Docker. Visit the Docker website (https://www.docker.com/), click on ‘Get started’, and choose the appropriate version for your operating system."
      },
      {
        "step": "Access and extract biomedical knowledge and information.",
        "input": "CaseOLAP LIFT, Know2BIO",
        "output": "Biomedical text documents and knowledge graph",
        "evidence": "CaseOLAP LIFT is a computational protocol designed to investigate sub-cellular proteins and their associations with disease through biomedical literature text mining."
      },
      {
        "step": "Construct and filter a combined knowledge graph.",
        "input": "Text mining results, knowledge graph data",
        "output": "Filtered knowledge graph for predictive analysis",
        "evidence": "Execute the provided combine_kg_results.py script to combine the text mining results within the knowledge graph results."
      },
      {
        "step": "Perform explainable prediction analysis using GNNExplainer.",
        "input": "Filtered knowledge graph",
        "output": "Predicted potential edges and insights",
        "evidence": "In this step, we will use GNNExplainer on a Graph Convolutional Network (GCN) to perform prediction analysis."
      },
      {
        "step": "Generate and explore hypotheses with RUGGED.",
        "input": "Knowledge graph, text corpus",
        "output": "Hypotheses and insights for biomedical research",
        "evidence": "Start RUGGED in the command line interface to interact with the system and explore your hypotheses."
      }
    ],
    "tools": [
      {
        "name": "Docker",
        "description": "Used for containerizing and running the RUGGED environment.",
        "evidence": "Install Docker. Visit the Docker website (https://www.docker.com/), click on ‘Get started’, and choose the appropriate version for your operating system."
      },
      {
        "name": "Neo4j",
        "description": "Used for managing the knowledge graph database.",
        "evidence": "RUGGED supports Neo4j, accessible as a Docker container, Neo4j Desktop, or Neo4j AuraDB online server."
      },
      {
        "name": "GNNExplainer",
        "description": "Used for explainable prediction analysis on the knowledge graph.",
        "evidence": "In this step, we will use GNNExplainer on a Graph Convolutional Network (GCN) to perform prediction analysis."
      }
    ],
    "benchmark_datasets": [
      {
        "name": "PubMed",
        "data_description": "Biomedical literature publications.",
        "usage": "Used for text mining and knowledge extraction.",
        "evidence": "The vast amount of biomedical information available today presents a significant challenge for investigators seeking to digest, process, and understand these findings effectively."
      }
    ],
    "evaluation_metrics": [
      {
        "name": "Accuracy",
        "purpose": "Measures the proportion of correctly classified predictions.",
        "application": "Used to evaluate the model's performance on the knowledge graph.",
        "evidence": "Accuracy indicates the proportion of correctly classified predictions."
      },
      {
        "name": "Precision",
        "purpose": "Measures the proportion of correct positive predictions out of all positive predictions.",
        "application": "Used to evaluate the model's precision in predicting edges.",
        "evidence": "Precision measures the proportion of correct positive predictions out of all positive predictions."
      },
      {
        "name": "Recall",
        "purpose": "Measures the proportion of correct positive predictions out of all positive edges.",
        "application": "Used to evaluate the model's recall in predicting edges.",
        "evidence": "Recall measures the proportion of correct positive predictions out of all positive edges."
      },
      {
        "name": "F1-score",
        "purpose": "Harmonic mean of precision and recall.",
        "application": "Used to evaluate the balance between precision and recall.",
        "evidence": "The F1-score is the harmonic mean of precision and recall."
      },
      {
        "name": "AUROC",
        "purpose": "Describes how well the model distinguishes between positive and negative predictions.",
        "application": "Used to evaluate the model's discrimination performance.",
        "evidence": "AUROC describes how well the model distinguishes between positive and negative predictions."
      },
      {
        "name": "AUPRC",
        "purpose": "Measures the trade-off between precision and recall at varying thresholds.",
        "application": "Used to evaluate the model's performance in precision-recall space.",
        "evidence": "AUPRC measures the trade-off between precision and recall at varying thresholds."
      }
    ]
  },
  "method_type": {
    "methods": [
      {
        "name": "Hypothesis or Idea Generation",
        "description": "The system produces candidate hypotheses or new research ideas from prior knowledge or external input.",
        "evidence": "A clinical use-case demonstrates RUGGED's ability to evaluate and recommend therapeutics for Arrhythmogenic Cardiomyopathy (ACM) and Dilated Cardiomyopathy (DCM)."
      },
      {
        "name": "Experimental design generation",
        "description": "The approach includes producing experimental protocols, configurations, or evaluation strategies.",
        "evidence": "The process involves splitting the filtered knowledge graph into training, validation, and test sets with an 85:5:10 ratio."
      }
    ]
  },
  "subject_area": {
    "areas": [
      {
        "name": "Health Sciences",
        "description": "The paper focuses on biomedical hypothesis generation and therapeutic recommendations.",
        "evidence": "A clinical use-case demonstrates RUGGED's ability to evaluate and recommend therapeutics for Arrhythmogenic Cardiomyopathy (ACM) and Dilated Cardiomyopathy (DCM)."
      },
      {
        "name": "Applied Sciences & Engineering",
        "description": "The paper involves the development of computational workflows and integration of AI models.",
        "evidence": "RUGGED is a computational workflow that integrates Large Language Model (LLM) inference with Retrieval Augmented Generation (RAG)."
      }
    ]
  },
  "performance_summary": {
    "performance_summary": [
      {
        "summary": "The model achieved a test accuracy of 0.7520, with a precision of 0.6741 and recall of 0.9755.",
        "evidence": "Val Accuracy: 0.7508, Test Accuracy: 0.7520; Val Precision: 0.6732, Test Precision: 0.6741; Val Recall: 0.9749, Test Recall: 0.9755."
      }
    ],
    "baselines": [
      {
        "name": "Graph Convolutional Network",
        "description": "Used as a baseline for link prediction in the knowledge graph.",
        "evidence": "The goal is to predict potential edges (relationships) in the knowledge graph, providing insights into previously unknown associations."
      }
    ],
    "benchmark_datasets": [
      {
        "name": "PubMed",
        "data_description": "Biomedical literature publications.",
        "usage": "Used for text mining and knowledge extraction.",
        "evidence": "The vast amount of biomedical information available today presents a significant challenge for investigators seeking to digest, process, and understand these findings effectively."
      }
    ],
    "evaluation_metrics": [
      {
        "name": "Accuracy",
        "purpose": "Measures the proportion of correctly classified predictions.",
        "application": "Used to evaluate the model's performance on the knowledge graph.",
        "evidence": "Accuracy indicates the proportion of correctly classified predictions."
      },
      {
        "name": "Precision",
        "purpose": "Measures the proportion of correct positive predictions out of all positive predictions.",
        "application": "Used to evaluate the model's precision in predicting edges.",
        "evidence": "Precision measures the proportion of correct positive predictions out of all positive predictions."
      },
      {
        "name": "Recall",
        "purpose": "Measures the proportion of correct positive predictions out of all positive edges.",
        "application": "Used to evaluate the model's recall in predicting edges.",
        "evidence": "Recall measures the proportion of correct positive predictions out of all positive edges."
      },
      {
        "name": "F1-score",
        "purpose": "Harmonic mean of precision and recall.",
        "application": "Used to evaluate the balance between precision and recall.",
        "evidence": "The F1-score is the harmonic mean of precision and recall."
      },
      {
        "name": "AUROC",
        "purpose": "Describes how well the model distinguishes between positive and negative predictions.",
        "application": "Used to evaluate the model's discrimination performance.",
        "evidence": "AUROC describes how well the model distinguishes between positive and negative predictions."
      },
      {
        "name": "AUPRC",
        "purpose": "Measures the trade-off between precision and recall at varying thresholds.",
        "application": "Used to evaluate the model's performance in precision-recall space.",
        "evidence": "AUPRC measures the trade-off between precision and recall at varying thresholds."
      }
    ]
  },
  "benchmark_dataset": {
    "name": "PubMed",
    "data_description": "Biomedical literature publications.",
    "usage": "Used for text mining and knowledge extraction.",
    "evidence": "The vast amount of biomedical information available today presents a significant challenge for investigators seeking to digest, process, and understand these findings effectively."
  },
  "limitations": {
    "limitations": [
      {
        "name": "Computational Resource Requirement",
        "description": "The explainability AI prediction analysis requires substantial computational resources and time.",
        "evidence": "Explainability AI prediction analysis enhances the interpretability of predictions but requires substantial computational resources and time."
      },
      {
        "name": "Potential for Hallucinations",
        "description": "Despite RAG systems aiming to reduce hallucinations, models can still produce incorrect information.",
        "evidence": "While RAG systems aim to reduce hallucinations in LLMs by grounding responses in evidence, these models can still produce incorrect information."
      }
    ]
  },
  "future_directions": {
    "future_directions": [
      {
        "name": "Expand to Other Biomedical Domains",
        "description": "Adapt the RUGGED workflow to handle other types of biomedical data and domains.",
        "evidence": "While designed for biomedical information retrieval, this protocol can handle any text and graph data, such as in-house data, clinical notes, or electronic health records."
      },
      {
        "name": "Enhance Model Performance",
        "description": "Explore new LLMs and task-specific models to improve the accuracy and applicability of the RUGGED system.",
        "evidence": "With the rapidly evolving LLM landscape, new landmark models and task-specific models are released regularly."
      }
    ]
  },
  "resource_link": {
    "answer": "https://github.com/pinglab-utils/RUGGED",
    "evidence": "The software is available at https://github.com/pinglab-utils/RUGGED."
  }
}