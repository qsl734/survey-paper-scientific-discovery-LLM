{
  "objective": {
    "answer": "The primary objective of the paper is to introduce DISCOVERYWORLD, a virtual environment designed to develop and evaluate AI agents' ability to perform complete cycles of scientific discovery.",
    "evidence": "In this work we introduce DISCOVERYWORLD, the first virtual environment for developing and benchmarking an agent’s ability to perform complete cycles of novel scientific discovery."
  },
  "knowledge_gap": {
    "answer": "The paper addresses the gap in developing AI systems capable of performing end-to-end scientific discovery, which is challenging due to the complexity and cost of real-world experiments.",
    "evidence": "However, developing and evaluating an AI agent’s capacity for end-to-end scientific reasoning is challenging as running real-world experiments is often prohibitively expensive or infeasible."
  },
  "novelty": {
    "answer": [
      "DISCOVERYWORLD tasks require long-horizon discovery processes, including ideation, experimentation, systematic search, and analysis.",
      "The tasks do not suggest a solution approach, requiring agents to ideate and define hypotheses.",
      "DISCOVERYWORLD is realistic rather than counterfactual, allowing sensible application of background knowledge.",
      "The tasks cover eight diverse topics to encourage general rather than task-specific solutions."
    ],
    "evidence": [
      "DISCOVERYWORLD tasks are long-horizon, requiring multiple facets of discovery including ideation, experimentation, systematic search, and analysis to be performed to solve a task.",
      "The tasks do not suggest a solution approach, instead requiring the agent to ideate and define hypotheses to explore.",
      "DISCOVERYWORLD is realistic (but simplified) rather than counterfactual, so that background knowledge can be sensibly applied.",
      "The tasks cover eight diverse topics, from identifying the cause of space illnesses to reactor tuning, to encourage development of general rather than task-specific solutions."
    ]
  },
  "inspirational_papers": {
    "answer": "- King et al. (2004) Functional genomic hypothesis generation and experimentation by a robot scientist. (Methodological precursors)\n- Jumper et al. (2021) Highly accurate protein structure prediction with AlphaFold. (Experimental baselines)",
    "evidence": "Recently, several real-world discovery systems have shown success in areas such as genetics (Adam [12], Eve [32]), chemistry (CoScientist [1], ChemCrow [2]) and protenomics (AlphaFold [10], RoseTTAFold [15])."
  },
  "method": {
    "steps": [
      {
        "step": "Develop a text-based simulated world called DISCOVERYWORLD.",
        "input": "Concept of a virtual environment for scientific discovery.",
        "output": "A simulated environment where agents can perform scientific discovery tasks.",
        "evidence": "Our approach is to develop a text-based simulated world (with optional 2D visual overlay), called DISCOVERYWORLD, where agents can navigate around, interact with objects in the world, use scientific equipment (measuring devices, tools, etc.), and make observations."
      },
      {
        "step": "Create 120 different challenge tasks across eight topics.",
        "input": "Scientific discovery topics and task design.",
        "output": "A set of tasks requiring hypothesis formation, experiment design, and analysis.",
        "evidence": "DISCOVERYWORLD contains a variety of different challenges, covering topics as diverse as radioisotope dating, rocket science, and proteomics, to encourage development of general discovery skills rather than task-specific solutions."
      },
      {
        "step": "Implement automatic metrics for evaluating agent performance.",
        "input": "Task completion criteria and performance metrics.",
        "output": "Metrics based on task completion, task-relevant actions, and discovered knowledge.",
        "evidence": "DISCOVERYWORLD further provides three automatic metrics for evaluating performance, based on (a) task completion, (b) task-relevant actions taken, and (c) the discovered explanatory knowledge."
      }
    ],
    "tools": [
      {
        "name": "PYGAME framework",
        "description": "Used to implement the DISCOVERYWORLD simulation engine.",
        "evidence": "The simulator is implemented as approximately 20K lines of PYTHON using the PYGAME framework [21]."
      },
      {
        "name": "OPENAI GYM specifications",
        "description": "Used to provide an API for developing agents.",
        "evidence": "The API resembles the OPENAI GYM specifications [3, 27], such that at each step, the agent is provided with an observation from the environment, and must choose a single action to take during that turn from a set of possible actions."
      }
    ],
    "benchmark_datasets": [],
    "evaluation_metrics": [
      {
        "name": "Task Completion",
        "purpose": "Measures whether the task was completed successfully.",
        "application": "Used to evaluate the overall success of agents in completing tasks.",
        "evidence": "To evaluate agents’ progress in DISCOVERYWORLD, we devised three automatic metrics: (1) task completion (a binary metric)."
      },
      {
        "name": "Procedural Process",
        "purpose": "Tracks task-relevant actions to measure partial performance.",
        "application": "Used to assess the procedural steps taken by agents during tasks.",
        "evidence": "A fine-grained report card for each task tracking task-relevant actions, to measure partial performance on relevant discovery procedures."
      },
      {
        "name": "Explanatory Knowledge Discovery",
        "purpose": "Assesses the accuracy of discovered knowledge against a gold reference.",
        "application": "Used to evaluate the knowledge produced by agents during tasks.",
        "evidence": "The accuracy of discovered explanatory knowledge with respect to a gold reference."
      }
    ]
  },
  "method_type": {
    "methods": [
      {
        "name": "Hypothesis or Idea Generation",
        "description": "The system produces candidate hypotheses or new research ideas from prior knowledge or external input.",
        "evidence": "Each task requires an agent to form hypotheses, design and run experiments, analyze results, and act on conclusions."
      },
      {
        "name": "Experimental design generation",
        "description": "The approach includes producing experimental protocols, configurations, or evaluation strategies.",
        "evidence": "Agents can then form hypotheses, plan and execute experiments, and draw conclusions to solve challenge tasks developed for this virtual world."
      }
    ]
  },
  "subject_area": {
    "areas": [
      {
        "name": "Interdisciplinary Sciences",
        "description": "The paper develops a virtual environment for scientific discovery across multiple domains.",
        "evidence": "DISCOVERYWORLD contains a variety of different challenges, covering topics as diverse as radioisotope dating, rocket science, and proteomics."
      }
    ]
  },
  "performance_summary": {
    "performance_summary": [
      {
        "summary": "Strong baseline agents struggle on most DISCOVERYWORLD tasks, indicating the environment captures novel challenges of discovery.",
        "evidence": "We find that strong baseline agents, that perform well in prior published environments, struggle on most DISCOVERYWORLD tasks, suggesting that DISCOVERYWORLD captures some of the novel challenges of discovery."
      }
    ],
    "baselines": [
      {
        "name": "ReAct",
        "description": "An agent using the ReAct approach for generating thoughts and actions.",
        "evidence": "The baseline agents are described below, with model performance on Discovery tasks shown in Table 4."
      },
      {
        "name": "Plan+Execute",
        "description": "An agent using a plan-and-execute approach for task completion.",
        "evidence": "The baseline agents are described below, with model performance on Discovery tasks shown in Table 4."
      },
      {
        "name": "Hypothesizer",
        "description": "An agent maintaining a working memory of hypotheses and measurements.",
        "evidence": "The baseline agents are described below, with model performance on Discovery tasks shown in Table 4."
      }
    ],
    "benchmark_datasets": [
      {
        "name": "DISCOVERYWORLD",
        "data_description": "A virtual environment with 120 tasks across eight topics.",
        "usage": "Used for developing and evaluating AI agents' scientific discovery capabilities.",
        "evidence": "DISCOVERYWORLD contains a variety of different challenges, covering topics as diverse as radioisotope dating, rocket science, and proteomics."
      }
    ],
    "evaluation_metrics": [
      {
        "name": "Task Completion",
        "purpose": "Measures whether the task was completed successfully.",
        "application": "Used to evaluate the overall success of agents in completing tasks.",
        "evidence": "To evaluate agents’ progress in DISCOVERYWORLD, we devised three automatic metrics: (1) task completion (a binary metric)."
      },
      {
        "name": "Procedural Process",
        "purpose": "Tracks task-relevant actions to measure partial performance.",
        "application": "Used to assess the procedural steps taken by agents during tasks.",
        "evidence": "A fine-grained report card for each task tracking task-relevant actions, to measure partial performance on relevant discovery procedures."
      },
      {
        "name": "Explanatory Knowledge Discovery",
        "purpose": "Assesses the accuracy of discovered knowledge against a gold reference.",
        "application": "Used to evaluate the knowledge produced by agents during tasks.",
        "evidence": "The accuracy of discovered explanatory knowledge with respect to a gold reference."
      }
    ]
  },
  "benchmark_dataset": null,
  "limitations": {
    "limitations": [
      {
        "name": "Simulation Fidelity",
        "description": "DISCOVERYWORLD is a low-fidelity representation of the physical world, which may not translate to real-world discovery.",
        "evidence": "DISCOVERYWORLD is inherently a low-fidelity representation of the physical world, with an abstracted action space."
      },
      {
        "name": "Agent Cost",
        "description": "The cost of running LLM inference for DISCOVERYWORLD tasks is high, limiting accessibility.",
        "evidence": "At submission time, these GPT-4O agent models were quite costly, ranging from approximately USD$3k-$10k to run for the complete set of 120 tasks in DISCOVERYWORLD."
      }
    ]
  },
  "future_directions": {
    "future_directions": [
      {
        "name": "Develop Inexpensive Models",
        "description": "Create models that allow for rapid iteration and are cost-effective for long-horizon tasks.",
        "evidence": "We believe that developing inexpensive models that allow for rapid iteration is a clear near-term goal to help facilitate developing discovery agents that must perform long-horizon tasks in this 1000+ step range."
      }
    ]
  },
  "resource_link": {
    "answer": "https://github.com/allenai/discoveryworld",
    "evidence": "Code available at github.com/allenai/discoveryworld."
  }
}