{
  "objective": {
    "answer": "The primary objective of the paper is to investigate whether Large Language Models (LLMs) can assist in intervention targeting for causal discovery by leveraging their rich world knowledge about experimental design.",
    "evidence": "In this work, we investigate a different approach, whether we can leverage Large Language Models (LLMs) to assist with the intervention targeting in causal discovery by making use of the rich world knowledge about the experimental design in LLMs."
  },
  "knowledge_gap": {
    "answer": "The paper addresses the gap of leveraging LLMs for intervention targeting in causal discovery, which has not been explored before.",
    "evidence": "While prior studies emphasize the role of LLMs in causal analysis, the question of whether LLMs can meaningfully contribute to experimental design in causal discovery remains largely unaddressed."
  },
  "novelty": {
    "answer": [
      "The paper introduces the LeGIT framework, which combines LLMs with numerical methods for intervention targeting in causal discovery.",
      "It is the first to explore the use of LLMs in selecting intervention targets for causal discovery.",
      "The framework demonstrates that LLMs can effectively incorporate world knowledge to assist in experimental design."
    ],
    "evidence": [
      "We propose a novel framework called LeGIT that combines the advantages of both the previous numerical methods as well as the LLMs to facilitate the intervening targeting.",
      "To the best of our knowledge, we are the first to investigate the use of LLMs in the experimental design to select intervention targets for causal discovery.",
      "We highlight the promise of LLMs in causal and scientific discovery, that LLMs can effectively incorporate world knowledge, making them valuable cost-efficient complements to humans."
    ]
  },
  "inspirational_papers": {
    "answer": "- Olko et al. (2023) Trust your ∇: Gradient-based intervention targeting for causal discovery. (Methodological precursors)\n- Tigas et al. (2022) Interventions, where and how? experimental design for causal models at scale. (Experimental baselines)",
    "evidence": "Despite the success of GIT method, similar to other estimation-based approaches, GIT is highly sensitive to the accuracy of the gradient estimation and estimated causal graphs which can be extremely noisy in the early rounds of an experiment."
  },
  "method": {
    "steps": [
      {
        "step": "Warmup Stage",
        "input": "Observational dataset and LLMs",
        "output": "Initial intervention targets using LLMs",
        "evidence": "Since at the very beginning of the online causal discovery, numerical-based estimations are noisy and easily mislead the online causal discovery, we begin by prompting LLMs to relate the pre-trained knowledge, analyze the variable description, and suggest influential candidates."
      },
      {
        "step": "Bootstrapped Stage",
        "input": "Intermediate causal discovery results",
        "output": "Additional intervention targets using LLMs",
        "evidence": "We further incorporate a second warmup stage, to bootstrap the use of LLM’s world knowledge in early intervention targeting."
      },
      {
        "step": "Double Selection Stage",
        "input": "Warmup and missing intervention targets",
        "output": "Robust causal structure",
        "evidence": "After getting the warmup and missing intervention target, we perform a double selection to ensure the robustness of the discovered causal structure while minimizing unnecessary interventions."
      },
      {
        "step": "Continual Intervention Stage",
        "input": "Relatively clearer causal graphs",
        "output": "Final intervention targets using numerical methods",
        "evidence": "After the three warmup stages, we have already obtained relatively clearer yet complicated causal graphs. Therefore, we switch to using the numerical-based methods to continue to consume the remaining intervention budgets."
      }
    ],
    "tools": [
      {
        "name": "LLMs",
        "description": "Used for generating initial intervention targets by leveraging world knowledge.",
        "evidence": "We begin by prompting LLMs to relate the pre-trained knowledge, analyze the variable description, and suggest influential candidates."
      },
      {
        "name": "ENCO",
        "description": "Used as the backbone causal discovery algorithm.",
        "evidence": "We utilize ENCO as the backbone causal discovery algorithm, with detailed settings provided in the Appendix."
      }
    ],
    "benchmark_datasets": [
      {
        "name": "Asia",
        "data_description": "8 variables related to a lung cancer diagnosis system.",
        "usage": "Used for evaluating causal discovery methods.",
        "evidence": "Asia dataset consists of 8 variables related to a lung cancer diagnosis system, with 8 edges."
      },
      {
        "name": "Child",
        "data_description": "20 nodes and 25 edges, modeling congenital heart disease in newborns.",
        "usage": "Used for evaluating causal discovery methods.",
        "evidence": "Child dataset contains 20 nodes and 25 edges, modeling congenital heart disease in newborns."
      },
      {
        "name": "Insurance",
        "data_description": "27 nodes and 52 edges, representing a car insurance system.",
        "usage": "Used for evaluating causal discovery methods.",
        "evidence": "Insurance dataset includes 27 nodes and 52 edges, representing a car insurance system."
      },
      {
        "name": "Alarm",
        "data_description": "37 nodes and 46 edges, simulating an alarm message system for patient monitoring.",
        "usage": "Used for evaluating causal discovery methods.",
        "evidence": "Alarm dataset comprises 37 nodes and 46 edges, simulating an alarm message system for patient monitoring."
      }
    ],
    "evaluation_metrics": [
      {
        "name": "Structural Hamming Distance (SHD)",
        "purpose": "Measures the number of edge insertions, deletions, or reversals needed to transform one graph into another.",
        "application": "Used to evaluate the accuracy of the learned causal graph.",
        "evidence": "SHD (lower is better) quantifies the number of edge insertions, deletions, or reversals needed to transform one graph into another."
      },
      {
        "name": "Structural Intervention Distance (SID)",
        "purpose": "Assesses causal inference by evaluating the correctness of the intervention distribution.",
        "application": "Used to evaluate the accuracy of causal inferences.",
        "evidence": "SID (lower is better) assesses causal inference by evaluating the correctness of the intervention distribution."
      },
      {
        "name": "Balanced Scoring Function (BSF)",
        "purpose": "Mitigates bias by balancing the evaluation of edges and independencies within Bayesian Network structures.",
        "application": "Used to evaluate the accuracy of the learned causal graph.",
        "evidence": "BSF (higher is better) mitigates bias by balancing the evaluation of edges and independencies within Bayesian Network structures."
      }
    ]
  },
  "method_type": {
    "methods": [
      {
        "name": "Hypothesis or Idea Generation",
        "description": "The system produces candidate hypotheses or new research ideas from prior knowledge or external input.",
        "evidence": "We prompt the LLM to generate testable hypotheses using domain-specific concepts derived from structured data."
      },
      {
        "name": "Experimental design generation",
        "description": "The approach includes producing experimental protocols, configurations, or evaluation strategies.",
        "evidence": "Our model proposes complete experimental setups including dataset split, evaluation metrics, and variables."
      }
    ]
  },
  "subject_area": {
    "areas": [
      {
        "name": "Interdisciplinary Sciences",
        "description": "The paper explores the integration of LLMs with causal discovery methods, which spans multiple scientific disciplines.",
        "evidence": "We highlight the promise of LLMs in causal and scientific discovery, that LLMs can effectively incorporate world knowledge, making them valuable cost-efficient complements to humans."
      }
    ]
  },
  "performance_summary": {
    "performance_summary": [
      {
        "summary": "LeGIT consistently outperforms baseline approaches across four distinct domains, achieving state-of-the-art causal discovery performances.",
        "evidence": "Our method consistently outperforms the baseline approaches across four distinct domains, as evidenced by SHD calculated from five seeds."
      }
    ],
    "baselines": [
      {
        "name": "GIT",
        "description": "Gradient-based intervention targeting method.",
        "evidence": "We compare LeGIT against different online causal discovery algorithms GIT (Olko et al., 2023)."
      },
      {
        "name": "AIT",
        "description": "Active Intervention Targeting method.",
        "evidence": "We compare LeGIT against different online causal discovery algorithms AIT (Scherrer et al., 2021)."
      },
      {
        "name": "CBED",
        "description": "Causal Bayesian Experimental Design method.",
        "evidence": "We compare LeGIT against different online causal discovery algorithms CBED (Tigas et al., 2022)."
      }
    ],
    "benchmark_datasets": [
      {
        "name": "Asia",
        "data_description": "8 variables related to a lung cancer diagnosis system.",
        "usage": "Used for evaluating causal discovery methods.",
        "evidence": "Asia dataset consists of 8 variables related to a lung cancer diagnosis system, with 8 edges."
      },
      {
        "name": "Child",
        "data_description": "20 nodes and 25 edges, modeling congenital heart disease in newborns.",
        "usage": "Used for evaluating causal discovery methods.",
        "evidence": "Child dataset contains 20 nodes and 25 edges, modeling congenital heart disease in newborns."
      },
      {
        "name": "Insurance",
        "data_description": "27 nodes and 52 edges, representing a car insurance system.",
        "usage": "Used for evaluating causal discovery methods.",
        "evidence": "Insurance dataset includes 27 nodes and 52 edges, representing a car insurance system."
      },
      {
        "name": "Alarm",
        "data_description": "37 nodes and 46 edges, simulating an alarm message system for patient monitoring.",
        "usage": "Used for evaluating causal discovery methods.",
        "evidence": "Alarm dataset comprises 37 nodes and 46 edges, simulating an alarm message system for patient monitoring."
      }
    ],
    "evaluation_metrics": [
      {
        "name": "Structural Hamming Distance (SHD)",
        "purpose": "Measures the number of edge insertions, deletions, or reversals needed to transform one graph into another.",
        "application": "Used to evaluate the accuracy of the learned causal graph.",
        "evidence": "SHD (lower is better) quantifies the number of edge insertions, deletions, or reversals needed to transform one graph into another."
      },
      {
        "name": "Structural Intervention Distance (SID)",
        "purpose": "Assesses causal inference by evaluating the correctness of the intervention distribution.",
        "application": "Used to evaluate the accuracy of causal inferences.",
        "evidence": "SID (lower is better) assesses causal inference by evaluating the correctness of the intervention distribution."
      },
      {
        "name": "Balanced Scoring Function (BSF)",
        "purpose": "Mitigates bias by balancing the evaluation of edges and independencies within Bayesian Network structures.",
        "application": "Used to evaluate the accuracy of the learned causal graph.",
        "evidence": "BSF (higher is better) mitigates bias by balancing the evaluation of edges and independencies within Bayesian Network structures."
      }
    ]
  },
  "benchmark_dataset": {
    "name": "Asia",
    "data_description": "8 variables related to a lung cancer diagnosis system.",
    "usage": "Used for evaluating causal discovery methods.",
    "evidence": "Asia dataset consists of 8 variables related to a lung cancer diagnosis system, with 8 edges."
  },
  "limitations": {
    "limitations": [
      {
        "name": "Limited Context Length of LLMs",
        "description": "LLMs may only focus on a subset of the variables due to limited context length, leading to incomplete intervention targets.",
        "evidence": "Due to the intrinsic limitations of LLMs such as limited context length (Liu et al., 2023) and hallucination (Zhang et al., 2023b), LLMs may only focus on a subset of the variables and find the influential nodes therein."
      },
      {
        "name": "Noisy Estimations in Early Rounds",
        "description": "Numerical-based estimations are noisy and can mislead the online causal discovery in the early rounds.",
        "evidence": "Since at the very beginning of the online causal discovery, numerical-based estimations are noisy and easily mislead the online causal discovery."
      }
    ]
  },
  "future_directions": {
    "future_directions": [
      {
        "name": "Explore Soft Interventions",
        "description": "Investigate the use of soft interventions, which adjust variable dependencies without removing them.",
        "evidence": "Soft interventions, which adjust variable dependencies without removing them, are beyond this study’s scope but may be explored in future research."
      },
      {
        "name": "Extend to Other Gradient-Based Methods",
        "description": "Explore the compatibility of LeGIT with other gradient-based causal discovery methods.",
        "evidence": "Consistent with prior work, we mainly adopt GIT as the numerical-based method M, and ENCO as the gradient-based causal discovery method. However, as also suggested in GIT (Olko et al., 2023), ENCO can also be switched to other gradient-based methods."
      }
    ]
  },
  "resource_link": {
    "answer": "https://causalcoat.github.io/legit",
    "evidence": "https://causalcoat.github.io/legit"
  }
}