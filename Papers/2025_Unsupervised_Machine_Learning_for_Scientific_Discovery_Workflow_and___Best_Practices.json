{
  "objective": {
    "answer": "The primary objective of the paper is to present a structured workflow for using unsupervised learning techniques in scientific discovery, with a focus on ensuring reliable and reproducible results. The authors aim to address the lack of standardization in unsupervised learning workflows by providing best practices and illustrating their proposed workflow through a case study in astronomy.",
    "evidence": "In this paper, we present a structured workflow for using unsupervised learning techniques in science. We highlight and discuss best practices starting with formulating validatable scientific questions, conducting robust data preparation and exploration, using a range of modeling techniques, performing rigorous validation by evaluating the stability and generalizability of unsupervised learning conclusions, and promoting effective communication and documentation of results to ensure reproducible scientific discoveries."
  },
  "knowledge_gap": {
    "answer": "There is a lack of well-established best practices and specific workflow procedures for producing robust, reproducible discoveries using unsupervised learning.",
    "evidence": "Though unsupervised discovery is an extremely important facet of modern data science and machine learning, there is currently a lack of well-established best practices and specific workflow procedures for producing robust, reproducible discoveries using unsupervised learning."
  },
  "novelty": {
    "answer": [
      "The paper introduces a model-agnostic workflow for unsupervised learning aimed at producing data-driven discoveries.",
      "The authors propose a stability-driven model building approach that assesses cluster stability across different preprocessing pipelines.",
      "The paper emphasizes the importance of validation techniques to assess the reliability of results across all facets of the workflow."
    ],
    "evidence": [
      "In this section, we present a model-agnostic workflow for unsupervised learning for the task of producing data-driven discoveries.",
      "Our approach is heavily driven by the philosophy that our scientific conclusions should be stable and generalizable regardless of which specific analytical choices are made.",
      "Validation techniques are needed to assess reliability of results across all facets of the workflow."
    ]
  },
  "inspirational_papers": {
    "answer": "- Monti et al. (2003) Consensus clustering: A resampling-based method for class discovery and visualization of gene expression microarray data. (Methodological precursors)\n- Tibshirani and Walther (2005) Cluster validation by prediction strength. (Experimental baselines)",
    "evidence": "Consensus clustering [113, 70] aggregates results from repeated clustering runs on data subsamples into a single metric that is weighted towards agreement of clustering assignments between each pair of observations across iterations. Similarly for graphical models, StARS [101] measures stability via agreement of edge selections between pairs of features across model estimates from resampled data sets."
  },
  "method": {
    "steps": [
      {
        "step": "Formulate the scientific question and determine the type of data to be collected or used.",
        "input": "Literature review and discussion with domain experts.",
        "output": "A validatable scientific question and a plan for data collection.",
        "evidence": "The first step in creating an unsupervised learning workflow is to formulate the scientific question to be answered and to determine the type of data that will be collected or used to answer this question."
      },
      {
        "step": "Perform data preparation and exploration.",
        "input": "Collected data.",
        "output": "Prepared data ready for modeling.",
        "evidence": "Once data have been collected, data preparation and exploration should be performed before modeling in order to ensure computational feasibility, to improve overall modeling results, and to aid in understanding and contextualization of findings."
      },
      {
        "step": "Select and apply unsupervised learning models.",
        "input": "Prepared data.",
        "output": "Modeling results.",
        "evidence": "In this step, the unsupervised learning models for analysis are selected and applied."
      },
      {
        "step": "Determine validation techniques for the results.",
        "input": "Modeling results.",
        "output": "Validated results.",
        "evidence": "After selection of the models that will be used for analyzing the data, techniques and procedures for validating the results produced by said modeling procedures should be determined."
      },
      {
        "step": "Communicate ideas, results, and insights.",
        "input": "Validated results.",
        "output": "Communicated findings.",
        "evidence": "Lastly, strategies for communication of ideas, results, and insights need to be determined for the workflow."
      }
    ],
    "tools": [
      {
        "name": "APOGEE DR17",
        "description": "Used as the dataset for the case study in astronomy.",
        "evidence": "We leverage data from the APOGEE DR17 value-added catalogue of GCs."
      },
      {
        "name": "tSNE",
        "description": "Used for dimension reduction and visualization.",
        "evidence": "We next explore various dimension reduction techniques. To identify appropriate hyperparameters for these methods, we evaluate the neighbor retention metric for various dimension reduction methods and hyperparameters."
      },
      {
        "name": "K-means clustering",
        "description": "Used for clustering stars in the case study.",
        "evidence": "Seeking new insights beyond these known divisions, we instead shift our interest towards the eight clusters generated by K-means."
      }
    ],
    "benchmark_datasets": [
      {
        "name": "APOGEE DR17",
        "data_description": "High-resolution, near-infrared survey of stars comprising the disk of the Milky Way.",
        "usage": "Used for clustering stars chemically to identify shared origins and trace the history of the Milky Way.",
        "evidence": "We leverage data from the APOGEE DR17 value-added catalogue of GCs."
      }
    ],
    "evaluation_metrics": [
      {
        "name": "Adjusted Rand Index (ARI)",
        "purpose": "Measures the similarity between two data clusterings.",
        "application": "Used to assess the stability of clustering results.",
        "evidence": "Here, we measure the overall stability (or similarity) between two sets of clusters using the Adjusted Rand Index (ARI)."
      },
      {
        "name": "Neighborhood retention metric",
        "purpose": "Measures the proportion of nearest neighbors maintained from the original high-dimensional space to the low-dimensional embedding.",
        "application": "Used to tune hyperparameters for dimension reduction methods.",
        "evidence": "To identify appropriate hyperparameters for these methods, we evaluate the neighbor retention metric for various dimension reduction methods and hyperparameters."
      }
    ]
  },
  "method_type": {
    "methods": [
      {
        "name": "Hypothesis or Idea Generation",
        "description": "The system produces candidate hypotheses or new research ideas from prior knowledge or external input.",
        "evidence": "Specification of the scientific question is pivotal for defining the overall direction of the workflow and research project as a whole."
      },
      {
        "name": "Experimental design generation",
        "description": "The approach includes producing experimental protocols, configurations, or evaluation strategies.",
        "evidence": "Before delving into discussions of the further parts of the unsupervised learning workflow, we pause to stress that the entire plan for modeling and validation should be planned out in this step as well."
      }
    ]
  },
  "subject_area": {
    "areas": [
      {
        "name": "Interdisciplinary Sciences",
        "description": "The paper develops a general workflow for unsupervised learning applicable across various scientific domains.",
        "evidence": "In this paper, we present a structured workflow for using unsupervised learning techniques in science."
      },
      {
        "name": "Earth & Environmental Sciences",
        "description": "The case study in the paper focuses on astronomy, specifically the chemical origins of the Milky Way.",
        "evidence": "To illustrate our proposed workflow, we present a case study from astronomy, seeking to refine globular clusters of Milky Way stars based upon their chemical composition."
      }
    ]
  },
  "performance_summary": {
    "performance_summary": [
      {
        "summary": "The stability-driven clustering model selection identified spectral clustering with k=2 as the most stable, but K-means with k=8 was chosen for uncovering novel groupings.",
        "evidence": "Seeking new insights beyond these known divisions, we instead shift our interest towards the eight clusters generated by K-means."
      }
    ],
    "baselines": [
      {
        "name": "Spectral Clustering",
        "description": "Used as a baseline for stability-driven clustering model selection.",
        "evidence": "Spectral clustering with 60 nearest neighbors at k = 2 has the highest overall mean stability."
      }
    ],
    "benchmark_datasets": [
      {
        "name": "APOGEE DR17",
        "data_description": "High-resolution, near-infrared survey of stars comprising the disk of the Milky Way.",
        "usage": "Used for clustering stars chemically to identify shared origins and trace the history of the Milky Way.",
        "evidence": "We leverage data from the APOGEE DR17 value-added catalogue of GCs."
      }
    ],
    "evaluation_metrics": [
      {
        "name": "Adjusted Rand Index (ARI)",
        "purpose": "Measures the similarity between two data clusterings.",
        "application": "Used to assess the stability of clustering results.",
        "evidence": "Here, we measure the overall stability (or similarity) between two sets of clusters using the Adjusted Rand Index (ARI)."
      },
      {
        "name": "Neighborhood retention metric",
        "purpose": "Measures the proportion of nearest neighbors maintained from the original high-dimensional space to the low-dimensional embedding.",
        "application": "Used to tune hyperparameters for dimension reduction methods.",
        "evidence": "To identify appropriate hyperparameters for these methods, we evaluate the neighbor retention metric for various dimension reduction methods and hyperparameters."
      }
    ]
  },
  "benchmark_dataset": {
    "name": "APOGEE DR17",
    "data_description": "High-resolution, near-infrared survey of stars comprising the disk of the Milky Way.",
    "usage": "Used for clustering stars chemically to identify shared origins and trace the history of the Milky Way.",
    "evidence": "We leverage data from the APOGEE DR17 value-added catalogue of GCs."
  },
  "limitations": {
    "limitations": [
      {
        "name": "Limited Generalizability",
        "description": "The clustering results may not generalize well to other datasets or domains due to the specific nature of the APOGEE data.",
        "evidence": "While promising, we emphasize further research is needed to scientifically validate these clusters, ideally with a collaborating astronomer."
      },
      {
        "name": "Sensitivity to Preprocessing Choices",
        "description": "The clustering results are sensitive to different preprocessing choices, which may affect the stability and generalizability of the findings.",
        "evidence": "Notably, several clusters - 1, 2, and 8 - show strong co-clustering membership, but others - 3, 7 - show high variability in co-clustering membership across pipelines."
      }
    ]
  },
  "future_directions": {
    "future_directions": [
      {
        "name": "Integrate Other Catalogs",
        "description": "Future research may seek to integrate other commonly used value-added catalogs from APOGEE or other spectroscopic sky surveys.",
        "evidence": "Further research into clustering astronomical survey data may seek to integrate other commonly used value-added catalogs from APOGEE such as annotated age labels."
      },
      {
        "name": "Collaborate with Astronomers",
        "description": "Collaborate with astronomers to scientifically validate the clusters and explore their implications.",
        "evidence": "While promising, we emphasize further research is needed to scientifically validate these clusters, ideally with a collaborating astronomer."
      }
    ]
  },
  "resource_link": {
    "answer": "https://github.com/DataSlingers/unsupervised-workflow-astro",
    "evidence": "For all code, documentation, justification of preprocessing and modeling choices, and more in-depth validation analyses and results, please see our Interactive Supplement at https://dataslingers.github.io/unsupervised-workflow-astro/ and GitHub repository https://github.com/DataSlingers/unsupervised-workflow-astro."
  }
}