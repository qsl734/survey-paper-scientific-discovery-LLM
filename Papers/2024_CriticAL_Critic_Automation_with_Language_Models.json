{
  "objective": {
    "answer": "The primary objective of the paper is to introduce CriticAL, a framework that uses large language models (LLMs) to automate the criticism of scientific models by generating summary statistics and applying hypothesis tests to evaluate discrepancies between model predictions and data.",
    "evidence": "Motivated by this, we introduce CriticAL (Critic Automation with Language Models). CriticAL uses LLMs to generate summary statistics that capture discrepancies between model predictions and data, and applies hypothesis tests to evaluate their significance."
  },
  "knowledge_gap": {
    "answer": "The paper addresses the gap in automating model criticism, which is traditionally dependent on human expertise to evaluate discrepancies between models and data, a process that is challenging to automate due to its reliance on understanding modeling assumptions and domain knowledge.",
    "evidence": "Model criticism is hard to automate because it is inherently dependent on the model and problem domain. In particular, it involves (1) determining which aspects to compare between the model and data and (2) evaluating the significance of any differences. Each of these tasks typically requires substantial human expertise."
  },
  "novelty": {
    "answer": [
      "CriticAL integrates LLMs within a principled model criticism framework to automate the generation of summary statistics tailored to specific models and datasets.",
      "CriticAL converts summary statistics into hypothesis tests to rigorously assess the significance of discrepancies between models and data.",
      "CriticAL provides natural language critiques to facilitate integration with broader scientific discovery systems."
    ],
    "evidence": [
      "CriticAL uses an LLM to generate summary statistics that capture properties of the data that might violate the modeling assumptions.",
      "We show how we can automatically convert the summary statistics produced by CriticAL into hypothesis tests, for many commonly-used scientific models.",
      "CriticAL also produces natural language criticism. This design choice is motivated by several considerations."
    ]
  },
  "inspirational_papers": {
    "answer": "- Li et al. (2024) Automated Statistical Model Discovery with Language Models. (Experimental baselines)\n- Bayarri & Berger (2000) P values for composite null models. (Methodological precursors)\n- Gelman et al. (1996) Posterior predictive assessment of model fitness via realized discrepancies. (Methodological precursors)",
    "evidence": "CriticAL’s critiques enable an LLM-based automated model discovery system [17] to significantly improve upon initial human-designed models.\nBayarri & Berger [2] introduce a framework for understanding these inadequacies that involves defining domain-specific evaluation criteria or performing sensitivity analyses.\nA common technique for evaluating such a model is a posterior predictive check (PPC) [4, 8, 20, 22]."
  },
  "method": {
    "steps": [
      {
        "step": "Generate summary statistics using LLMs",
        "input": "Dataset metadata and a symbolic representation of a model",
        "output": "Summary statistics tailored to the model and dataset",
        "evidence": "CriticAL uses an LLM to generate summary statistics that capture properties of the data that might violate the modeling assumptions."
      },
      {
        "step": "Convert summary statistics into hypothesis tests",
        "input": "Summary statistics and model samples",
        "output": "Empirical p-values indicating the significance of discrepancies",
        "evidence": "We show how we can automatically convert the summary statistics produced by CriticAL into hypothesis tests, for many commonly-used scientific models."
      },
      {
        "step": "Produce natural language criticism",
        "input": "Test statistic and its p-value",
        "output": "Natural language summary of the discrepancy",
        "evidence": "We prompt an LLM to produce natural language criticism hk that summarizes the discrepancy implied by test statistic Tk and its p-value ˜pk."
      }
    ],
    "tools": [
      {
        "name": "gpt-4-turbo-2024-04-09",
        "description": "Used to propose test statistics",
        "evidence": "For our test statistic proposer, we use gpt-4-turbo-2024-04-09."
      },
      {
        "name": "pymc",
        "description": "Used for fitting models proposed by the revision LLM",
        "evidence": "We fit the models proposed by the revision LLM using pymc [1]."
      }
    ],
    "benchmark_datasets": [
      {
        "name": "Stan PosteriorDB",
        "data_description": "Real-world datasets and probabilistic models implemented in Stan",
        "usage": "Used to evaluate CriticAL on real-world model-dataset pairs",
        "evidence": "The Stan PosteriorDB database [19] consists of real-world datasets and probabilistic models implemented in Stan."
      }
    ],
    "evaluation_metrics": [
      {
        "name": "True Positive Rate",
        "purpose": "Measures the proportion of actual discrepancies correctly identified",
        "application": "Used to evaluate CriticAL's ability to discover true discrepancies",
        "evidence": "We show the true and false positive rates of CriticAL."
      },
      {
        "name": "False Positive Rate",
        "purpose": "Measures the proportion of no-discovery pairs incorrectly identified as having discrepancies",
        "application": "Used to evaluate CriticAL's ability to avoid hallucinations",
        "evidence": "We show the true and false positive rates of CriticAL."
      }
    ]
  },
  "method_type": {
    "methods": [
      {
        "name": "Hypothesis or Idea Generation",
        "description": "The system produces candidate hypotheses or new research ideas from prior knowledge or external input.",
        "evidence": "CriticAL uses an LLM to generate summary statistics that capture properties of the data that might violate the modeling assumptions."
      },
      {
        "name": "Experimental design generation",
        "description": "The approach includes producing experimental protocols, configurations, or evaluation strategies.",
        "evidence": "We describe how CriticAL uses the test statistics to identify significant discrepancies."
      }
    ]
  },
  "subject_area": {
    "areas": [
      {
        "name": "Interdisciplinary Sciences",
        "description": "The paper develops a framework for automating model criticism applicable across various scientific domains.",
        "evidence": "While our evaluation was limited to Bayesian models, which are commonly used in scientific domains, CriticAL’s design is versatile."
      }
    ]
  },
  "performance_summary": {
    "performance_summary": [
      {
        "summary": "CriticAL consistently identifies true discrepancies and avoids hallucinating false ones, outperforming naive LLM critics.",
        "evidence": "CriticAL correctly identifies more discrepancies than the pre-specified method, at the same FPR level."
      }
    ],
    "baselines": [
      {
        "name": "Naive LLM critic",
        "description": "A baseline approach that receives initial statistical models and dataframes to identify discrepancies.",
        "evidence": "We implement a naive approach to model criticism that receives (1) an initial statistical model represented as a pymc [1] program (2) a dataframe of the posterior predictive mean radon predictions."
      }
    ],
    "benchmark_datasets": [
      {
        "name": "Stan PosteriorDB",
        "data_description": "Real-world datasets and probabilistic models implemented in Stan",
        "usage": "Used to evaluate CriticAL on real-world model-dataset pairs",
        "evidence": "The Stan PosteriorDB database [19] consists of real-world datasets and probabilistic models implemented in Stan."
      }
    ],
    "evaluation_metrics": [
      {
        "name": "True Positive Rate",
        "purpose": "Measures the proportion of actual discrepancies correctly identified",
        "application": "Used to evaluate CriticAL's ability to discover true discrepancies",
        "evidence": "We show the true and false positive rates of CriticAL."
      },
      {
        "name": "False Positive Rate",
        "purpose": "Measures the proportion of no-discovery pairs incorrectly identified as having discrepancies",
        "application": "Used to evaluate CriticAL's ability to avoid hallucinations",
        "evidence": "We show the true and false positive rates of CriticAL."
      }
    ]
  },
  "benchmark_dataset": {
    "name": "Stan PosteriorDB",
    "data_description": "Real-world datasets and probabilistic models implemented in Stan",
    "usage": "Used to evaluate CriticAL on real-world model-dataset pairs",
    "evidence": "The Stan PosteriorDB database [19] consists of real-world datasets and probabilistic models implemented in Stan."
  },
  "limitations": {
    "limitations": [
      {
        "name": "Suboptimal transformations of data",
        "description": "CriticAL does not see the model predictions or data, leading to poor critiques on data transformations.",
        "evidence": "CriticAL sometimes does not provide good critiques on transforming data. This happens most prominently in the mesquite setting where the model predictions can be negative even though the data is non-negative."
      },
      {
        "name": "Correct criticism but imperfect implementation",
        "description": "CriticAL identifies legitimate discrepancies, but the revision LLM may incorrectly implement them.",
        "evidence": "In some cases, CriticAL identifies a legitimate discrepancy that the revision LLM incorrectly implements."
      }
    ]
  },
  "future_directions": {
    "future_directions": [
      {
        "name": "Explore other scientific models",
        "description": "Extend CriticAL's framework to other common classes of scientific models beyond Bayesian models.",
        "evidence": "An exploration of other common classes of scientific models [6] is an exciting direction for future work."
      }
    ]
  },
  "resource_link": {
    "answer": "",
    "evidence": ""
  }
}