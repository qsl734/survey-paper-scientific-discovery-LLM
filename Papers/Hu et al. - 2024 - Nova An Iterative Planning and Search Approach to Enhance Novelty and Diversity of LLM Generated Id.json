{
  "objective": {
    "answer": "The primary objective of the paper is to introduce an enhanced iterative planning and search methodology to improve the novelty and diversity of research ideas generated by large language model-based systems. The authors aim to address the problem of simplistic and repetitive suggestions produced by existing large language models due to their limited ability to acquire external knowledge for innovation.",
    "evidence": "To address this problem, we introduce an enhanced planning and search methodology designed to boost the creative potential of LLM-based systems. Our approach involves an iterative process to purposely plan the retrieval of external knowledge, progressively enriching the idea generation with broader and deeper insights."
  },
  "knowledge_gap": {
    "answer": "Existing large language model-based systems for research idea generation often produce repetitive and simplistic ideas due to a constrained scope and lack of direction in external knowledge acquisition, limiting their ability to foster true innovation.",
    "evidence": "However, they also show that 'LLMs lack diversity in idea generation'. We argue that this repetitive problem is due to the constrained scope and lack of direction in knowledge acquisition within these methods."
  },
  "novelty": {
    "answer": [
      "Introduction of an iterative planning framework that guides large language models to devise search plans for targeted external knowledge retrieval, enhancing novelty and diversity in idea generation.",
      "Integration of multi-source seed idea generation using recent literature, scientific discovery methods, and knowledge tracking based on user engagement metrics.",
      "Application of self-correction mechanics (self-check, self-critique, and reflection) to improve the logicality and reduce hallucination in generated ideas.",
      "Demonstration of significant improvements in both the number and quality of unique novel ideas compared to state-of-the-art methods."
    ],
    "evidence": [
      "In order to address the above problem, we introduce an iterative planning framework for LLM-based idea generation that specifically targets the enhancement of the novelty and diversity of the ideas produced.",
      "To produce high-quality ideas, we design a multi-source seed idea generation module that initiates with diverse and novel concepts. ... We pinpoint influential recent papers based on user engagement metrics such as likes, comments, and reposts across social media, forums, and GitHub.",
      "To prevent hallucination and improve the logicality of generated initial seed ideas, we also utilize self-correction mechanics: self-check (Miao et al., 2023), self-critique (Gou et al., 2024), and reflection (Shinn et al., 2023).",
      "The number of unique novel ideas produced by our framework is 3.4 times higher than without it. Moreover, our method outperforms the current state-of-the-art, generating at least 2.5 times more top-rated ideas based on 170 seed papers in a Swiss Tournament evaluation."
    ]
  },
  "inspirational_papers": {
    "answer": [
      "Si et al. (2024) Introduced AI-Researcher, which demonstrated that large language models can generate ideas deemed more novel than those written by human experts, but noted a lack of diversity. (Methodological precursors, limitations addressed)",
      "Baek et al. (2024) Proposed a research agent that utilizes an external knowledge graph for co-occurrence entity search and integrates retrieved entities into idea generation. (Methodological precursors)",
      "Lu et al. (2024) Treated past generated ideas as negative examples to avoid generating similar ideas. (Methodological precursors)",
      "Wang et al. (2024b) Enriched idea generation by incorporating co-occurrence entities with existing knowledge. (Methodological precursors)"
    ],
    "evidence": [
      "Concurrent with our research, Si et al. (2024) introduce AI-Researcher, which, for the first time, demonstrates that LLMs can generate ideas deemed more novel than those written by human experts. In addition, they point out that using LLMs to directly evaluate different dimensions of scientific ideas is unreliable and propose an idea ranking method based on pairwise comparison, achieving an accuracy of 71.4% in distinguishing accepted and rejected submissions on real ICLR 2024 data.",
      "Among these studies, Baek et al. (2024) introduces a research agent that utilizes an external knowledge graph for co-occurrence entity search and integrates retrieved entities into idea generation of LLMs.",
      "To avoid generating similar ideas, Lu et al. (2024) treat past generated ideas as negative examples and instruct the LLM on what constitutes a negative example.",
      "Wang et al. (2024b) enrich the process by incorporating co-occurrence entities with existing knowledge, prompting LLMs to generate ideas based on these entities."
    ]
  },
  "method": {
    "steps": [
      {
        "step": "Initial Seed Idea Generation",
        "input": "Input paper (seed paper), its references, recent publications, and scientific discovery methods.",
        "output": "A set of 15 diverse and novel seed ideas for each input paper.",
        "tools": [
          "Large Language Model: Used to generate initial ideas based on prompts.",
          "Knowledge Tracking Module: Monitors latest publications and user engagement metrics.",
          "Self-correction Mechanics: Self-check, self-critique, and reflection to improve logicality."
        ],
        "evidence": "Upon receiving an input paper (i.e., seed paper), the LLM is prompted to generate initial seed ideas by utilizing related papers (including recent publications) and scientific discovery methods."
      },
      {
        "step": "Iterative Planning and Search for Seed Idea Improvement",
        "input": "Initial seed idea pool, current set of ideas, and external literature.",
        "output": "New seed ideas generated based on newly acquired knowledge, replacing old seed ideas in each iteration.",
        "tools": [
          "Large Language Model: Guides planning and generates new ideas.",
          "In-context Learning: Leverages LLM’s internal knowledge to determine useful knowledge for new ideas."
        ],
        "evidence": "In planning and search step, we guide the LLM to identify key fields for comprehensive and novel knowledge acquisition to enhance further research and idea generation based on the given ideas."
      },
      {
        "step": "Output Idea Generation",
        "input": "Final seed idea pool after T iterations.",
        "output": "Detailed research proposals, with ideas decomposed into sub-modules and expanded.",
        "tools": [
          "Large Language Model: Decomposes and expands ideas into detailed proposals."
        ],
        "evidence": "After finishing T step iteration, we have a final seed idea pool. We then expand the seed idea into the initial proposal and final proposal as in (Si et al., 2024)."
      }
    ],
    "tools": [
      "Large Language Model: Used throughout for idea generation, planning, and proposal expansion.",
      "Knowledge Tracking Module: Identifies recent influential papers using user engagement metrics.",
      "Self-correction Mechanics: Self-check, self-critique, and reflection to improve logicality and reduce hallucination.",
      "In-context Learning: Guides the LLM to determine useful knowledge for new ideas."
    ],
    "evidence": [
      "Our pipeline streamlines the research process through three stages: initial idea generation, iterative refinement, and detailed completion.",
      "To enrich the knowledge base with the most current insights, we utilize the input paper’s references and have designed a knowledge tracking module.",
      "To prevent hallucination and improve the logicality of generated initial seed ideas, we also utilize self-correction mechanics: self-check (Miao et al., 2023), self-critique (Gou et al., 2024), and reflection (Shinn et al., 2023)."
    ]
  },
  "subject_area": {
    "areas": [
      "Applied Sciences & Engineering",
      "Social Sciences"
    ],
    "evidence": [
      "Our work is dedicated to addressing the challenge of employing LLMs to produce high-caliber research ideas, with an emphasis on enhancing their novelty and diversity.",
      "These progresses have opened up new possibilities to utilize LLMs to accelerate research (Wang et al., 2023a), including generating novel research ideas (Si et al., 2024; Wang et al., 2024b; Baek et al., 2024)."
    ]
  },
  "performance_summary": {
    "performance_summary": [
      "Nova generates 3.4 times more unique novel ideas than the baseline without iterative planning.",
      "Nova produces at least 2.5 times more top-rated ideas (Swiss Tournament Score 5) compared to state-of-the-art methods on 170 seed papers.",
      "Nova achieves significantly higher Swiss Tournament scores, with 619 and 2521 ideas scored at 4 and 5, respectively, surpassing all baselines.",
      "Nova generates over 80% unique ideas, significantly outperforming other methods in diversity.",
      "Human evaluation confirms Nova contributes the highest proportion of top-rated ideas and the lowest proportion of worst-rated ideas."
    ],
    "baselines": [
      "AI-Researcher (Si et al., 2024): Uses retrieval-augmented generation and pairwise ranking for idea evaluation.",
      "AI-Scientist (Lu et al., 2024): Treats past generated ideas as negative examples to avoid repetition.",
      "Research-Agent (Baek et al., 2024): Utilizes an external knowledge graph for co-occurrence entity search and idea generation."
    ],
    "benchmark_datasets": [
      "A dataset of 170 high-quality papers from top conferences (CVPR 2024, ACL 2024, ICLR 2024), filtered for LLM relevance and citation count, each used to generate 100 ideas for evaluation."
    ],
    "evaluation_metrics": [
      "Swiss System Tournament Score: Uses pairwise comparisons (5 rounds per idea) to determine idea quality, with higher scores indicating better ideas.",
      "Novelty: Judged by LLMs using top 10 most relevant papers; if no similar idea is found (cosine similarity threshold > 0.3), the idea is considered novel.",
      "Diversity: Measured by the proportion of unique ideas using cosine similarity (duplication threshold 0.8).",
      "Human Evaluation: Experts rate ideas on novelty and overall quality, identifying best and worst ideas."
    ],
    "evidence": [
      "The number of unique novel ideas produced by our framework is 3.4 times higher than without it. Moreover, our method outperforms the current state-of-the-art, generating at least 2.5 times more top-rated ideas based on 170 seed papers in a Swiss Tournament evaluation.",
      "The Swiss Tournament score comparison are shown in Fig. 4. The novelty and diversity comparison are shown in Fig. 5.",
      "In our human evaluation, Nova achieves the highest scores for both overall quality and novelty.",
      "Our dataset is constructed by collecting high-quality papers from top conferences. The initial corpus comprised 7,805 papers from CVPR 2024, ACL 2024, and ICLR 2024. ... the dataset consists of 170 papers, each of which is used to generate 100 ideas for subsequent evaluation.",
      "Following Si et al. (2024), we employ the Swiss System Tournament with Claude-3.5-Sonnet zero-shot ranker to evaluate the quality of ideas. The ranker makes pairwise comparisons to determine which idea is better. For each idea, there are 5 rounds of comparison, each winning comparison gets 1 score.",
      "Following Baek et al. (2024), we use LLMs to judge whether a generated idea is novel by checking the top 10 most relevant papers and if no paper is identified as containing a similar idea, it is considered novel.",
      "Similar to Si et al. (2024), we use the proportion of unique ideas to measure generation diversity. To be specific, we use the same similarity measurement as in the novelty measurement and the duplication threshold is set to be 0.8.",
      "We recruit a panel of 10 experts, all holding a PhD degree or professorship in natural language processing, machine learning, or computer vision, doing research in LLMs-related fields. These experts evaluated ideas based on novelty and overall quality (including feasibility and effectiveness)."
    ]
  },
  "limitations": {
    "limitations": [
      {
        "label": "Limited Iteration Steps",
        "explanation": "The method does not show continuous improvement in generating new ideas after three rounds of iteration.",
        "evidence": "Limited Iterations Steps. Although our approach can significantly enhance the novelty and diversity of generated ideas through iteration, we do not see a continuous increment in generating new ideas after 3 rounds of iteration."
      },
      {
        "label": "Planning without Rewards",
        "explanation": "The planning and search framework does not incorporate reward functions, potentially limiting planning effectiveness.",
        "evidence": "Planning without Rewards. In our planning and search framework, we do not introduce reward functions but only use the internal knowledge of LLMs to generate search plans. This may limit the effectiveness of planning."
      }
    ],
    "evidence": [
      "Limited Iterations Steps. Although our approach can significantly enhance the novelty and diversity of generated ideas through iteration, we do not see a continuous increment in generating new ideas after 3 rounds of iteration.",
      "Planning without Rewards. In our planning and search framework, we do not introduce reward functions but only use the internal knowledge of LLMs to generate search plans. This may limit the effectiveness of planning."
    ]
  },
  "future_directions": {
    "future_directions": [
      "Incorporate a reward function into the iterative planning framework to further enhance external knowledge retrieval.",
      "Explore methods for more comprehensive integration of both internal and external knowledge for large language model-based scientific innovation.",
      "Investigate approaches to enhance the generation diversity by improving models or refining the ideation process.",
      "Explore other methods of human-AI collaboration to address potential negative consequences of AI integration in research."
    ],
    "evidence": [
      "In the future, we will explore incorporating a reward function into our iterative planning framework to further enhance external knowledge retrieval.",
      "We hope these findings inspire future investigations into using LLM to comprehensively integrate both internal and external knowledge for LLM-based scientific innovation.",
      "Therefore, it is important to recognize the limitations of current LLM-generated ideas, and future work should focus more on enhancing the generation diversity either by improving the models themselves or by refining the ideation process.",
      "Future works should explore other methods of human-AI collaboration. Understanding how LLM should be integrated into the research process will be an ongoing problem."
    ]
  },
  "resource_link": {
    "answer": "",
    "evidence": "No code repository, project website, or data repository link is provided in the paper."
  },
  "paper_title": "Nova: An Iterative Planning and Search Approach to Enhance Novelty and Diversity of LLM Generated Ideas",
  "authors": [
    "Xiang",
    "Hongyu",
    "Jinge",
    "Yifeng",
    "Zhikun",
    "Renjun",
    "Yu",
    "Yaochu",
    "Lili",
    "Zhenzhong"
  ],
  "published": "2024-10-27",
  "link": "http://arxiv.org/abs/2410.14255"
}