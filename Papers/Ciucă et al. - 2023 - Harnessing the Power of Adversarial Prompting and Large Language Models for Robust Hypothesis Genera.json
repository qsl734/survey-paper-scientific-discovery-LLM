{
  "objective": {
    "answer": "The primary objective of the paper is to investigate the application of large language models, specifically GPT-4, for robust hypothesis generation in astronomy using in-context and adversarial prompting. The authors aim to determine whether immersing the model in domain-specific literature and employing adversarial prompting can significantly improve the quality and relevance of generated scientific hypotheses in Galactic Astronomy.",
    "evidence": "This study investigates the application of Large Language Models (LLMs), specifically GPT-4, within Astronomy. We employ in-context prompting, supplying the model with up to 1000 papers from the NASA Astrophysics Data System, to explore the extent to which performance can be improved by immersing the model in domain-specific literature. Our findings point towards a substantial boost in hypothesis generation when using in-context prompting, a benefit that is further accentuated by adversarial prompting."
  },
  "knowledge_gap": {
    "answer": "There is a lack of effective methods for leveraging large language models to generate robust, domain-specific scientific hypotheses in astronomy, particularly due to limited inclusion of astronomical literature in model training and the challenge of connecting knowledge across subfields.",
    "evidence": "Although the field is rich in literature, the inclusion of such text in the vast corpus used to train GPT models is probably limited. This lack leads to noticeable hallucination problems when employing naive versions of LLMs (Ciuc˘a et al., 2023). Secondly, unlike domains that focus more on intensive, detailed studies, advancements in astronomy often stem from “connecting the dots” across different subfields due to the universality of underlying physical processes at various scales."
  },
  "novelty": {
    "answer": [
      "Application of adversarial prompting in conjunction with in-context prompting to enhance hypothesis generation quality in astronomy.",
      "Use of up to 1000 domain-specific papers as in-context prompts for GPT-4 to immerse the model in astronomical literature.",
      "Development of a multi-step adversarial workflow where hypotheses generated by GPT-4 are critiqued and refined through additional GPT-4 instances.",
      "Visualization and analysis of the 'knowledge footprint' of generated hypotheses to assess how context and adversarial prompting affect knowledge integration."
    ],
    "evidence": [
      "We illustrate how adversarial prompting empowers GPT-4 to extract essential details from a vast knowledge base to produce meaningful hypotheses, signaling an innovative step towards employing LLMs for scientific research in Astronomy.",
      "We employ in-context prompting, supplying the model with up to 1000 papers from the NASA Astrophysics Data System...",
      "This idea is then critiqued by a second GPT-4 model, and the feedback is moderated by a third GPT-4 model.",
      "For each hypothesis generated, we determined which papers inspired it by querying the GPT model. In Fig. 3, we visualized this ‘knowledge footprint’ for each hypothesis as black polygons within a green hull representing all the papers GPT-4 had access to."
    ]
  },
  "inspirational_papers": {
    "answer": [
      "Ciucă et al. (2023) Their findings on the Gaia-Sausage-Enceladus merger influenced the design of hypothesis generation tasks. (Experimental baselines)",
      "Kuzma et al. (2021) Their probabilistic approach for studying globular clusters inspired the methodology for hypothesis generation. (Methodological precursors)",
      "Peebles (1984); Peñarrubia et al. (2017) Their work on dark matter mini-halos provided foundational context for hypothesis formulation. (Methodological precursors)",
      "Antoja et al. (2015); Gorski and Barmby (2020); Yuan et al. (2014); An and Beers (2020) Their studies on unexplored Galactic regions and large-scale surveys informed the scope of hypothesis generation. (Papers with limitations addressed by this work)"
    ],
    "evidence": [
      "The study could involve a combination of observational data from large spectroscopic surveys such as APOGEE, GALAH, and Gaia-ESO, as well as the utilization of high- resolution cosmological simulations like the Auriga project. Key objectives would include characterizing the chemical abundance patterns and kinematic properties of stars in the disc and halo components during and after the mergers and probing the impact of these mergers on the radial distribution and migration of stars across the Galactic disc. By focusing on intermediate-mass gas- rich mergers, this research would fill a knowledge gap in our understanding of the role these events play in shaping the structure and evolution of Milky Way-like galaxies.",
      "The proposed research would build upon the probabilistic approach developed by Kuzma et al. (2021) for studying the peripheral regions of GCs, which utilizes a mixture model in spatial and proper motion space to model cluster, extra-tidal, and contaminant stellar populations.",
      "The aim would be to determine whether these GCs are embedded in dark matter mini-halos, which could provide critical insights into their origins (Peebles 1984; Peñarrubia et al. 2017).",
      "This research proposal is inspired by the unexplored regions mentioned in Antoja et al. (2015), along with the possibilities for improvement suggested by Gorski and Barmby (2020) and the advancements in large-scale surveys discussed in studies such as Yuan et al. (2014) and An and Beers (2020)."
    ]
  },
  "method": {
    "steps": [
      {
        "step": "Literature Retrieval and Pre-processing",
        "input": "1,000 papers related to Galactic Astronomy from the NASA Astrophysics Data System, selected based on keywords, publication date, and relevance.",
        "output": "A curated dataset of 1,000 papers with metadata including ArxivID, Publication Date, Authors, Title, Abstract, Citation, and Key.",
        "tools": [
          "NASA Astrophysics Data System (ADS): Database for astronomical literature."
        ],
        "evidence": "Our study includes a selection of 1,000 papers related to Galactic Astronomy from the NASA ADS (Accomazzi et al., 2015) Astronomy collection."
      },
      {
        "step": "Data Ingestion and Embedding",
        "input": "Full texts of the selected papers, converted from PDF to text and split into chunks of 1,000 tokens.",
        "output": "Embedded representations of text chunks stored in a vector database.",
        "tools": [
          "langchain library: Used for PDF-to-text conversion and chunking.",
          "OpenAI text-ada-002 embedding model: Generates vector embeddings for text chunks."
        ],
        "evidence": "The first step in in-context prompting involves pre-processing 1,000 papers from the Galactic Astronomy corpus using the langchain library. Each paper, transformed from PDF to text, is subsequently segmented into ‘chunks’ of 1,000 tokens each. These segmented units are then embedded using OpenAI’s text-ada-002 embedding model."
      },
      {
        "step": "Contextual Retrieval",
        "input": "User query and chat history, embedded for similarity search.",
        "output": "Relevant document chunks retrieved from the vector database and compressed to remove irrelevant information.",
        "tools": [
          "langchain’s contextual compression: Filters out irrelevant information from retrieved chunks."
        ],
        "evidence": "A similarity search is conducted between the embedded query and the vector database. We then use langchain’s contextual compression to filter out irrelevant information from the individual chunks."
      },
      {
        "step": "Hypothesis Generation",
        "input": "Compressed relevant text chunks and standalone input query.",
        "output": "Initial hypothesis generated by GPT-4.",
        "tools": [
          "OpenAI GPT-4: Large language model used for hypothesis generation."
        ],
        "evidence": "These final texts, combined with the standalone input, form the foundation upon which a GPT-4 model, having a context window of approximately 8,000 tokens, formulates ideas."
      },
      {
        "step": "Adversarial Critique and Iterative Refinement",
        "input": "Initial hypothesis and same contextual information.",
        "output": "Critique of the hypothesis by a second GPT-4 instance, reformulated feedback by a third GPT-4 instance, and refined hypothesis.",
        "tools": [
          "OpenAI GPT-4 (multiple instances): Used for adversarial critique and moderation."
        ],
        "evidence": "This idea is then critiqued by a second GPT-4 model, and the feedback is moderated by a third GPT-4 model."
      },
      {
        "step": "Evaluation",
        "input": "Generated hypotheses and critiques.",
        "output": "Human expert scores for scientific accuracy, creativity, and feasibility.",
        "tools": [
          "Human expert evaluation: Two domain experts in Galactic Astronomy."
        ],
        "evidence": "We involved two domain experts in the field of Galactic Astronomy to evaluate the quality of the generated hypotheses."
      }
    ],
    "tools": [
      "NASA Astrophysics Data System (ADS): Database for astronomical literature.",
      "langchain library: Used for PDF-to-text conversion, chunking, and contextual compression.",
      "OpenAI text-ada-002 embedding model: Generates vector embeddings for text chunks.",
      "OpenAI GPT-4: Large language model used for hypothesis generation, critique, and moderation.",
      "Human expert evaluation: Used for final assessment of hypothesis quality."
    ],
    "evidence": [
      "Our study includes a selection of 1,000 papers related to Galactic Astronomy from the NASA ADS (Accomazzi et al., 2015) Astronomy collection.",
      "The first step in in-context prompting involves pre-processing 1,000 papers from the Galactic Astronomy corpus using the langchain library. Each paper, transformed from PDF to text, is subsequently segmented into ‘chunks’ of 1,000 tokens each. These segmented units are then embedded using OpenAI’s text-ada-002 embedding model.",
      "A similarity search is conducted between the embedded query and the vector database. We then use langchain’s contextual compression to filter out irrelevant information from the individual chunks.",
      "These final texts, combined with the standalone input, form the foundation upon which a GPT-4 model, having a context window of approximately 8,000 tokens, formulates ideas.",
      "This idea is then critiqued by a second GPT-4 model, and the feedback is moderated by a third GPT-4 model.",
      "We involved two domain experts in the field of Galactic Astronomy to evaluate the quality of the generated hypotheses."
    ]
  },
  "subject_area": {
    "areas": [
      "Physical Sciences"
    ],
    "evidence": [
      "We focused our exploration on Galactic Astronomy, utilizing our domain expertise to assess the results.",
      "Our findings confirm that in-context prompting significantly mitigates hallucination, leading to the generation of meaningful hypotheses that can compete with substantive thesis topics, as evaluated by domain experts."
    ]
  },
  "performance_summary": {
    "performance_summary": [
      "Adversarial prompting combined with in-context prompting significantly improved the quality and consistency of hypothesis generation, especially when the model was supplied with an extensive context (up to 1,000 papers).",
      "Without adversarial prompting, the quality of hypotheses remained stagnant regardless of the amount of context provided.",
      "The average quality score of hypotheses increased from 2.5 (with 10 papers as context) to near-expert level of 4/5 (with 1,000 papers), as evaluated by human experts."
    ],
    "baselines": [
      "In-context prompting without adversarial prompting: The model generates hypotheses using only the provided literature context, without iterative critique or refinement."
    ],
    "benchmark_datasets": [
      "A curated set of 1,000 papers from the NASA Astrophysics Data System related to Galactic Astronomy, selected based on keywords, publication date, and relevance. Used as the primary context for hypothesis generation and evaluation."
    ],
    "evaluation_metrics": [
      "Human expert scoring: Hypotheses were graded by two domain experts based on scientific accuracy, creativity, and feasibility, with the average score used as the final metric."
    ],
    "evidence": [
      "Adversarial prompting and domain-specific context enrichment significantly enhance hypothesis generation quality. 60 hypotheses and 40 critiques generated by the AI were evaluated by two human experts, with the mean scores reported for individual instances.",
      "The average quality score rose significantly from 2.5 (when 10 papers were used as context, where a score of 3/5 corresponds to a typical hypothesis by a competent PhD student) to a near-expert level of 4/5 when 1,000 papers were included, emphasizing the potential of adversarial prompting in enhancing the quality of scientific hypothesis generation.",
      "The quality of hypothesis generation, without adversarial prompting, showed little dependence on the number of papers, suggesting that in-context prompting alone, while helpful for mitigating hallucination, did not suffice for a comprehensive understanding of the corpus.",
      "We involved two domain experts in the field of Galactic Astronomy to evaluate the quality of the generated hypotheses. These were graded based on the number of papers included within the domain-specific context, and we computed the average score from these dual-human evaluations for each hypothesis. The hypotheses are graded based on a rubric of three categories – scientific accuracy, creativity and feasibility, and the average score of these three domains assumed to be the final score."
    ]
  },
  "limitations": {
    "limitations": [
      {
        "label": "Evaluation Alignment",
        "explanation": "The AI judge primarily improves technical detail rather than deep insights, indicating a gap in aligning AI critique with human expectations.",
        "evidence": "We have observed that while the AI judge can assist the AI generator, improvements are primarily in technical detail rather than deep insights. We propose leveraging well-curated question-and-answer pairs (e.g. Dugan et al., 2022) to better align the judge with human expectations."
      },
      {
        "label": "Limited Scope of Downstream Tasks",
        "explanation": "The study focuses mainly on hypothesis generation, not integrating other downstream scientific tasks or fine-tuning approaches.",
        "evidence": "Instead of focusing solely on hypothesis generation, integrating other downstream tasks and finite fine-tuning models with smaller adapter models could potentially improve inferences."
      }
    ],
    "evidence": [
      "We have observed that while the AI judge can assist the AI generator, improvements are primarily in technical detail rather than deep insights. We propose leveraging well-curated question-and-answer pairs (e.g. Dugan et al., 2022) to better align the judge with human expectations.",
      "Instead of focusing solely on hypothesis generation, integrating other downstream tasks and finite fine-tuning models with smaller adapter models could potentially improve inferences."
    ]
  },
  "future_directions": {
    "future_directions": [
      "Develop improved and automated evaluation methods for hypotheses, potentially using well-curated question-and-answer pairs to better align AI judges with human expectations.",
      "Integrate additional downstream scientific tasks and explore fine-tuning models with smaller adapter models to enhance inference capabilities.",
      "Curate metadata from the NASA Astrophysics Data System to better design and support new scientific tasks."
    ],
    "evidence": [
      "These areas include (a) an improved and automated evaluation method for hypotheses. We have observed that while the AI judge can assist the AI generator, improvements are primarily in technical detail rather than deep insights. We propose leveraging well-curated question-and-answer pairs (e.g. Dugan et al., 2022) to better align the judge with human expectations.",
      "(b) Instead of focusing solely on hypothesis generation, integrating other downstream tasks and finite fine-tuning models with smaller adapter models could potentially improve inferences. We have commenced curating metadata from ADS to better design these tasks."
    ]
  },
  "resource_link": {
    "answer": "https://github.com/errai34/IdeaGPT",
    "evidence": "The full dataset as well as the codebase used in our analysis can be found here for reproducibility2.\n2https://github.com/errai34/IdeaGPT"
  },
  "paper_title": "Harnessing the Power of Adversarial Prompting and Large Language Models for Robust Hypothesis Generation in Astronomy",
  "authors": [
    "Ioana",
    "Yuan-Sen",
    "Sandor",
    "Kartheik"
  ],
  "published": "2023-06-20",
  "link": "http://arxiv.org/abs/2306.11648"
}