{
  "objective": {
    "answer": "The primary objective of the paper is to propose a novel framework for research ideation that dynamically adjusts the emphasis on key metrics such as novelty, feasibility, and effectiveness to achieve high overall quality through a two-stage approach combining Supervised Fine-Tuning (SFT) and controllable Reinforcement Learning (RL).",
    "evidence": "To address these limitations, we for the first time propose fine-tuning LLMs to be better idea proposers and introduce a novel framework that employs a two-stage approach combining Supervised Fine-Tuning (SFT) and controllable Reinforcement Learning (RL)."
  },
  "knowledge_gap": {
    "answer": "Existing LLM-based systems for research ideation predominantly rely on prompting-based pre-trained models, which limits their ability to optimize generated content effectively and handle the complex interdependence among novelty, feasibility, and effectiveness.",
    "evidence": "However, current approaches predominantly rely on prompting-based pre-trained models, limiting their ability to optimize generated content effectively. Moreover, they also lack the capability to deal with the complex interdependence and inherent restrictions among novelty, feasibility, and effectiveness."
  },
  "novelty": {
    "answer": [
      "The introduction of a two-stage framework combining Supervised Fine-Tuning and controllable Reinforcement Learning for research ideation.",
      "The use of dimensional controllers to dynamically adjust the generation style to prioritize specific metric dimensions.",
      "The implementation of a sentence-level decoder to ensure context-aware emphasis during inference."
    ],
    "evidence": [
      "We propose a novel research ideation framework that dynamically adjusts the emphasis on key metrics to achieve high overall quality through a two-stage approach: SFT and controllable RL.",
      "To enable precise and adaptive control, we introduce dimensional controllers, trained alongside the RL process, which adjusts the generation style to prioritize specific metric dimensions when necessary.",
      "This is complemented at inference time by a sentence-level decoder that dynamically adjusts the weights of controllers, ensuring context-aware emphasis."
    ]
  },
  "inspirational_papers": {
    "answer": "- Baek et al. (2024) ResearchAgent: Iterative Research Idea Generation over Scientific Literature with Large Language Models. (Methodological precursors)\n- Bornstein and Singh (2024) Hypothesis-craft: Towards automated hypothesis generation and refinement using llms. (Methodological precursors)\n- Ouyang et al. (2022) Training language models to follow instructions with human feedback. (Experimental baselines)",
    "evidence": "This capability is demonstrated by a growing body of work employing autonomous LLM-based agents to generate and validate innovative ideas (Baek et al., 2024; Bornstein and Singh, 2024). For example, Reinforcement Learning from Human Feedback (RLHF) has been explored to benefit LLM training (Ouyang et al., 2022)."
  },
  "method": {
    "steps": [
      {
        "step": "Supervised Fine-Tuning (SFT) stage",
        "input": "Pairs of research papers and follow-up ideas",
        "output": "Model learns foundational patterns",
        "evidence": "In the SFT stage, the idea generator learns foundational patterns by training on pairs of research papers and corresponding follow-up ideas."
      },
      {
        "step": "Reinforcement Learning (RL) stage",
        "input": "Multi-dimensional reward modeling guided by fine-grained feedback",
        "output": "Optimized generated ideas across key metrics",
        "evidence": "In the RL stage, we employ multi-dimensional reward modeling as a real-world assessment approximation."
      },
      {
        "step": "Training dimensional controllers",
        "input": "Feedback signals from reward models",
        "output": "Adaptive control over generation style",
        "evidence": "To enable precise and adaptive control, we introduce dimensional controllers, trained alongside the RL process."
      },
      {
        "step": "Sentence-level decoding",
        "input": "Contextual information during inference",
        "output": "Context-aware emphasis in idea generation",
        "evidence": "This is complemented at inference time by a sentence-level decoder that dynamically adjusts the weights of controllers."
      }
    ],
    "tools": [
      {
        "name": "LLaMA",
        "description": "Used for extracting research ideas from sampled papers",
        "evidence": "We utilize the LLaMA with a prompt (detailed in appendix D) to extract the research idea y from the sampled paper p as the golden output."
      },
      {
        "name": "PPO algorithm",
        "description": "Used to train the model during reinforcement learning",
        "evidence": "Thereafter, we utilize the PPO algorithm (Schulman et al., 2017) to train the model following the existing work (Jing and Du, 2024)."
      }
    ],
    "benchmark_datasets": [
      {
        "name": "ICLR 2023 and 2024 papers",
        "data_description": "Research papers from ICLR conferences",
        "usage": "Used for supervised fine-tuning and reward model training",
        "evidence": "To conduct a Supervised Fine-Tuning stage, we first collect papers from the ICLR 2023 and 2024."
      }
    ],
    "evaluation_metrics": [
      {
        "name": "Novelty",
        "purpose": "Evaluates how original and creative the generated ideas are",
        "application": "Used to assess the creativity of generated ideas",
        "evidence": "Novelty: Evaluates how original and creative the generated ideas are, compared to existing works."
      },
      {
        "name": "Feasibility",
        "purpose": "Assesses the practical implementation likelihood of the idea",
        "application": "Used to evaluate the practicality of generated ideas",
        "evidence": "Feasibility: Assesses the practical implementation and the likelihood that the idea can be executed within typical resource constraints."
      },
      {
        "name": "Effectiveness",
        "purpose": "Measures the potential improvement or impact of the generated idea",
        "application": "Used to compare the impact of generated ideas against baselines",
        "evidence": "Effectiveness: Measures the potential improvement or impact of the generated idea when compared to baseline models."
      }
    ]
  },
  "method_type": {
    "methods": [
      {
        "name": "Hypothesis or Idea Generation",
        "description": "The system produces candidate hypotheses or new research ideas from prior knowledge or external input.",
        "evidence": "We propose a novel research ideation framework that dynamically adjusts the emphasis on key metrics to achieve high overall quality through a two-stage approach: SFT and controllable RL."
      },
      {
        "name": "Experimental design generation",
        "description": "The approach includes producing experimental protocols, configurations, or evaluation strategies.",
        "evidence": "The method dynamically adjusts learning strategies to improve scalability and effectiveness in real-world applications."
      }
    ]
  },
  "subject_area": {
    "areas": [
      {
        "name": "Interdisciplinary Sciences",
        "description": "The paper develops a framework for automated research ideation applicable across various scientific domains.",
        "evidence": "Our framework provides a balanced approach to research ideation, achieving high-quality outcomes by dynamically navigating the trade-offs among novelty, feasibility, and effectiveness."
      }
    ]
  },
  "performance_summary": {
    "performance_summary": [
      {
        "summary": "The proposed model with dynamic decoding achieved the highest overall score of 6.2, outperforming other configurations.",
        "evidence": "Dynamic Decoding emerges as the most effective approach, leveraging contextual dynamic strategy to balance creativity, practicality, and impact, ultimately producing higher-quality ideas."
      }
    ],
    "baselines": [
      {
        "name": "T5-SFT",
        "description": "A version of the T5 model trained using SFT without reinforcement learning or control strategies.",
        "evidence": "T5-SFT: A version of the T5 model trained using SFT on 1,000 examples, without reinforcement learning or control strategies."
      },
      {
        "name": "LLaMA2-SFT",
        "description": "A fine-tuned version of the LLaMA2 model using research paper-idea pairs without RL or dimensional controllers.",
        "evidence": "LLaMA2-SFT: A fine-tuned version of the LLaMA2 model using 1,000 examples of research paper-idea pairs, without any RL or dimensional controllers."
      }
    ],
    "benchmark_datasets": [
      {
        "name": "ICLR and NeurIPS papers",
        "data_description": "Research papers submitted to ICLR and NeurIPS in 2023 and 2024",
        "usage": "Used for training and evaluation of the proposed framework",
        "evidence": "We collect a dataset of 6,765 usable research papers in total submitted to ICLR and NeurIPS in the years 2023 and 2024."
      }
    ],
    "evaluation_metrics": [
      {
        "name": "Novelty",
        "purpose": "Measures the originality and creativity of generated ideas",
        "application": "Used to evaluate the novelty of generated ideas",
        "evidence": "Novelty: Evaluates how original and creative the generated ideas are, compared to existing works."
      },
      {
        "name": "Feasibility",
        "purpose": "Assesses the practical implementation likelihood of the idea",
        "application": "Used to evaluate the practicality of generated ideas",
        "evidence": "Feasibility: Assesses the practical implementation and the likelihood that the idea can be executed within typical resource constraints."
      },
      {
        "name": "Effectiveness",
        "purpose": "Measures the potential improvement or impact of the generated idea",
        "application": "Used to compare the impact of generated ideas against baselines",
        "evidence": "Effectiveness: Measures the potential improvement or impact of the generated idea when compared to baseline models."
      }
    ]
  },
  "benchmark_dataset": null,
  "limitations": {
    "limitations": []
  },
  "future_directions": {
    "future_directions": "No explicit future directions were stated in the paper."
  },
  "resource_link": {
    "answer": "https://github.com/du-nlp-lab/Learn2Gen",
    "evidence": "Our benchmark is publicly available at https://github.com/du-nlp-lab/Learn2Gen."
  }
}