{
  "objective": {
    "answer": "The primary objective of the paper is to introduce DiSciPLE, a framework for discovering interpretable programs for scientific visual discovery using large language models (LLMs) and evolutionary algorithms. The authors aim to create Python programs that explain visual data and improve interpretability in scientific workflows.",
    "evidence": "This paper introduces an automatic way of obtaining such interpretable-by-design models, by learning programs that interleave neural networks. We propose DiSciPLE (Discovering Scientific Programs using LLMs and Evolution) an evolutionary algorithm that leverages common sense and prior knowledge of large language models (LLMs) to create Python programs explaining visual data."
  },
  "knowledge_gap": {
    "answer": "Existing methods for interpretable vision models are limited to simple functions of primitive concepts, which do not scale to the realistic complexity of visual data and complex relationships in scientific indicators.",
    "evidence": "While there have been many works that train interpretable vision models (for example concept-bottlenecks), these models are often limited to simple functions of primitive concepts, such as bag of words. These simple functions do not scale to the realistic complexity of our visual world and the complex relationships between its many rich scientific indicators, resulting in poor accuracy."
  },
  "novelty": {
    "answer": [
      "Introduction of DiSciPLE, a novel framework that produces interpretable, reliable, and sample-efficient programs for scientific discovery.",
      "Incorporation of a program critic and a program simplification method to improve the search for better programs.",
      "Proposal of benchmarks for scientific visual discovery tasks using real-world high-dimensional visual data."
    ],
    "evidence": [
      "We introduce a novel framework DiSciPLE, that can produce interpretable, reliable, and sample-efficient programs for scientific discovery.",
      "We present two key components: a critic and a program simplification method to DiSciPLE that can further improve the search resulting in better programs.",
      "We propose benchmarks for the task of scientific visual discovery containing real-world high-dimensional visual data for three problems in two different domains."
    ]
  },
  "inspirational_papers": {
    "answer": "- Chiquier et al. (2024) Evolving interpretable visual classifiers with large language models. (Methodological precursors)\n- Metzger et al. (2022) Fine-grained population mapping from coarse census counts and open geodata. (Experimental baselines)",
    "evidence": "Recently, code generation methods such as ViperGPT and VisProg have demonstrated that large language models are able to synthesize programs with competitive performance on many vision tasks. Fine-grained population mapping from coarse census counts and open geodata."
  },
  "method": {
    "steps": [
      {
        "step": "Initialize the program search with zero-shot programs from LLMs.",
        "input": "Dataset D, metric M, set of primitives F, textual description descr.",
        "output": "Initial population of programs.",
        "evidence": "DiSciPLE introduces an evolutionary search algorithm that starts with zero-shot programs from LLMs and iteratively improves them over the dataset."
      },
      {
        "step": "Perform evolutionary search using LLMs for crossover and mutation.",
        "input": "Objective prompt, initial programs, fitness scores.",
        "output": "New generation of programs.",
        "evidence": "We keep the overall evolutionary algorithm the same but replace key steps with an LLM."
      },
      {
        "step": "Critique and simplify programs to improve interpretability and performance.",
        "input": "Generated programs, fitness scores.",
        "output": "Improved and simplified programs.",
        "evidence": "The generated program is further improved by passing it through a critic and then an analytical simplification step."
      }
    ],
    "tools": [
      {
        "name": "LLM (Llama3)",
        "description": "Used for generating initial programs, performing crossover and mutation.",
        "evidence": "We use the metric M as the fitness function in our work. We keep the overall evolutionary algorithm the same but replace key steps with an LLM."
      },
      {
        "name": "GRAFT",
        "description": "Used as a black-box open-world foundational model for satellite images.",
        "evidence": "All the visual data in our benchmarks comes from satellite images, so to allow inferring semantic information from it, we use a black-box open-world foundational model for satellite images, GRAFT."
      }
    ],
    "benchmark_datasets": [
      {
        "name": "ACS Community Surveys 5-year estimates",
        "data_description": "Population density values for various locations in the USA.",
        "usage": "Used for population density estimation.",
        "evidence": "We obtain the population density values (yi) for various locations in the USA by using ACS Community Surveys 5-year estimates."
      },
      {
        "name": "SustainBench",
        "data_description": "Coordinate location as input and wealth asset index as output.",
        "usage": "Used for poverty estimation.",
        "evidence": "For poverty estimation, we use data from SustainBench."
      },
      {
        "name": "NASA’s GEDI",
        "data_description": "Observation variables for input location and output AGB estimate.",
        "usage": "Used for aboveground biomass estimation.",
        "evidence": "We use NASA’s GEDI to obtain the observation value for three US states."
      }
    ],
    "evaluation_metrics": [
      {
        "name": "L2 error over log",
        "purpose": "Measures the accuracy of population density predictions.",
        "application": "Used as a metric for population density estimation.",
        "evidence": "For example, in the case of population density a good metric used by domain experts is L2 error over log."
      },
      {
        "name": "L1 error",
        "purpose": "Measures the accuracy of poverty and AGB predictions.",
        "application": "Used as a metric for poverty and AGB estimation.",
        "evidence": "We use L2 error for each location as the evaluation metric."
      }
    ]
  },
  "method_type": {
    "methods": [
      {
        "name": "Hypothesis or Idea Generation",
        "evidence": "Our approach learns to synthesize a program for solving the task."
      },
      {
        "name": "Experimental design generation",
        "evidence": "We propose benchmarks for the task of scientific visual discovery containing real-world high-dimensional visual data for three problems in two different domains."
      }
    ]
  },
  "subject_area": {
    "areas": [
      {
        "name": "Interdisciplinary Sciences",
        "description": "The paper develops a framework for scientific visual discovery applicable to multiple domains.",
        "evidence": "In three different scientific applications of computer vision, DiSciPLE is able to learn state-of-the-art programs for novel tasks."
      },
      {
        "name": "Applied Sciences & Engineering",
        "description": "The framework is applied to problems in demography and climate science using remote sensing data.",
        "evidence": "In this work, we focus on two such scientific domain of: demography and climate science."
      }
    ]
  },
  "performance_summary": {
    "performance_summary": [
      {
        "summary": "DiSciPLE outperforms all interpretable baselines and even some deep models in population density estimation, while being more interpretable.",
        "evidence": "DiSciPLE outperforms all interpretable baselines. It can even outperform a deep model in many cases, specifically on population density estimation, while being significantly more interpretable."
      }
    ],
    "baselines": [
      {
        "name": "Mean",
        "description": "A naive baseline that uses the mean of the training observation as the prediction.",
        "evidence": "Mean: A naive baseline that use the mean of the training observation as the prediction."
      },
      {
        "name": "Concept Bottleneck (CB)",
        "description": "Extracts a list of relevant features and trains a linear classifier on it.",
        "evidence": "Concept Bottleneck (CB): Similar to [20, 33, 42], we first extract a list of relevant features and train a linear classifier on it."
      },
      {
        "name": "Deep models",
        "description": "Uses deep models such as ResNets as baseline.",
        "evidence": "Deep models: We use deep models such as ResNets as baseline."
      }
    ],
    "benchmark_datasets": [
      {
        "name": "ACS Community Surveys 5-year estimates",
        "data_description": "Population density values for various locations in the USA.",
        "usage": "Used for population density estimation.",
        "evidence": "We obtain the population density values (yi) for various locations in the USA by using ACS Community Surveys 5-year estimates."
      },
      {
        "name": "SustainBench",
        "data_description": "Coordinate location as input and wealth asset index as output.",
        "usage": "Used for poverty estimation.",
        "evidence": "For poverty estimation, we use data from SustainBench."
      },
      {
        "name": "NASA’s GEDI",
        "data_description": "Observation variables for input location and output AGB estimate.",
        "usage": "Used for aboveground biomass estimation.",
        "evidence": "We use NASA’s GEDI to obtain the observation value for three US states."
      }
    ],
    "evaluation_metrics": [
      {
        "name": "L2 error over log",
        "purpose": "Measures the accuracy of population density predictions.",
        "application": "Used as a metric for population density estimation.",
        "evidence": "For example, in the case of population density a good metric used by domain experts is L2 error over log."
      },
      {
        "name": "L1 error",
        "purpose": "Measures the accuracy of poverty and AGB predictions.",
        "application": "Used as a metric for poverty and AGB estimation.",
        "evidence": "We use L2 error for each location as the evaluation metric."
      }
    ]
  },
  "benchmark_dataset": {
    "name": "ACS Community Surveys 5-year estimates",
    "data_description": "Population density values for various locations in the USA.",
    "usage": "Used for population density estimation.",
    "evidence": "We obtain the population density values (yi) for various locations in the USA by using ACS Community Surveys 5-year estimates."
  },
  "limitations": {
    "limitations": [
      {
        "name": "Limited Differentiable Optimization",
        "description": "The method can only optimize learnable parameters in the last computational layer, potentially missing useful programs with parameters in intermediate layers.",
        "evidence": "One of our limitation is that we can only differentiably optimize learnable parameters in the last computational layer."
      }
    ]
  },
  "future_directions": {
    "future_directions": [
      {
        "name": "Improve Expressive Models",
        "description": "Use initialization tricks for non-linear optimization and second-order optimization to obtain more expressive models.",
        "evidence": "In future work, we plan to use initialization tricks for non-linear optimization and second-order optimization to obtain even more expressive models."
      }
    ]
  },
  "resource_link": {
    "answer": "https://disciple.cs.columbia.edu/pdf/supplementary.pdf",
    "evidence": "The supplementary material can be found at: https://disciple.cs.columbia.edu/pdf/supplementary.pdf"
  }
}