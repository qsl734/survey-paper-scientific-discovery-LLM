{
  "objective": {
    "answer": "The primary objective of the paper is to investigate how large language models can be combined with evolutionary computation techniques to automatically discover optimization algorithms for the design of photonic structures. The authors aim to extend the Large Language Model Evolutionary Algorithm framework with domain-specific prompt engineering and diverse evolutionary strategies, and to evaluate its effectiveness on real-world multilayer photonic problems such as Bragg mirrors, ellipsometry inverse analysis, and solar cell antireflection coatings.",
    "evidence": "We study how large language models can be used in combination with evolutionary computation techniques to automatically discover optimization algorithms for the design of photonic structures. Building on the Large Language Model Evolutionary Algorithm (LLaMEA) framework, we introduce structured prompt engineering tailored to multilayer photonic problems such as Bragg mirror, ellipsometry inverse analysis, and solar cell antireflection coatings."
  },
  "knowledge_gap": {
    "answer": "Previous approaches to automated algorithm discovery for photonic structure optimization lacked domain-specific guidance in prompts and did not systematically explore a diverse range of evolutionary strategies, limiting their effectiveness for complex, real-world photonic problems.",
    "evidence": "In this work, we extend the capabilities of the Large Language Model Evolutionary Algorithm (LLaMEA) framework [33] to deal with real-world photonic problems by addressing two critical limitations: ‚Ä¢ Generic Task Prompts: Original LLaMEA prompts lacked domain-specific guidance, which can lead to suboptimal algorithm designs for photonic problems. ‚Ä¢ Limited Evolutionary Strategy Diversity: Previous studies focused only on simple (1,1) and (1+1) strategies, neglecting the potential of population-based exploration."
  },
  "novelty": {
    "answer": [
      "Introduction of structured, domain-specific prompt engineering for large language model-driven algorithm discovery in photonic structure optimization.",
      "Systematic exploration and evaluation of multiple evolutionary strategies, including population-based approaches, within the LLaMEA framework.",
      "Demonstration that algorithms generated by large language models on small-scale instances can match or surpass established optimization methods on large-scale, real-world photonic problems.",
      "Integration of a self-debugging mutation loop in LLaMEA, augmented by automatically extracted problem-specific insights, to improve convergence and anytime performance."
    ],
    "evidence": [
      "To overcome these limitations, we introduce structured task prompts enriched with photonics-specific problem descriptions and algorithmic insights.",
      "Furthermore, we systematically evaluate five new evolutionary strategy configurations-(1,5), (1+5), (2,10), (2+10), and (5+5)-to balance exploration-exploitation trade-offs.",
      "Our experiments show that LLM-generated algorithms, generated using small-scale problem instances, can match or surpass established methods like quasi-oppositional differential evolution on large-scale realistic real-world problem instances.",
      "Notably, LLaMEA‚Äôs self-debugging mutation loop, augmented by automatically extracted problem-specific insights, achieves strong anytime performance and reliable convergence across diverse problem scales."
    ]
  },
  "inspirational_papers": {
    "answer": [
      "- van Stein and B√§ck (2024) LLaMEA: A Large Language Model Evolutionary Algorithm for Automatically Generating Metaheuristics. (Methodological precursor)",
      "- Liu et al. (2024) Evolution of Heuristics: Towards Efficient Automatic Algorithm Design Using Large Language Model. (Methodological precursor and baseline)",
      "- Bennet et al. (2020) The photonics and ARCoating testbeds in Nevergrad. (Experimental baseline and problem source)",
      "- Bennet et al. (2024) Illustrated tutorial on global optimization in nanophotonics. (Benchmark and problem definition)"
    ],
    "evidence": [
      "We apply LLaMEA to real-world problems published by P. Bennet et al. to automatically discover and implement photonic structure optimization algorithms [2, 33].",
      "Recent research has explored how LLMs can contribute to algorithmic discovery [20]. Two state-of-the-art representative frameworks in this area are Evolution of Heuristic (EoH) and LLaMEA [19, 33].",
      "Building on PyMoosh, P. Bennet et al. have developed a testbed for defining and solving photonic optimization problems [2].",
      "Please read Illustrated tutorial on global optimization in nanophotonics first [3]. Then, give me summaries of bragg mirror problem, ellipsometry problem, and photovoltaics problem, respectively."
    ]
  },
  "method": {
    "steps": [
      {
        "step": "Problem Simulation and Setup",
        "input": "Definitions and parameterizations of real-world photonic optimization problems (Bragg mirror, ellipsometry, photovoltaics) using PyMoosh and IOHexperimenter.",
        "output": "Simulated problem instances with defined search spaces and evaluation budgets.",
        "tools": [
          "PyMoosh: Python-based Multilayer Optics Optimization and Simulation Hub for calculating optical properties of multilayer structures.",
          "IOHexperimenter: Benchmarking platform for iterative optimization heuristics."
        ],
        "evidence": "Python-based Multilayer Optics Optimization and Simulation Hub (PyMoosh) is a numerical toolkit for calculating the optical properties of multilayer structures [17]... Based on their work, we migrate the following problems to the IOHexperimenter platform [5]."
      },
      {
        "step": "Prompt Engineering",
        "input": "Domain-specific problem descriptions and algorithmic insights generated via meta-prompts to GPT-4o.",
        "output": "Structured task prompts tailored to each photonic problem.",
        "tools": [
          "GPT-4o: Used to generate problem descriptions and algorithmic insights for prompt construction."
        ],
        "evidence": "Meta-prompt for generating problem description... Meta-prompt for generating algorithmic insight... All descriptions and insights can be found in the supplementary material and the problem description and algorithmic insights for the Bragg mirror are as follows:"
      },
      {
        "step": "Algorithm Generation via LLaMEA",
        "input": "Structured prompts, problem instances, and evolutionary strategy configuration.",
        "output": "Candidate optimization algorithms (Python code) generated and iteratively improved by the large language model.",
        "tools": [
          "LLaMEA: Large Language Model Evolutionary Algorithm framework for automated algorithm discovery and optimization."
        ],
        "evidence": "We chose LLaMEA as the algorithm discovery method in our experiments for the following reasons: (1) Targeting continuous optimization problems... (2) Reliable performance: LLaMEA has been shown to perform better than EoH in several complex optimization tasks [33]."
      },
      {
        "step": "Evolutionary Strategy Exploration",
        "input": "Different evolutionary strategy configurations (e.g., (1+1), (1+5), (2+10), (5+5)).",
        "output": "Diverse populations of candidate algorithms, balancing exploration and exploitation.",
        "tools": [
          "LLaMEA evolutionary strategies: Various (Œº,Œª) configurations for population-based search."
        ],
        "evidence": "In addition to the initial (1,1) and (1+1) strategies, which are the default for LLaMEA, we investigate five other configurations of evolutionary strategies: ‚Ä¢ Comma strategy: (1,5), (2,10) ‚Ä¢ The plus strategy: (1+5), (2+10), (5+5)"
      },
      {
        "step": "Algorithm Evaluation and Feedback",
        "input": "Candidate algorithms, problem instances, and performance metrics (AOCC, best fitness).",
        "output": "Performance feedback to the large language model for iterative improvement.",
        "tools": [
          "AOCC metric: Area over the convergence curve, used as feedback.",
          "Feedback prompt: Communicates AOCC and best fitness to the large language model."
        ],
        "evidence": "We use the metric suggested by LLaMEA, AOCC, as a feedback to the LLM... In the feedback prompt, we provide both AOCC and ùë¶‚àó information to help LLM better establish the connection between algorithmic implementation and real-world results as a way to improve existing algorithms in a targeted manner:"
      },
      {
        "step": "Benchmarking and Comparison",
        "input": "Best-performing discovered algorithms and established optimization baselines (DE, CMA-ES, BFGS, QNDE, QODE).",
        "output": "Comparative performance results on multiple problem instances.",
        "tools": [
          "Benchmarking suite: Executes and compares algorithms on photonic optimization problems."
        ],
        "evidence": "After the algorithm discovery step, for each problem, we have 2500 generated algorithms. Of these, the first 3 algorithms with the best AOCC average participate in the final benchmark. The optimal algorithms discovered through mini-Bragg and photovoltaic are also applied to higher-dimensional problem instances. In addition, five algorithms commonly used in the field of photonic structure optimization are added to the benchmark to provide a performance comparison, including DE [7], CMA-ES [11], Broyden‚ÄìFletcher‚ÄìGoldfarb‚ÄìShanno (BFGS) [12], quasi-Newton differential evolution (QNDE) [25], and quasi-oppositional differential evolution (QODE) [27]."
      }
    ],
    "tools": [
      "PyMoosh: Python toolkit for multilayer optics simulation.",
      "IOHexperimenter: Platform for benchmarking iterative optimization heuristics.",
      "GPT-4o: Large language model for generating prompts and insights.",
      "LLaMEA: Framework for evolutionary algorithm discovery using large language models.",
      "AOCC metric: Area over the convergence curve, measures anytime performance.",
      "Benchmarking suite: Used for comparative evaluation of algorithms."
    ],
    "evidence": [
      "Python-based Multilayer Optics Optimization and Simulation Hub (PyMoosh) is a numerical toolkit for calculating the optical properties of multilayer structures [17].",
      "Meta-prompt for generating problem description... Meta-prompt for generating algorithmic insight...",
      "We chose LLaMEA as the algorithm discovery method in our experiments for the following reasons...",
      "In addition to the initial (1,1) and (1+1) strategies, which are the default for LLaMEA, we investigate five other configurations of evolutionary strategies...",
      "We use the metric suggested by LLaMEA, AOCC, as a feedback to the LLM...",
      "After the algorithm discovery step, for each problem, we have 2500 generated algorithms. Of these, the first 3 algorithms with the best AOCC average participate in the final benchmark. The optimal algorithms discovered through mini-Bragg and photovoltaic are also applied to higher-dimensional problem instances. In addition, five algorithms commonly used in the field of photonic structure optimization are added to the benchmark to provide a performance comparison, including DE [7], CMA-ES [11], Broyden‚ÄìFletcher‚ÄìGoldfarb‚ÄìShanno (BFGS) [12], quasi-Newton differential evolution (QNDE) [25], and quasi-oppositional differential evolution (QODE) [27]."
    ]
  },
  "subject_area": {
    "areas": [
      "Physical Sciences",
      "Applied Sciences & Engineering"
    ],
    "evidence": [
      "Optimization of photonic structures plays a key role in the advancement of technologies in various fields such as telecommunication, solar energy, and materials science [1, 16, 21, 22, 37].",
      "This work demonstrates the feasibility of domain-focused LLM prompts and evolutionary approaches in solving optical design tasks, paving the way for rapid, automated photonic inverse design."
    ]
  },
  "performance_summary": {
    "performance_summary": [
      "Algorithms generated by the large language model using the LLaMEA framework achieved performance that matches or surpasses established optimization methods such as quasi-oppositional differential evolution and covariance matrix adaptation evolution strategy on large-scale, real-world photonic structure optimization problems.",
      "For Bragg mirror and ellipsometry problems, LLaMEA-discovered algorithms demonstrated significantly faster convergence and more stable performance compared to baselines.",
      "For photovoltaic problems, LLaMEA algorithms were not always the best but still showed reliable and fast convergence.",
      "The best LLaMEA algorithms consistently found near-optimal solutions with concentrated performance distributions, especially for Bragg mirror instances."
    ],
    "baselines": [
      "Differential Evolution (DE): A global optimization algorithm.",
      "Covariance Matrix Adaptation Evolution Strategy (CMA-ES): An evolutionary strategy for continuous optimization.",
      "Broyden‚ÄìFletcher‚ÄìGoldfarb‚ÄìShanno (BFGS): A quasi-Newton method for local optimization.",
      "Quasi-Newton Differential Evolution (QNDE): Differential evolution with adaptive local search.",
      "Quasi-Oppositional Differential Evolution (QODE): Differential evolution with quasi-oppositional initialization."
    ],
    "benchmark_datasets": [
      "Bragg mirror: Simulated multilayer photonic structure optimization problem with 10 and 20 layers, maximizing reflectivity at 600 nm.",
      "Ellipsometry: Simulated inverse problem for retrieving material and thickness parameters from spectral response, with 1 layer.",
      "Photovoltaic: Simulated multilayer antireflection coating optimization for solar absorption, with 10, 20, and 32 layers."
    ],
    "evaluation_metrics": [
      "Area Over the Convergence Curve (AOCC): Measures anytime performance of the optimization algorithm, with 1.0 as the best score.",
      "Best fitness value (y*): The optimal fitness value found at the end of the algorithm runs, with lower values indicating better solutions."
    ],
    "evidence": [
      "Our experiments show that LLM-generated algorithms, generated using small-scale problem instances, can match or surpass established methods like quasi-oppositional differential evolution on large-scale realistic real-world problem instances.",
      "Fig. 5 shows the best 3 optimal algorithms found by LLaMEA for each of the 6 instances of 3 problems, compared to the commonly used algorithms. From Figs. 5a and 5b, we find that the algorithms found by LLaMEA demonstrate a significantly more rapid convergence trend.",
      "We use the metric suggested by LLaMEA, AOCC, as a feedback to the LLM. Eq. 1 is the definition of AOCC...",
      "In addition, five algorithms commonly used in the field of photonic structure optimization are added to the benchmark to provide a performance comparison, including DE [7], CMA-ES [11], Broyden‚ÄìFletcher‚ÄìGoldfarb‚ÄìShanno (BFGS) [12], quasi-Newton differential evolution (QNDE) [25], and quasi-oppositional differential evolution (QODE) [27]."
    ]
  },
  "limitations": {
    "limitations": [],
    "evidence": [
      "No explicit limitations are mentioned in the provided text. The paper focuses on the strengths and results of the approach, without a dedicated section or statements on limitations."
    ]
  },
  "future_directions": {
    "future_directions": [],
    "evidence": [
      "No explicit future directions were stated in the paper."
    ]
  },
  "resource_link": {
    "answer": "https://doi.org/10.5281/zenodo.15073784",
    "evidence": "This chapter presents the results of the experiments, for which the raw data and associated code are publicly available 1.\n1https://doi.org/10.5281/zenodo.15073784"
  },
  "paper_title": "Optimizing Photonic Structures with Large Language Model Driven Algorithm Discovery",
  "authors": [
    "Haoran",
    "Anna V.",
    "Thomas",
    "Niki van"
  ],
  "published": "2025-03-25",
  "link": "http://arxiv.org/abs/2503.19742"
}