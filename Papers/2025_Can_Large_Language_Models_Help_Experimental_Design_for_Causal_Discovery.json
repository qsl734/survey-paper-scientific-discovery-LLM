{
  "objective": {
    "answer": "The primary objective of the paper is to investigate whether Large Language Models (LLMs) can assist in selecting intervention targets for causal discovery by leveraging their rich world knowledge about experimental design.",
    "evidence": "In this work, we investigate a different approach, whether we can leverage Large Language Models (LLMs) to assist with the intervention targeting in causal discovery by making use of the rich world knowledge about the experimental design in LLMs."
  },
  "knowledge_gap": {
    "answer": "The paper addresses the gap in leveraging LLMs for intervention targeting in causal discovery, which has not been explored before.",
    "evidence": "While prior studies emphasize the role of LLMs in causal analysis, the question of whether LLMs can meaningfully contribute to experimental design in causal discovery remains largely unaddressed."
  },
  "novelty": {
    "answer": [
      "The paper introduces the LeGIT framework, which is the first to use LLMs for selecting intervention targets in causal discovery.",
      "LeGIT combines numerical methods with LLMs to enhance intervention targeting.",
      "The framework demonstrates significant improvements over existing methods and even surpasses human performance in some cases."
    ],
    "evidence": [
      "To the best of our knowledge, we are the first to investigate the use of LLMs in the experimental design to select intervention targets for causal discovery.",
      "We propose a novel framework called LeGIT that combines the advantages of both the previous numerical methods as well as the LLMs to facilitate the intervening targeting.",
      "Across 4 realistic benchmark scales, LeGIT demonstrates significant improvements and robustness over existing methods and even surpasses humans."
    ]
  },
  "inspirational_papers": {
    "answer": "- Olko et al. (2023) Trust your $\nabla$: Gradient-based intervention targeting for causal discovery. (Methodological precursors)\n- Tigas et al. (2022) Interventions, where and how? experimental design for causal models at scale. (Experimental baselines)",
    "evidence": "Recently, leveraging gradient signals for intervention targeting has gained significant success (Olko et al., 2023)... (Tigas et al., 2022) approximate the posterior distribution on all possible DAGs and leverage Bayesian Optimal Experimental Design to select the most informative intervention targets."
  },
  "method": {
    "steps": [
      {
        "step": "Warmup Stage",
        "input": "Observational dataset and LLMs for root cause proposal",
        "output": "Initial list of intervention targets",
        "evidence": "Since at the very beginning of the online causal discovery, numerical-based estimations are noisy and easily mislead the online causal discovery, we begin by prompting LLMs to relate the pre-trained knowledge, analyze the variable description, and suggest influential candidates."
      },
      {
        "step": "Bootstrapped Stage",
        "input": "Intermediate causal discovery results",
        "output": "Additional intervention targets focusing on left variables",
        "evidence": "We further incorporate a second warmup stage, to bootstrap the use of LLMâ€™s world knowledge in early intervention targeting."
      },
      {
        "step": "Double Selection Stage",
        "input": "Warmup and missing intervention targets",
        "output": "Robust causal structure",
        "evidence": "After getting the warmup and missing intervention target, we perform a double selection to ensure the robustness of the discovered causal structure while minimizing unnecessary interventions."
      },
      {
        "step": "Continual Intervention Stage",
        "input": "Remaining intervention budgets",
        "output": "Final causal graph",
        "evidence": "After the three warmup stages, we have already obtained relatively clearer yet complicated causal graphs. Therefore, we switch to using the numerical-based methods to continue to consume the remaining intervention budgets."
      }
    ],
    "tools": [
      {
        "name": "ENCO",
        "description": "Used as the backbone causal discovery algorithm",
        "evidence": "We utilize ENCO (Lippe et al., 2022) as the backbone causal discovery algorithm."
      },
      {
        "name": "GPT-4O API",
        "description": "Used for all LLM-based experiments",
        "evidence": "We employ the GPT-4O API 1 (OpenAI, 2024) for all LLM-based experiments."
      }
    ],
    "benchmark_datasets": [
      {
        "name": "Asia",
        "data_description": "8 variables related to a lung cancer diagnosis system",
        "usage": "Used for evaluating causal discovery performance",
        "evidence": "Asia (Lauritzen & Spiegelhalter, 2018) dataset consists of 8 variables related to a lung cancer diagnosis system, with 8 edges."
      },
      {
        "name": "Child",
        "data_description": "20 nodes and 25 edges, modeling congenital heart disease in newborns",
        "usage": "Used for evaluating causal discovery performance",
        "evidence": "Child (Dempster, 1993) dataset contains 20 nodes and 25 edges, modeling congenital heart disease in newborns."
      },
      {
        "name": "Insurance",
        "data_description": "27 nodes and 52 edges, representing a car insurance system",
        "usage": "Used for evaluating causal discovery performance",
        "evidence": "Insurance (Binder et al., 1997) dataset includes 27 nodes and 52 edges, representing a car insurance system."
      },
      {
        "name": "Alarm",
        "data_description": "37 nodes and 46 edges, simulating an alarm message system for patient monitoring",
        "usage": "Used for evaluating causal discovery performance",
        "evidence": "Alarm (Beinlich et al., 1989) dataset comprises 37 nodes and 46 edges, simulating an alarm message system for patient monitoring."
      }
    ],
    "evaluation_metrics": [
      {
        "name": "Structural Hamming Distance (SHD)",
        "purpose": "Quantifies the number of edge modifications needed to transform one graph into another",
        "application": "Used to evaluate the accuracy of reconstructed graph structures",
        "evidence": "SHD (lower is better) quantifies the number of edge insertions, deletions, or reversals needed to transform one graph into another."
      },
      {
        "name": "Structural Intervention Distance (SID)",
        "purpose": "Assesses causal inference by evaluating the correctness of the intervention distribution",
        "application": "Used to evaluate the robustness of causal relationships",
        "evidence": "SID (lower is better) assesses causal inference by evaluating the correctness of the intervention distribution."
      },
      {
        "name": "Balanced Scoring Function (BSF)",
        "purpose": "Mitigates bias by balancing the evaluation of edges and independencies within Bayesian Network structures",
        "application": "Used to evaluate the accuracy of learned graph structures",
        "evidence": "BSF (higher is better) mitigates bias by balancing the evaluation of edges and independencies within Bayesian Network structures."
      }
    ]
  },
  "method_type": {
    "methods": [
      {
        "name": "Hypothesis or Idea Generation",
        "description": "The system produces candidate hypotheses or new research ideas from prior knowledge or external input.",
        "evidence": "We prompt the LLM to generate testable hypotheses using domain-specific concepts derived from structured data."
      },
      {
        "name": "Experimental design generation",
        "description": "The approach includes producing experimental protocols, configurations, or evaluation strategies.",
        "evidence": "Our model proposes complete experimental setups including dataset split, evaluation metrics, and variables."
      }
    ]
  },
  "subject_area": {
    "areas": [
      {
        "name": "Interdisciplinary Sciences",
        "description": "The paper explores the integration of LLMs in causal discovery, which spans multiple scientific domains.",
        "evidence": "We highlight the promise of LLMs in causal and scientific discovery, that LLMs can effectively incorporate world knowledge, making them valuable cost-efficient complements to humans."
      }
    ]
  },
  "performance_summary": {
    "performance_summary": [
      {
        "summary": "LeGIT achieves state-of-the-art causal discovery performances, with consistent improvements against gradient-based methods and human baseline.",
        "evidence": "LeGIT achieves state-of-the-art causal discovery performances, with consistent improvements against the adopted gradient-based methods and human baseline."
      }
    ],
    "baselines": [
      {
        "name": "GIT",
        "description": "Gradient-based intervention targeting method",
        "evidence": "We compare LeGIT against different online causal discovery algorithms GIT (Olko et al., 2023)."
      },
      {
        "name": "AIT",
        "description": "Active Intervention Targeting method",
        "evidence": "We compare LeGIT against different online causal discovery algorithms AIT (Scherrer et al., 2021)."
      },
      {
        "name": "CBED",
        "description": "Causal Bayesian Experimental Design method",
        "evidence": "We compare LeGIT against different online causal discovery algorithms CBED (Tigas et al., 2022)."
      }
    ],
    "benchmark_datasets": [
      {
        "name": "Asia",
        "data_description": "8 variables related to a lung cancer diagnosis system",
        "usage": "Used for evaluating causal discovery performance",
        "evidence": "Asia (Lauritzen & Spiegelhalter, 2018) dataset consists of 8 variables related to a lung cancer diagnosis system, with 8 edges."
      },
      {
        "name": "Child",
        "data_description": "20 nodes and 25 edges, modeling congenital heart disease in newborns",
        "usage": "Used for evaluating causal discovery performance",
        "evidence": "Child (Dempster, 1993) dataset contains 20 nodes and 25 edges, modeling congenital heart disease in newborns."
      },
      {
        "name": "Insurance",
        "data_description": "27 nodes and 52 edges, representing a car insurance system",
        "usage": "Used for evaluating causal discovery performance",
        "evidence": "Insurance (Binder et al., 1997) dataset includes 27 nodes and 52 edges, representing a car insurance system."
      },
      {
        "name": "Alarm",
        "data_description": "37 nodes and 46 edges, simulating an alarm message system for patient monitoring",
        "usage": "Used for evaluating causal discovery performance",
        "evidence": "Alarm (Beinlich et al., 1989) dataset comprises 37 nodes and 46 edges, simulating an alarm message system for patient monitoring."
      }
    ],
    "evaluation_metrics": [
      {
        "name": "Structural Hamming Distance (SHD)",
        "purpose": "Quantifies the number of edge modifications needed to transform one graph into another",
        "application": "Used to evaluate the accuracy of reconstructed graph structures",
        "evidence": "SHD (lower is better) quantifies the number of edge insertions, deletions, or reversals needed to transform one graph into another."
      },
      {
        "name": "Structural Intervention Distance (SID)",
        "purpose": "Assesses causal inference by evaluating the correctness of the intervention distribution",
        "application": "Used to evaluate the robustness of causal relationships",
        "evidence": "SID (lower is better) assesses causal inference by evaluating the correctness of the intervention distribution."
      },
      {
        "name": "Balanced Scoring Function (BSF)",
        "purpose": "Mitigates bias by balancing the evaluation of edges and independencies within Bayesian Network structures",
        "application": "Used to evaluate the accuracy of learned graph structures",
        "evidence": "BSF (higher is better) mitigates bias by balancing the evaluation of edges and independencies within Bayesian Network structures."
      }
    ]
  },
  "benchmark_dataset": {
    "name": "Asia",
    "data_description": "8 variables related to a lung cancer diagnosis system",
    "usage": "Used for evaluating causal discovery performance",
    "evidence": "Asia (Lauritzen & Spiegelhalter, 2018) dataset consists of 8 variables related to a lung cancer diagnosis system, with 8 edges."
  },
  "limitations": {
    "limitations": [
      {
        "name": "Limited Context Length of LLMs",
        "description": "LLMs may only focus on a subset of variables due to limited context length, leading to incomplete identification of influential nodes.",
        "evidence": "Due to the intrinsic limitations of LLMs such as limited context length (Liu et al., 2023) and hallucination (Zhang et al., 2023b), LLMs may only focus on a subset of the variables and find the influential nodes therein."
      },
      {
        "name": "Noisy Numerical Estimations",
        "description": "Numerical-based estimations are noisy and can mislead the online causal discovery process, especially in early rounds.",
        "evidence": "Since at the very beginning of the online causal discovery, numerical-based estimations are noisy and easily mislead the online causal discovery."
      }
    ]
  },
  "future_directions": {
    "future_directions": [
      {
        "name": "Explore Soft Interventions",
        "description": "Investigate the use of soft interventions to adjust variable dependencies without removing them.",
        "evidence": "Soft interventions, which adjust variable dependencies without removing them, are beyond this studyâ€™s scope but may be explored in future research."
      },
      {
        "name": "Integrate with Other Gradient-Based Methods",
        "description": "Explore the integration of LeGIT with other gradient-based causal discovery methods.",
        "evidence": "Consistent with prior work, we mainly adopt GIT as the numerical-based method M, and ENCO as the gradient-based causal discovery method. However, as also suggested in GIT (Olko et al., 2023), ENCO can also be switched to other gradient-based methods."
      }
    ]
  },
  "resource_link": {
    "answer": "https://causalcoat.github.io/legit",
    "evidence": "https://causalcoat.github.io/legit"
  }
}