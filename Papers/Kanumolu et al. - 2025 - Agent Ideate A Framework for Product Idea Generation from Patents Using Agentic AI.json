{
  "objective": {
    "answer": "The primary objective of the paper is to design and evaluate Agent Ideate, a framework that leverages large language models and autonomous agents to automatically generate product-based business ideas from patent documents. The authors aim to address the challenge of mining and interpreting complex patent information to inspire innovative and actionable product concepts. They seek to compare the effectiveness of agentic workflows versus standalone large language models in this context.",
    "evidence": "In this work, we design Agent Ideate, a framework for automatically generating product-based business ideas from patents. ... We also analyze the effectiveness of agent-based and LLM-driven architectures for transforming patent knowledge into innovative product concepts."
  },
  "knowledge_gap": {
    "answer": "Despite the wealth of technical insights in patent documents, generating actionable product business ideas from patents is an underexplored area due to the complexity and technical nature of patent language.",
    "evidence": "Despite the wealth of technical insights contained within patent documents, generating product business ideas from patents remains an underexplored area (Jiang and Goetz, 2024)."
  },
  "novelty": {
    "answer": [
      "Development of Agent Ideate, a multi-agent framework that combines large language models with external search tools to generate structured product ideas from patents.",
      "Systematic comparison of prompt-based, agent-based, and tool-augmented agent architectures for product idea generation from patents across multiple domains.",
      "Use of an LLM-as-a-judge evaluation strategy to assess the quality of generated business ideas across multiple criteria."
    ],
    "evidence": [
      "In this study, we built the Agent Ideate framework, which is a Multi-Agent architecture leveraging an external search tool for generating product ideas from patent text.",
      "We conduct experiments with prompt-based, agent with Tool and agent without Tool based approaches.",
      "To assess the relative quality of business ideas generated by different methods, we employed an LLM-as-a-judge evaluation strategy."
    ]
  },
  "inspirational_papers": {
    "answer": [
      "- Si et al. (2024) Investigated the research ideation capabilities of large language models and inspired the evaluation of idea novelty. (Methodological precursors)",
      "- Wang et al. (2024) Proposed SciMON, a framework for generating novel scientific ideas, which influenced the use of literature-based inspiration and iterative novelty optimization. (Methodological precursors)",
      "- Jiang and Goetz (2024) Highlighted the challenge of generating business ideas from patents, motivating the focus of this work. (Papers with limitations addressed)"
    ],
    "evidence": [
      "One closely related line of work is by Si et al. (2024), who investigate the research ideation capabilities of LLMs.",
      "SciMON(Wang et al., 2024) is a framework that enhances language modelsâ€™ ability to generate novel scientific ideas by leveraging literature-based inspirations and iterative novelty optimization.",
      "Despite the wealth of technical insights contained within patent documents, generating product business ideas from patents remains an underexplored area (Jiang and Goetz, 2024)."
    ]
  },
  "method": {
    "steps": [
      {
        "step": "Data Preprocessing",
        "input": "Patent documents including title, abstract, claims, description, publication number, and publication date.",
        "output": "Segmented and structured patent sections for downstream processing.",
        "evidence": "To address this challenge, we implemented a preprocessing strategy that segments the description into semantically meaningful subsections."
      },
      {
        "step": "Prompt-based LLM Approach",
        "input": "Entire patent or reduced components (title, abstract, claims, summarized description).",
        "output": "Structured business idea with fields: product title, product description, implementation, differentiation.",
        "evidence": "We use a single-prompt approach with a large language model (LLM), wherein the entire patent (or its reduced components: title, abstract, claims, and summarized description) is passed as input to the model."
      },
      {
        "step": "Multi-Agent LLM Architecture (Agent without Tool)",
        "input": "Patent text (segmented sections).",
        "output": "Structured business idea, validated for format and originality.",
        "evidence": "The second approach builds on modularization via a multi-agent system, where different tasks are handled by different specialized agents."
      },
      {
        "step": "Multi-Agent LLM with External Search Tool (Agent with Tool)",
        "input": "Patent summary and keywords extracted from patent content.",
        "output": "Business idea that incorporates both patent insights and external market information, validated for novelty and structure.",
        "evidence": "The third and most comprehensive method incorporates a search tool to enrich the reasoning process with external information."
      },
      {
        "step": "Evaluation using LLM-as-a-Judge",
        "input": "Patent description and two generated product ideas.",
        "output": "Selection of the better idea based on six criteria: technical validity, innovativeness, specificity, need validity, market size, and competitive advantage.",
        "evidence": "To assess the relative quality of business ideas generated by different methods, we employed an LLM-as-a-judge evaluation strategy."
      }
    ],
    "tools": [
      {
        "name": "llama-4-scout-17b-16e-instruct",
        "description": "Open-source large language model used for generating responses in both prompt-based and agent-based architectures.",
        "evidence": "For all experiments, we used the llama-4-scout-17b-16e-instruct3 model for response generation in both architectures"
      },
      {
        "name": "Groq API",
        "description": "API used to host and run open-source large language models for inference.",
        "evidence": "we opted to experiment with open-source LLMs hosted via the Groq API"
      },
      {
        "name": "CrewAI",
        "description": "Framework used to create agents and integrate with external search tools.",
        "evidence": "For all agentic framework experiments, we used the CrewAI5 framework to create agents and integrate with external search tools."
      },
      {
        "name": "DuckDuckGo Tool",
        "description": "External web search tool used by the Research Agent to gather information about existing products and tools.",
        "evidence": "A Research Agent, which performs a DuckDuckGo tool-based web search using these keywords to gather information about existing tools, libraries, or products in the domain."
      },
      {
        "name": "LLaMA 3 70B",
        "description": "High-capacity large language model used for LLM-as-a-judge evaluation.",
        "evidence": "We used a high-capacity model LLaMA 3 70B 6 hosted via Groq for inference, ensuring strong reasoning and evaluation capabilities."
      }
    ],
    "evidence": [
      "To address this challenge, we implemented a preprocessing strategy that segments the description into semantically meaningful subsections.",
      "We use a single-prompt approach with a large language model (LLM), wherein the entire patent (or its reduced components: title, abstract, claims, and summarized description) is passed as input to the model.",
      "The second approach builds on modularization via a multi-agent system, where different tasks are handled by different specialized agents.",
      "The third and most comprehensive method incorporates a search tool to enrich the reasoning process with external information.",
      "To assess the relative quality of business ideas generated by different methods, we employed an LLM-as-a-judge evaluation strategy."
    ]
  },
  "subject_area": {
    "areas": [
      "Applied Sciences & Engineering",
      "Chemical Sciences",
      "Physical Sciences"
    ],
    "evidence": [
      "The dataset provided by the shared task organizers comprises a total of 150 U.S. patents, with 50 patents each from three distinct domains: Computer Science(CS), Natural Language Processing (NLP), and Material Chemistry(MC)."
    ]
  },
  "performance_summary": {
    "performance_summary": [
      "The Agent with Tool method consistently generated the highest-ranked ideas in Computer Science (86%), showed moderate performance in Material Chemistry (38%), and performed poorly in Natural Language Processing (12%).",
      "The standalone Agent without Tool approach performed strongly in Natural Language Processing (98%) and Material Chemistry (64%), but less effectively in Computer Science (14%) compared to the Agent with Tool method.",
      "The basic prompt-based large language model method performed poorly across all domains (Computer Science: 14%, Natural Language Processing: 2%, Material Chemistry: 8%).",
      "Human evaluation ranked the system highest in Innovativeness for Chemistry, with balanced performance in Computer Science, and strong overall performance in Natural Language Processing except for Market Size."
    ],
    "baselines": [
      "Prompt-based LLM: A single-prompt approach using a large language model to generate business ideas from patent text.",
      "Agent without Tool: A multi-agent system where agents handle summarization, idea generation, and validation without external search.",
      "Agent with Tool: A multi-agent system augmented with an external search tool to gather market information and enhance idea differentiation."
    ],
    "benchmark_datasets": [
      "A curated dataset of 150 U.S. patents across Computer Science, Natural Language Processing, and Material Chemistry, each with structured metadata (title, abstract, claims, description, publication number, and publication date). Used for evaluating idea generation methods."
    ],
    "evaluation_metrics": [
      "Technical Validity: Measures if the patent technology is appropriate and realistically implementable within 3 years.",
      "Innovativeness: Assesses if the idea utilizes the patent in a novel and creative way.",
      "Specificity: Evaluates if the idea is clearly and narrowly defined.",
      "Need Validity: Checks if there is a clear and valid user need addressed.",
      "Market Size: Assesses if the target market is large enough for viability.",
      "Competitive Advantage: Evaluates if the patented technology offers a unique advantage over competitors."
    ],
    "evidence": [
      "The Agent with Tool method consistently generates highly-ranked ideas in Computer Science (86%), demonstrates moderate performance in Material Chemistry (38%), but performs poorly in NLP (12%).",
      "The basic LLM prompt method performs poorly across all domains (Computer Science: 14%, NLP: 02%, Material Chemistry: 08%), suggesting that multi-agent frameworks provide substantial benefits even without tool access.",
      "The dataset provided by the shared task organizers comprises a total of 150 U.S. patents, with 50 patents each from three distinct domains: Computer Science(CS), Natural Language Processing (NLP), and Material Chemistry(MC).",
      "The LLM is then instructed to critically evaluate the ideas across six well-defined dimensions: technical validity, innovativeness, specificity, need validity, market size, and competitive advantage."
    ]
  },
  "limitations": {
    "limitations": [
      {
        "label": "Open-Source Model Constraints",
        "explanation": "Reliance on open-source large language models may restrict performance compared to state-of-the-art proprietary models.",
        "evidence": "First, reliance on open-source LLMs (e.g., LLama-4-17B, and LLaMA-3-70B) may restrict performance compared to state-of-the-art proprietary models."
      },
      {
        "label": "Domain-Specific Effectiveness",
        "explanation": "The systemâ€™s effectiveness varies significantly across domains, requiring domain specific models.",
        "evidence": "Second, the systemâ€™s effectiveness varies significantly across domains, requiring domain specific models."
      },
      {
        "label": "External Search Quality Dependency",
        "explanation": "The tool-augmented agentâ€™s performance depends heavily on external search quality, which can introduce noise.",
        "evidence": "Finally, the tool-augmented agentâ€™s performance depends heavily on external search quality, which can introduce noise."
      }
    ],
    "evidence": [
      "First, reliance on open-source LLMs (e.g., LLama-4-17B, and LLaMA-3-70B) may restrict performance compared to state-of-the-art proprietary models. Second, the systemâ€™s effectiveness varies significantly across domains, requiring domain specific models. Finally, the tool-augmented agentâ€™s performance depends heavily on external search quality, which can introduce noise."
    ]
  },
  "future_directions": {
    "future_directions": [
      "Develop more robust domain adaptation techniques to improve performance across different scientific and technical fields.",
      "Integrate hybrid evaluation methods that combine human and automated assessments for more reliable idea quality measurement.",
      "Enhance tool integration to reduce noise and improve the quality of external information used by agentic frameworks."
    ],
    "evidence": [
      "These constraints highlight the need for more robust domain adaptation, hybrid evaluation methods, and improved tool integration in future work."
    ]
  },
  "resource_link": {
    "answer": "https://github.com/gopichandkanumolu/AgentIdeate",
    "evidence": "Our code is publicly available 2.\n2https://github.com/gopichandkanumolu/AgentIdeate"
  },
  "paper_title": "Agent Ideate: A Framework for Product Idea Generation from Patents Using Agentic AI",
  "authors": [
    "Gopichand",
    "Ashok",
    "Charaka Vinayak",
    "Bala Mallikarjunarao"
  ],
  "published": "2025-07-02",
  "link": "http://arxiv.org/abs/2507.01717"
}