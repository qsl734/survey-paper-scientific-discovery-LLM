{
  "objective": {
    "answer": "The primary objective of the paper is to introduce IRIS, an open-source platform designed to leverage LLM-assisted scientific ideation, incorporating a Human-in-the-loop (HITL) approach to enhance transparency and steerability in hypothesis generation.",
    "evidence": "To address this gap, we introduce IRIS: Interactive Research Ideation System, an open-source platform designed for researchers to leverage LLM-assisted scientific ideation."
  },
  "knowledge_gap": {
    "answer": "The paper addresses the gap in current LLM-based scientific ideation systems, which often fail to integrate human supervision during generation in a complementary manner, leading to dissatisfaction due to misalignment with user goals.",
    "evidence": "However, these approaches often fail to integrate human supervision during generation in a truly complementary manner, neglecting the nuanced expectations and goals of the user."
  },
  "novelty": {
    "answer": [
      "Introduction of a Human-in-the-loop (HITL) framework that balances human control with automation.",
      "Use of Monte Carlo Tree Search (MCTS) to iteratively explore the idea space and extend test time compute.",
      "Implementation of a fine-grained review-based refinement process with actionable feedback.",
      "Development of a query-based retrieval system for targeted literature synthesis.",
      "Open-source availability of the platform for broader adoption."
    ],
    "evidence": [
      "HITL Framework: A user-centered design balancing human control with automation instead of entirely delegating the process of ideation to AI.",
      "Monte Carlo Tree Search: A systematic method to iteratively explore the idea space and extend test time compute via alternating phases of exploration and exploitation (§3.2).",
      "Fine-grained Review based Refinement: An exhaustive taxonomy (Table 2) with fine-grained actionable feedback for improving hypotheses (Figure 2) (§3.1).",
      "Query-based Retrieval: Generating targeted queries for retrieving relevant literature, with re-ranking, clustering and summarization to produce comprehensive, technical and cited responses (§3.1).",
      "Open Source: Publicly available platform for AI-Assisted scientific ideation."
    ]
  },
  "inspirational_papers": {
    "answer": "- Si et al. (2024) Current solutions that leverage LLMs in scientific ideation primarily remain hinged on multi-agent frameworks or extending test-time compute. (Methodological precursors)\n- Baek et al. (2025) These approaches often fail to integrate human supervision during generation in a truly complementary manner. (Papers with limitations addressed by this work)\n- Pu et al. (2024) Pu et al. (2024) find that researchers typically seek to refine their hypotheses into concrete research briefs. (Experimental baselines)",
    "evidence": "Current solutions that leverage LLMs in scientific ideation primarily remain hinged on multi-agent frameworks or extending test-time compute (Si et al., 2024; Hu et al., 2024; Gottweis, 2025). However, these approaches often fail to integrate human supervision during generation in a truly complementary manner (Baek et al., 2025). In contrast, Pu et al. (2024) find that researchers typically seek to refine their hypotheses into concrete research briefs."
  },
  "method": {
    "steps": [
      {
        "step": "Input a research goal and output a research brief using a three-agent architecture.",
        "input": "Research goal consisting of a research problem and its motivation.",
        "output": "Research brief consisting of a Title, Proposed Methodology, and Experiment Plan.",
        "evidence": "Broadly, the system expects as input a research goal G consisting of a research problem and it’s motivation, and outputs a research brief B consisting of a Title, Proposed Methodology and Experiment Plan."
      },
      {
        "step": "Employ Monte Carlo Tree Search (MCTS) to explore and refine research ideas.",
        "input": "Research goal and current state of research brief.",
        "output": "Refined research brief with improved quality.",
        "evidence": "To systematically explore the vast space of potential research ideas, IRIS employs Monte Carlo Tree Search (MCTS)."
      },
      {
        "step": "Use a retrieval agent to synthesize queries and retrieve relevant literature.",
        "input": "Research goal.",
        "output": "Relevant literature passages and organized reports.",
        "evidence": "For the input research goal, the retrieval agent synthesizes queries targeted to retrieve literature relevant to the research goal."
      }
    ],
    "tools": [
      {
        "name": "Gemini-2.0-Flash",
        "description": "Used for core LLM functionalities.",
        "evidence": "The core LLM functionalities are powered by Gemini-2.0-Flash (DeepMind, 2024) accessed via LiteLLM."
      },
      {
        "name": "Ai2 Scholar QA API",
        "description": "Used for answering queries with relevant literature.",
        "evidence": "For answering each query, it adopts Ai2 Scholar QA API."
      }
    ],
    "benchmark_datasets": [],
    "evaluation_metrics": [
      {
        "name": "LLM-as-a-judge",
        "purpose": "Measures the quality of generated hypotheses.",
        "application": "Used to evaluate hypothesis quality with absolute and relative scores.",
        "evidence": "Metrics: We employ LLM-as-a-judge, popularly adopted in parallel literature."
      }
    ]
  },
  "method_type": {
    "methods": [
      {
        "name": "Hypothesis or Idea Generation",
        "description": "The system produces candidate hypotheses or new research ideas from prior knowledge or external input.",
        "evidence": "This work tackles the crucial first stage of research, generating novel hypotheses."
      },
      {
        "name": "Experimental design generation",
        "description": "The approach includes producing experimental protocols, configurations, or evaluation strategies.",
        "evidence": "Outputs a research brief B consisting of a Title, Proposed Methodology and Experiment Plan."
      },
      {
        "name": "Iterative refinement of Ideas, Hypothesis and Experiment design",
        "description": "The system iteratively refines research ideas using feedback and retrieval.",
        "evidence": "IRIS employs Monte Carlo Tree Search (MCTS) to iteratively explore the idea space."
      }
    ]
  },
  "subject_area": {
    "areas": [
      {
        "name": "Interdisciplinary Sciences",
        "description": "The paper develops a system for scientific ideation applicable across diverse disciplines.",
        "evidence": "We conduct a user study with researchers from diverse disciplines validating the effectiveness of our designed system."
      }
    ]
  },
  "performance_summary": {
    "performance_summary": [
      {
        "summary": "User interaction within IRIS consistently improved hypothesis quality, increasing average absolute scores by 0.5 points and ELO ratings by 12 points for a tree depth of 3.",
        "evidence": "LLM-as-a-judge evaluations showed that user interaction within IRIS consistently improved hypothesis quality, increasing average absolute scores by 0.5 points and ELO ratings by 12 points for a tree depth of 3."
      }
    ],
    "baselines": [
      {
        "name": "Gemini-2.0-Flash",
        "description": "Used as a baseline for generating novel research briefs.",
        "evidence": "We prompt baselines Gemini-2.0-Flash, ChatGPT, ChatGPT w/ search and Claude 3.5 Haiku to generate novel research briefs."
      },
      {
        "name": "ChatGPT",
        "description": "Used as a baseline for generating novel research briefs.",
        "evidence": "We prompt baselines Gemini-2.0-Flash, ChatGPT, ChatGPT w/ search and Claude 3.5 Haiku to generate novel research briefs."
      }
    ],
    "benchmark_datasets": [],
    "evaluation_metrics": [
      {
        "name": "Absolute Score",
        "purpose": "Measures the quality of each generated hypothesis on a scale of 1-10.",
        "application": "Used to evaluate the quality of generated hypotheses.",
        "evidence": "We use two methods guided by our pre-defined criteria (Table 2). absolute score: each generated hypothesis (1-10)."
      },
      {
        "name": "ELO Rating",
        "purpose": "Aggregates head-to-head comparisons and preferences to compute ratings.",
        "application": "Used to evaluate the quality of generated hypotheses.",
        "evidence": "We use two methods guided by our pre-defined criteria (Table 2). relative score: aggregating head-to-head comparisons and preferences to compute ELO ratings."
      }
    ]
  },
  "benchmark_dataset": null,
  "limitations": {
    "limitations": [
      {
        "name": "Reliance on Researcher Expertise",
        "description": "The system relies on the researcher as the judge to verify the quality of the emerging idea, assuming sufficient domain expertise.",
        "evidence": "Currently the system relies on the researcher as the judge to verify the quality of the emerging idea at each iteration, augmented by LLM-as-the-judge."
      },
      {
        "name": "Computational Intensity",
        "description": "MCTS can be computationally intensive, requiring budget controls to manage resource usage.",
        "evidence": "MCTS can be computationally intensive. IRIS incorporates budget controls, allowing users to set limits."
      }
    ]
  },
  "future_directions": {
    "future_directions": [
      {
        "name": "Develop a True Human-AI Co-creation System",
        "description": "Aim for a system where foundational LLMs with scientific expertise engage in a two-way Socratic review and refinement communication with researchers.",
        "evidence": "In future we aim for a true Human AI Co-creation System, where more foundational LLMs with scientific expertise, questions researchers for the choices he or she has made."
      },
      {
        "name": "Explore Frontier LLMs",
        "description": "Investigate the use of stronger base models like Claude 3.7 Sonnet and Gemini-2.5-Pro to improve hypothesis quality.",
        "evidence": "Due to budget constraints, we have not explored frontier LLMs such as Claude 3.7 Sonnet, Grok-3 or reasoning models like Gemini-2.5-Pro, o1 etc."
      }
    ]
  },
  "resource_link": {
    "answer": "https://github.com/allenai/s2orc-doc2json",
    "evidence": "We also provide the ability for the researcher to upload papers in the form of PDF documents, which they think to be relevant but have been missed out as the part of the retrieval. The retrieval agent parses the PDF through Grobid based doc2json tool3 and appends the most relevant chunks to the context for the ideation agent to refine the research brief."
  }
}