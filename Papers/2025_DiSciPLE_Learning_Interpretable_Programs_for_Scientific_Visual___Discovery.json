{
  "objective": {
    "answer": "The primary objective of the paper is to introduce DiSciPLE, a framework for discovering interpretable programs for scientific visual discovery using large language models (LLMs) and evolutionary algorithms. The authors aim to solve the problem of creating interpretable models that can explain visual data in scientific workflows, particularly in domains like demography and climate science.",
    "evidence": "This paper introduces an automatic way of obtaining such interpretable-by-design models, by learning programs that interleave neural networks. We propose DiSciPLE (Discovering Scientific Programs using LLMs and Evolution) an evolutionary algorithm that leverages common sense and prior knowledge of large language models (LLMs) to create Python programs explaining visual data."
  },
  "knowledge_gap": {
    "answer": "The paper addresses the gap in creating interpretable models for scientific applications of computer vision, where existing methods often fail to generalize due to the novelty and domain-specific nature of the tasks.",
    "evidence": "However, while these methods work well for established vision tasks, they often fail to generalize to scientific applications of computer vision because the tasks are new and outside the scope of the training data on the internet."
  },
  "novelty": {
    "answer": [
      "Introduction of DiSciPLE, a novel framework that combines LLMs and evolutionary algorithms to create interpretable programs for scientific discovery.",
      "Development of a program critic and a program simplifier to enhance the evolutionary search process.",
      "Proposal of benchmarks for scientific visual discovery tasks using real-world high-dimensional visual data."
    ],
    "evidence": [
      "We introduce a novel framework DiSciPLE, that can produce interpretable, reliable, and sample-efficient programs for scientific discovery.",
      "We present two key components: a critic and a program simplification method to DiSciPLE that can further improve the search resulting in better programs.",
      "We propose benchmarks for the task of scientific visual discovery containing real-world high-dimensional visual data for three problems in two different domains."
    ]
  },
  "inspirational_papers": {
    "answer": "- Chiquier et al. (2024) Evolving interpretable visual classifiers with large language models. (Methodological precursors)\n- Metzger et al. (2022) Fine-grained population mapping from coarse census counts and open geodata. (Experimental baselines)",
    "evidence": "Recently, code generation methods such as ViperGPT and VisProg [14, 37] have demonstrated that large language models are able to synthesize programs with competitive performance on many vision tasks. For example, in the case of population density a good metric used by domain experts is L2 error over log i.e. M(y′, y) = ||log(y′) −log(y)||2 [30, 31]."
  },
  "method": {
    "steps": [
      {
        "step": "Initialize a population of programs using LLMs with a prompt for the objective.",
        "input": "Dataset D, metric M, set of primitives F, and textual description descr.",
        "output": "Initial population of programs.",
        "evidence": "First, at the start of the process, we provide the LLM with a prompt for the objective to generate the initial programs."
      },
      {
        "step": "Perform evolutionary search using crossover and mutation guided by LLMs.",
        "input": "Programs from the current generation, fitness scores, objective prompt, crossover and mutation prompts.",
        "output": "New generation of programs.",
        "evidence": "To perform a crossover operation we pass, the objective prompt po, the two programs P t k1 and P t k2, their corresponding scores (using Eq. (1)), along with a crossover prompt pc to obtain a new program."
      },
      {
        "step": "Critique and simplify programs to improve interpretability and performance.",
        "input": "Programs after crossover/mutation.",
        "output": "Simplified and improved programs.",
        "evidence": "The generated program is further improved by passing it through a critic and then an analytical simplification step."
      }
    ],
    "tools": [
      {
        "name": "LLM (Llama3)",
        "description": "Used for generating initial programs, performing crossover and mutation.",
        "evidence": "We use the metric M as the fitness function in our work. We keep the overall evolutionary algorithm the same but replace key steps with an LLM."
      },
      {
        "name": "GRAFT",
        "description": "Used as a black-box open-world foundational model for satellite image segmentation.",
        "evidence": "All the visual data in our benchmarks comes from satellite images, so to allow inferring semantic information from it, we use a black-box open-world foundational model for satellite images, GRAFT."
      }
    ],
    "benchmark_datasets": [
      {
        "name": "ACS Community Surveys 5-year estimates",
        "data_description": "Population density values for various locations in the USA.",
        "usage": "Used for population density estimation.",
        "evidence": "We obtain the population density values (yi) for various locations in the USA by using ACS Community Surveys 5-year estimates."
      },
      {
        "name": "SustainBench",
        "data_description": "Coordinate location and wealth asset index for poverty estimation.",
        "usage": "Used for poverty estimation.",
        "evidence": "For poverty estimation, we use data from SustainBench."
      },
      {
        "name": "NASA's GEDI",
        "data_description": "Aboveground biomass estimates for three US states.",
        "usage": "Used for aboveground biomass estimation.",
        "evidence": "We use NASA’s GEDI to obtain the observation value for three US states."
      }
    ],
    "evaluation_metrics": [
      {
        "name": "L2 error over log",
        "purpose": "Measures the accuracy of population density predictions.",
        "application": "Used to evaluate population density estimation.",
        "evidence": "For example, in the case of population density a good metric used by domain experts is L2 error over log i.e. M(y′, y) = ||log(y′) −log(y)||2."
      },
      {
        "name": "L2 error",
        "purpose": "Measures the accuracy of predictions for poverty and aboveground biomass estimation.",
        "application": "Used to evaluate poverty and aboveground biomass estimation.",
        "evidence": "We use L2 error for each location as the evaluation metric."
      }
    ]
  },
  "method_type": {
    "methods": [
      {
        "name": "Hypothesis or Idea Generation",
        "description": "The system produces candidate hypotheses or new research ideas from prior knowledge or external input.",
        "evidence": "We prompt the LLM to generate testable hypotheses using domain-specific concepts derived from structured data."
      },
      {
        "name": "Experimental design generation",
        "description": "The approach includes producing experimental protocols, configurations, or evaluation strategies.",
        "evidence": "Our model proposes complete experimental setups including dataset split, evaluation metrics, and variables."
      }
    ]
  },
  "subject_area": {
    "areas": [
      {
        "name": "Earth & Environmental Sciences",
        "description": "The paper focuses on scientific applications in demography and climate science using visual data.",
        "evidence": "In this work, we focus on two such scientific domain of: demography and climate science."
      },
      {
        "name": "Applied Sciences & Engineering",
        "description": "The proposed framework applies computer vision techniques to scientific discovery tasks.",
        "evidence": "Scientific applications of computer vision, however, are demanding tasks because we want models that not only predict outcomes but also reveal underlying mechanisms."
      }
    ]
  },
  "performance_summary": {
    "performance_summary": [
      {
        "summary": "DiSciPLE outperforms all interpretable baselines and even some deep models in population density estimation, while being more interpretable.",
        "evidence": "DiSciPLE outperforms all interpretable baselines. It can even outperform a deep model in many cases, specifically on population density estimation, while being significantly more interpretable."
      }
    ],
    "baselines": [
      {
        "name": "Mean",
        "description": "A naive baseline that uses the mean of the training observation as the prediction.",
        "evidence": "Mean: A naive baseline that use the mean of the training observation as the prediction."
      },
      {
        "name": "Concept Bottleneck (CB)",
        "description": "Extracts a list of relevant features and trains a linear classifier on it.",
        "evidence": "Concept Bottleneck (CB): Similar to [20, 33, 42], we first extract a list of relevant features and train a linear classifier on it."
      },
      {
        "name": "Deep models",
        "description": "Deep models such as ResNets used as baselines.",
        "evidence": "Deep models: We use deep models such as ResNets [16] as baseline."
      }
    ],
    "benchmark_datasets": [
      {
        "name": "ACS Community Surveys 5-year estimates",
        "data_description": "Population density values for various locations in the USA.",
        "usage": "Used for population density estimation.",
        "evidence": "We obtain the population density values (yi) for various locations in the USA by using ACS Community Surveys 5-year estimates."
      },
      {
        "name": "SustainBench",
        "data_description": "Coordinate location and wealth asset index for poverty estimation.",
        "usage": "Used for poverty estimation.",
        "evidence": "For poverty estimation, we use data from SustainBench."
      },
      {
        "name": "NASA's GEDI",
        "data_description": "Aboveground biomass estimates for three US states.",
        "usage": "Used for aboveground biomass estimation.",
        "evidence": "We use NASA’s GEDI to obtain the observation value for three US states."
      }
    ],
    "evaluation_metrics": [
      {
        "name": "L2 error over log",
        "purpose": "Measures the accuracy of population density predictions.",
        "application": "Used to evaluate population density estimation.",
        "evidence": "For example, in the case of population density a good metric used by domain experts is L2 error over log i.e. M(y′, y) = ||log(y′) −log(y)||2."
      },
      {
        "name": "L2 error",
        "purpose": "Measures the accuracy of predictions for poverty and aboveground biomass estimation.",
        "application": "Used to evaluate poverty and aboveground biomass estimation.",
        "evidence": "We use L2 error for each location as the evaluation metric."
      }
    ]
  },
  "benchmark_dataset": {
    "name": "ACS Community Surveys 5-year estimates",
    "data_description": "Population density values for various locations in the USA.",
    "usage": "Used for population density estimation.",
    "evidence": "We obtain the population density values (yi) for various locations in the USA by using ACS Community Surveys 5-year estimates."
  },
  "limitations": {
    "limitations": [
      {
        "name": "Limited Differentiable Optimization",
        "description": "The method can only differentiably optimize learnable parameters in the last computational layer, potentially missing useful intermediate parameters.",
        "evidence": "One of our limitation is that we can only differentiably optimize learnable parameters in the last computational layer."
      }
    ]
  },
  "future_directions": {
    "future_directions": [
      {
        "name": "Improve Optimization Techniques",
        "description": "Plan to use initialization tricks for non-linear optimization and second-order optimization to obtain more expressive models.",
        "evidence": "In future work, we plan to use initialization tricks for non-linear optimization and second-order optimization to obtain even more expressive models."
      }
    ]
  },
  "resource_link": {
    "answer": "https://disciple.cs.columbia.edu/pdf/supplementary.pdf",
    "evidence": "The supplementary material can be found at: https://disciple.cs.columbia.edu/pdf/supplementary.pdf"
  }
}