{
  "objective": {
    "answer": "The primary objective of the paper is to investigate whether augmenting large language models with relevant data during the research idea generation process can enhance the quality of generated ideas in the social sciences. The authors aim to address challenges related to feasibility and expected effectiveness of large language model-generated research ideas by incorporating metadata and automatic validation. They conduct empirical experiments in the domain of climate negotiations to evaluate the impact of these data-driven enhancements.",
    "evidence": "This paper explores how augmenting LLMs with relevant data during the idea generation process can enhance the quality of generated ideas. We introduce two ways of incorporating data: (1) providing metadata during the idea generation stage to guide LLMs toward feasible directions, and (2) adding automatic validation during the idea selection stage to assess the empirical plausibility of hypotheses within ideas. We conduct experiments in the social science domain, specifically with climate negotiation topics, and find that metadata improves the feasibility of generated ideas by 20%, while automatic validation improves the overall quality of selected ideas by 7%."
  },
  "knowledge_gap": {
    "answer": "Many research ideas generated by large language models are novel but often lack feasibility, suitable datasets for validation, or have uncertain effectiveness, limiting their practical utility in empirical research.",
    "evidence": "However, many LLM-generated ideas suffer from practical limitations: they may be infeasible to implement, lack suitable datasets for validation, or have uncertain effectiveness. For instance, an LLM might propose investigating 'the impact of diplomatsâ€™ childhood environmental experiences on their bargaining positions in UN climate negotiations', which is an interesting idea but lacks available data for empirical analysis."
  },
  "novelty": {
    "answer": [
      "Introducing the integration of metadata (dataset descriptions) into the idea generation stage of large language models to guide them toward empirically feasible research ideas.",
      "Incorporating automatic validation during the idea selection stage, where large language models use code to analyze data and preliminarily validate hypotheses within generated ideas.",
      "Constructing a unified climate negotiation dataset (CLIMATEDATABANK) to support data-driven research idea generation and validation.",
      "Demonstrating through human studies that large language model-generated ideas, when augmented with data and validation, can inspire human researchers to propose higher-quality research ideas."
    ],
    "evidence": [
      "We introduce two ways of incorporating data: (1) providing metadata during the idea generation stage to guide LLMs toward feasible directions, and (2) adding automatic validation during the idea selection stage to assess the empirical plausibility of hypotheses within ideas.",
      "We conduct experiments in the social science domain, specifically with climate negotiation topics, and find that metadata improves the feasibility of generated ideas by 20%, while automatic validation improves the overall quality of selected ideas by 7%.",
      "We first collect and gather relevant datasets into a unified CLIMATEDATABANK. To evaluate the impact of metadata, we compare LLM-generated ideas with and without access to the metadata of CLIMATEDATABANK...",
      "A human study shows that LLM-generated ideas, along with their related data and validation processes, inspire researchers to propose research ideas with higher quality."
    ]
  },
  "inspirational_papers": {
    "answer": [
      "Si et al. (2024) Can LLMs generate novel research ideas? a large-scale human study with 100+ nlp researchers. (Experimental baselines, prior work on LLM idea generation)",
      "Yamada et al. (2025) The ai scientist-v2: Workshop-level automated scientific discovery via agentic tree search. (Methodological precursor for automated scientific discovery)",
      "Elovic (2023) gpt-researcher. (Experimental baseline for idea generation methods)",
      "Li et al. (2024a) Chain of ideas: Revolutionizing research via novel idea development with llm agents. (Experimental baseline for idea generation methods)"
    ],
    "evidence": [
      "Recent advances in large language models (LLMs) have demonstrated their potential to generate domain-specific research ideas, with some studies suggesting that these ideas can exhibit greater novelty than those proposed by human experts (Si et al., 2024; Yamada et al., 2025).",
      "We experiment with three prevalent research idea generation methods: AI-Researcher (Si et al., 2024), GPT-Researcher (Elovic, 2023), and Chain-of-Ideas (Li et al., 2024a)."
    ]
  },
  "method": {
    "steps": [
      {
        "step": "Data Collection and Preparation",
        "input": "Relevant datasets related to climate negotiations, including textual, panel, and cross-sectional data; literature review to identify important datasets and reference papers.",
        "output": "CLIMATEDATABANK, a unified collection of 22 datasets in CSV format; a set of 8 reference papers with clear hypotheses and replicable data.",
        "tools": [],
        "evidence": "We first collect data related to climate negotiations, constructing the CLIMATEDATABANK to facilitate the following experiments. Our process begins with a comprehensive literature review, identifying important and commonly used datasets."
      },
      {
        "step": "Research Idea Generation with Metadata",
        "input": "Research topic, related literature, and metadata (concise dataset descriptions) from CLIMATEDATABANK.",
        "output": "A set of candidate research ideas, each with a research question, theory, and hypotheses.",
        "tools": [
          "GPT-4o (gpt-4o-2024-08-06): Used for idea generation and selection.",
          "Gemini-1.5-Pro (gemini-1.5-pro-002): Used as a judge model for evaluation.",
          "Claude-3.5-Sonnet (claude-3-5-sonnet-20241022): Used as a judge model for evaluation."
        ],
        "evidence": "We enhance this framework by incorporating data at two key stages: (1) During idea generation, we provide metadata, such as dataset descriptions, to guide models toward feasible research directions..."
      },
      {
        "step": "Idea Selection via Tournament Ranking",
        "input": "Generated research ideas (with and without metadata).",
        "output": "Top-ranked research ideas based on significance, novelty, feasibility, and expected effectiveness.",
        "tools": [
          "GPT-4o: Used for idea selection via Swiss tournament ranking."
        ],
        "evidence": "As Si et al. (2024) demonstrate that LLMs better assess ideas in pairwise ranking than rating, we conduct a Swiss tournament for idea selection."
      },
      {
        "step": "Automatic Validation of Hypotheses",
        "input": "Selected research ideas, corresponding datasets from CLIMATEDATABANK.",
        "output": "Validation traces (code, outputs, and interpretations) indicating whether hypotheses are supported by data.",
        "tools": [
          "GPT-4o with the code interpreter assistant: Used to write and execute Python code for hypothesis validation."
        ],
        "evidence": "We experiment with GPT-4o using the code interpreter assistant, a built-in tool available in GPT models. It achieves superior performance in quantitative reasoning with data (Liu et al., 2024b)..."
      },
      {
        "step": "Summarization of Validation Process",
        "input": "Raw validation traces (code and text outputs).",
        "output": "Concise natural language summaries of the validation process for each idea.",
        "tools": [
          "GPT-4o: Used for summarizing the validation process."
        ],
        "evidence": "To make the output more interpretable and useful for downstream selection, we prompt the LLM to summarize the full validation process into concise natural language steps..."
      },
      {
        "step": "Human Study for Inspiration Assessment",
        "input": "LLM-generated ideas, validation processes, and data snippets; human participants (researchers).",
        "output": "Human-proposed research ideas and feedback on the inspirational value of LLM-generated references.",
        "tools": [],
        "evidence": "In a study with 23 researchers, we find that compared to traditional idea creation aided only by the Internet, participants propose ideas of higher quality when given the reference of LLM-generated ideas."
      }
    ],
    "tools": [
      "GPT-4o: Large language model used for idea generation, selection, feasibility checks, and validation process summarization.",
      "GPT-4o with code interpreter assistant: Used for writing and executing Python code to validate hypotheses against data.",
      "Gemini-1.5-Pro: Large language model used as a judge for automatic evaluation of idea quality.",
      "Claude-3.5-Sonnet: Large language model used as a judge for automatic evaluation of idea quality."
    ],
    "evidence": [
      "We use GPT-4o (gpt-4o-2024-08-06) for idea generation and selection, and use Gemini-1.5-Pro (Team et al., 2024) (gemini-1.5-pro-002) and Claude-3.5-Sonnet (Anthropic, 2024) (claude-3-5-sonnet-20241022) as judge models.",
      "We experiment with GPT-4o using the code interpreter assistant, a built-in tool available in GPT models.",
      "We first collect data related to climate negotiations, constructing the CLIMATEDATABANK to facilitate the following experiments."
    ]
  },
  "subject_area": {
    "areas": [
      "Social Sciences",
      "Earth & Environmental Sciences"
    ],
    "evidence": [
      "We conduct experiments in the domain of social science, focusing specifically on topics related to climate negotiations.",
      "CLIMATEDATABANK is composed of three primary types of data: (1) Textual data, which includes documents such as national communications and high-level statements issued by various countries, enabling both qualitative analysis and text mining. (2) Panel data, such as the Gross Domestic Product (GDP) of each country over time, facilitating longitudinal analysis of trends over multiple years. (3) Cross-sectional data, capturing static attributes such as membership in the Alliance of Small Island States (AOSIS), with all values standardized to the year 2025 for consistency."
    ]
  },
  "performance_summary": {
    "performance_summary": [
      "Incorporating metadata during idea generation improves the feasibility of generated ideas by 20% and expected effectiveness by 18% in human evaluation.",
      "Automatic validation during idea selection improves the accuracy of idea ranking by an average of 8% and ideas selected with validation are rated 7% higher in human evaluation.",
      "Human study shows that participants propose higher-quality ideas when given LLM-generated references, with improvements observed in novelty, feasibility, and expected effectiveness."
    ],
    "baselines": [
      "AI-Researcher: A method that retrieves papers related to the research topic and generates and ranks candidate ideas.",
      "GPT-Researcher: A multi-agent framework with planner, executor, and publisher agents for idea generation.",
      "Chain-of-Ideas: A method that organizes relevant literature in a chain structure to mirror progressive research development."
    ],
    "benchmark_datasets": [
      "CLIMATEDATABANK: A unified collection of 22 datasets related to climate negotiations, including textual, panel, and cross-sectional data. Used for both idea generation (as metadata) and hypothesis validation.",
      "DiscoveryBench: Contains hypotheses from 20 papers across diverse fields like humanities, sociology, and economics. Used for evaluating hypothesis validation accuracy."
    ],
    "evaluation_metrics": [
      "Feasibility: Whether the study can be done with available resources, time, and technology.",
      "Expected Effectiveness: Likelihood that the proposed idea will achieve its intended outcomes.",
      "Significance: Impact on the field and relevance to current problems.",
      "Novelty: Originality and contribution of fresh insights.",
      "Accuracy (for hypothesis validation): Proportion of validation results that align with conclusions in original papers.",
      "ELO scores: Used for automatic evaluation of idea quality via tournament ranking."
    ],
    "evidence": [
      "incorporating metadata improves the feasibility by 20% and the expected effectiveness by 18% in human evaluation. Additionally, we find that automatic validation improves the accuracy of idea ranking by an average of 8%, and ideas selected with validation are rated 7% higher in human evaluation compared to those selected without validation.",
      "We experiment with three prevalent research idea generation methods: AI-Researcher (Si et al., 2024), GPT-Researcher (Elovic, 2023), and Chain-of-Ideas (Li et al., 2024a).",
      "CLIMATEDATABANK contains 22 datasets in total, each stored in CSV format for ease of access.",
      "We extract 18 hypotheses from the 8 domain-specific papers collected in Â§2, of which 10 are supported and 8 are refuted. Hypotheses with insignificant or mixed evidence are excluded. To expand the experimental scope, we sample 50 hypotheses from DiscoveryBench (Majumder et al., 2024b), drawn from 20 papers across diverse fields like humanities, sociology, and economics.",
      "We assess idea quality using four criteria motivated by previous works (Si et al., 2024; Yang et al., 2024b): significance, novelty, feasibility, and expected effectiveness (abbreviated as exp. effectiveness).",
      "We begin by evaluating whether the LLMâ€™s validation results align with the conclusions presented in the original papers. As shown in Table 2a, the model achieves over 70% accuracy on both general-domain and domain-specific hypotheses.",
      "For automatic evaluation, we conduct tournament ranking and compute ELO scores following Idea Arena (Li et al., 2024a)."
    ]
  },
  "limitations": {
    "limitations": [
      {
        "label": "Task Scope",
        "explanation": "Experiments focus only on climate negotiation topics, limiting generalizability to other domains.",
        "evidence": "While our experiments focus on topics related to climate negotiations, the proposed method could be applied to other quantitative social science research areas. We believe that incorporating data could also enhance the generation of research ideas in other domains, such as computer science, but this would need further development of the method."
      },
      {
        "label": "Exploration of LLMs and Validation Methods",
        "explanation": "Only a single large language model and a specific validation method are evaluated due to the high cost of human evaluation.",
        "evidence": "Due to the high cost of human evaluation, our experiments focus on a single LLM and a specific automatic validation method. Future studies could systematically evaluate how different models and validation methods impact idea quality."
      },
      {
        "label": "Trade-off between Novelty and Feasibility",
        "explanation": "Adding metadata improves feasibility but can reduce the novelty of generated ideas.",
        "evidence": "The introduction of metadata improves feasibility but leads to a modest decline in novelty. This suggests that although LLMs are not explicitly restricted to the provided data, the metadata implicitly narrows their scope of imagination."
      }
    ],
    "evidence": [
      "While our experiments focus on topics related to climate negotiations, the proposed method could be applied to other quantitative social science research areas. We believe that incorporating data could also enhance the generation of research ideas in other domains, such as computer science, but this would need further development of the method.",
      "Due to the high cost of human evaluation, our experiments focus on a single LLM and a specific automatic validation method. Future studies could systematically evaluate how different models and validation methods impact idea quality.",
      "The introduction of metadata improves feasibility but leads to a modest decline in novelty. This suggests that although LLMs are not explicitly restricted to the provided data, the metadata implicitly narrows their scope of imagination."
    ]
  },
  "future_directions": {
    "future_directions": [
      "Apply the proposed method to other quantitative social science research areas and potentially to other domains such as computer science.",
      "Systematically evaluate how different large language models and validation methods impact idea quality.",
      "Broaden the data scope from existing data to data that can be collected, or better integrate literature with data to maintain a balance between creativity and feasibility.",
      "Explore deeper questions about the nature and value of large language model-generated research ideas and their role in augmenting human creativity."
    ],
    "evidence": [
      "While our experiments focus on topics related to climate negotiations, the proposed method could be applied to other quantitative social science research areas. We believe that incorporating data could also enhance the generation of research ideas in other domains, such as computer science, but this would need further development of the method.",
      "Due to the high cost of human evaluation, our experiments focus on a single LLM and a specific automatic validation method. Future studies could systematically evaluate how different models and validation methods impact idea quality.",
      "Future works could broaden the data scope from existing data to data that can be collected, or better integrate literature with data to maintain a balance between creativity and feasibility.",
      "How could LLM-generated ideas contribute to real-world research in ways that augment human creativity? While we provide a preliminary case study of such use in Â§5, these questions remain open and worth future exploration."
    ]
  },
  "resource_link": {
    "answer": "https://github.com/assafelovic/gpt-researcher",
    "evidence": "Assaf Elovic. 2023. gpt-researcher. https://github.com/assafelovic/gpt-researcher."
  },
  "paper_title": "Improving Research Idea Generation Through Data: An Empirical Investigation in Social Science",
  "authors": [
    "Xiao",
    "Xinyi",
    "Xinyang",
    "Yansong",
    "Xun"
  ],
  "published": "2025-05-27",
  "link": "http://arxiv.org/abs/2505.21396"
}