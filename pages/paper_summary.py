import os
import json
import streamlit as st

# ğŸ“ Path to your JSON folder
json_dir = json_dir = "Papers"

# ğŸ” Get all JSON files in the folder
json_files = sorted(f for f in os.listdir(json_dir) if f.endswith(".json"))

# ğŸ¯ App Title
st.set_page_config(page_title="Paper Summary Viewer", layout="wide")
st.title("ğŸ“„ Scientific Paper Summarizer")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“œ Sidebar: Search & Select
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.header("ğŸ” Search Papers")

    # Search input box
    search_query = st.text_input("Search by filename")

    # Filter files based on query
    if search_query:
        filtered_files = [f for f in json_files if search_query.lower() in f.lower()]
    else:
        filtered_files = json_files

    st.markdown("### ğŸ“‚ Matching Papers")
    for file in filtered_files:
        if st.button(file):
            st.session_state["selected_file"] = file

# ğŸ“¦ Main Content Area
st.header("ğŸ“‘ Summary")

if "selected_file" in st.session_state:
    selected_file = st.session_state["selected_file"]
    file_path = os.path.join(json_dir, selected_file)

    with open(file_path) as f:
        data = json.load(f)

    for section, content in data.items():
        st.markdown(f"## ğŸ”¹ {section.replace('_', ' ').title()}")

        # Handle dictionary sections with "answer"
        if isinstance(content, dict) and "answer" in content:
            answer = content["answer"]
            evidence = content.get("evidence", "")

            st.markdown("**âœ… Answer**")
            if isinstance(answer, list):
                for i, a in enumerate(answer, 1):
                    st.markdown(f"{i}. {a}")
            else:
                st.markdown(answer)

            st.markdown("**ğŸ“Œ Evidence**")
            if isinstance(evidence, list):
                for e in evidence:
                    st.markdown(f"- {e}")
            else:
                st.markdown(evidence)

            st.markdown("---")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ğŸ” METHOD Section
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        elif section == "method":
            st.subheader("ğŸ”„ Steps")
            for step in content.get("steps", []):
                st.markdown(f"- **{step['step']}**")
                st.markdown(f"  - ğŸ“¥ Input: {step['input']}")
                st.markdown(f"  - ğŸ“¤ Output: {step['output']}")
                st.markdown(f"  - ğŸ“Œ Evidence: {step['evidence']}")
                st.markdown("---")

            if content.get("tools"):
                st.subheader("ğŸ› ï¸ Tools")
                for tool in content["tools"]:
                    st.markdown(f"- **{tool['name']}**: {tool['description']}")
                    st.markdown(f"  - ğŸ“Œ Evidence: {tool['evidence']}")

            if content.get("benchmark_datasets"):
                st.subheader("ğŸ“š Benchmark Datasets")
                for d in content["benchmark_datasets"]:
                    st.markdown(f"- **{d['name']}**")
                    st.markdown(f"  - ğŸ“Š Description: {d['data_description']}")
                    st.markdown(f"  - ğŸ”§ Usage: {d['usage']}")
                    st.markdown(f"  - ğŸ“Œ Evidence: {d['evidence']}")

            if content.get("evaluation_metrics"):
                st.subheader("ğŸ“ Evaluation Metrics")
                for m in content["evaluation_metrics"]:
                    st.markdown(f"- **{m['name']}**")
                    st.markdown(f"  - ğŸ¯ Purpose: {m['purpose']}")
                    st.markdown(f"  - âš™ï¸ Application: {m['application']}")
                    st.markdown(f"  - ğŸ“Œ Evidence: {m['evidence']}")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ğŸ§  METHOD TYPE Section
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        elif section == "method_type":
            st.subheader("ğŸ§  Method Types")
            for m in content.get("methods", []):
                st.markdown(f"- **{m['name']}**: {m['description']}")
                st.markdown(f"  - ğŸ“Œ Evidence: {m['evidence']}")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ğŸ§ª SUBJECT AREA Section
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        elif section == "subject_area":
            st.subheader("ğŸ§ª Subject Areas")
            for s in content.get("areas", []):
                st.markdown(f"- **{s['name']}**: {s['description']}")
                st.markdown(f"  - ğŸ“Œ Evidence: {s['evidence']}")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ğŸ§ª PERFORMANCE SUMMARY Section
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        elif section == "performance_summary":
            if content.get("performance_summary"):
                st.subheader("ğŸ“ˆ Performance Summary")
                for p in content["performance_summary"]:
                    st.markdown(f"- {p['summary']}")
                    st.markdown(f"  - ğŸ“Œ Evidence: {p['evidence']}")

            if content.get("baselines"):
                st.subheader("ğŸ“Š Baselines")
                for b in content["baselines"]:
                    st.markdown(f"- {b['name']}: {b['description']}")
                    st.markdown(f"  - ğŸ“Œ Evidence: {b['evidence']}")


            if content.get("benchmark_datasets"):
                st.subheader("ğŸ§ª Benchmark Datasets")
                for d in content["benchmark_datasets"]:
                    st.markdown(f"- **{d['name']}**")
                    st.markdown(f"  - ğŸ“Š Description: {d['data_description']}")
                    st.markdown(f"  - ğŸ”§ Usage: {d['usage']}")
                    st.markdown(f"  - ğŸ“Œ Evidence: {d['evidence']}")
                    
            if content.get("evaluation_metrics"):
                st.subheader("ğŸ“ Evaluation Metrics")
                for m in content["evaluation_metrics"]:
                    st.markdown(f"- **{m['name']}**")
                    st.markdown(f"  - Purpose: {m['purpose']}")
                    st.markdown(f"  - Application: {m['application']}")
                    st.markdown(f"  - ğŸ“Œ Evidence: {m['evidence']}")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ğŸ§ª benchmark_dataset Section
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        elif section == "benchmark_dataset":
            if content is None:
                st.warning("No benchmark dataset was used.")
            else:
                st.markdown(content)

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ğŸ§ª limitations
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        elif section == "limitations":
            for item in content.get("limitations", []):
                st.markdown(f"- **{item['name']}**: {item['description']}")
                st.markdown(f"  - ğŸ“Œ Evidence: {item['evidence']}")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ğŸ§ª future_directions Section
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        elif section == "future_directions":
            for i, item in enumerate(content.get("future_directions", []), 1):
                st.markdown(f"### {i}. {item['name']}")
                st.markdown(f"{item['description']}")
                st.markdown(f"ğŸ“Œ **Evidence**: {item['evidence']}")
                st.markdown("---")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ğŸ§ª resource_link Section
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        elif section == "resource_link":
            st.markdown("### ğŸ”— Resource Link")
            st.markdown(f"[{content['answer']}]({content['answer']})")
            st.markdown(f"ğŸ“Œ **Evidence**: {content.get('evidence', 'No evidence provided.')}")
            st.markdown("---")

        else:
            st.markdown("â„¹ï¸ Unrecognized format. Raw content below:")
            st.json(content)

else:
    st.info("Select a paper from the sidebar to begin.")
